category,page,text,label
Finance,Morningstar Style Box,"The Morningstar Style Box is a grid of nine squares used to identify the investment style of stocks and mutual funds. Developed by Don Phillips and John Rekenthaler, the Style Box was launched in 1992.The vertical axis of the Style Box represents an investment's size category: small, mid and large. The horizontal axis depicts fund investment style categories such as ""value"" and ""growth,"" which are common to stocks and funds. The ""blend"" definition in the central column differs for stocks and funds. “For stocks, the central column of the Style Box will represent the core style (those for which neither value or growth characteristics dominate); for funds, it will represent the blend style (a mixture of growth and value stocks or mostly core stocks).”",3
Finance,Master of Finance,"The Master of Finance is a master's degree awarded by universities or graduate schools preparing students for careers in finance. The degree is often titled Master in Finance (abbreviated M.Fin., MiF, MFin), or Master of Science in Finance (MSF in North America, and MSc in Finance in the UK and Europe).  In the U.S. and Canada the program may be positioned as a professional degree.  Particularly in Australia, the degree may be offered as a Master of Applied Finance (MAppFin). In some cases, the degree is offered as a Master of Management in Finance (MMF). More specifically focused and titled degrees are also offered.

",3
Finance,Financial close management,"Financial close management (FCM) is a recurring process in management accounting by which accounting teams verify and adjust account balances at the end of a designated period in order to produce financial reports representative of the company's true financial position to inform stakeholders such as management, investors, lenders, and regulatory agencies.

",3
Finance,Austerity,"Austerity is a set of political-economic policies that aim to reduce government budget deficits through spending cuts, tax increases, or a combination of both. There are three primary types of austerity measures: higher taxes to fund spending, raising taxes while cutting spending, and lower taxes and lower government spending. Austerity measures are often used by governments that find it difficult to borrow or meet their existing obligations to pay back loans. The measures are meant to reduce the budget deficit by bringing government revenues closer to expenditures. Proponents of these measures state that this reduces the amount of borrowing required and may also demonstrate a government's fiscal discipline to creditors and credit rating agencies and make borrowing easier and cheaper as a result.
In most macroeconomic models, austerity policies which reduce government spending lead to increased unemployment in the short term. These reductions in employment usually occur directly in the public sector and indirectly in the private sector. Where austerity policies are enacted using tax increases, these can reduce consumption by cutting household disposable income. Reduced government spending can reduce GDP growth in the short term as government expenditure is itself a component of GDP. In the longer term, reduced government spending can reduce GDP growth if, for example, cuts to education spending leave a country's workforce less able to do high-skilled jobs or if cuts to infrastructure investment impose greater costs on business than they saved through lower taxes. In both cases, if reduced government spending leads to reduced GDP growth, austerity may lead to a higher debt-to-GDP ratio than the alternative of the government running a higher budget deficit. In the aftermath of the Great Recession, austerity measures in many European countries were followed by rising unemployment and slower GDP growth. The result was increased debt-to-GDP ratios despite reductions in budget deficits.Theoretically in some cases, particularly when the output gap is low, austerity can have the opposite effect and stimulate economic growth. For example, when an economy is operating at or near capacity, higher short-term deficit spending (stimulus) can cause interest rates to rise, resulting in a reduction in private investment, which in turn reduces economic growth. Where there is excess capacity, the stimulus can result in an increase in employment and output. Alberto Alesina, Carlo Favero, and Francesco Giavazzi argue that austerity can be expansionary in situations where government reduction in spending is offset by greater increases in aggregate demand (private consumption, private investment, and exports).",3
Finance,Accounting period,"An accounting period, in bookkeeping, is the period with reference to which management accounts and financial statements are prepared. 
In management accounting the accounting period varies widely and is determined by management. Monthly accounting periods are common.
In financial accounting the accounting period is determined by regulation and is usually 12 months. The beginning of the accounting period differs according to jurisdiction. For example, one entity may follow the calendar year, January to December, while another may follow April to March as the accounting period.
The International Financial Reporting Standards allow a period of 52 weeks as an accounting period instead of 12 months.  This method is known as the 4-4-5 calendar in British and Commonwealth usage and the 52–53-week fiscal year in the United States.  In the United States the method is permitted by generally accepted accounting principles, as well as by US Internal Revenue Code Regulation 1.441-2  (IRS Publication 538).In some of the ERP tools there are more than 12 accounting periods in a financial year. They put one accounting period as ""Year Open"" period where all the carried over balances from last financial year are cleared and one period as ""Year Close"" where all the transactions for closed for the same financial year. Older systems sometimes called these periods ""Month 0"" and ""Month 13"".",3
Finance,Value-in-use,"Use value (German: Gebrauchswert) or value in use is a concept in Marxist economics. It refers to the tangible features of a commodity (a tradeable object) which can satisfy some human requirement, want or need, or which serves a useful purpose. In Karl Marx's critique of political economy, any product has a labor-value and a use-value, and if it is traded as a commodity in markets, it additionally has an exchange value, most often expressed as a money-price.Marx acknowledges that commodities being traded also have a general utility, implied by the fact that people want them, but he argues that this by itself says nothing about the specific character of the economy in which they are produced and sold.",3
Finance,Undervalued stock,"An undervalued stock is defined as a stock that is selling at a price significantly below what is assumed to be its intrinsic value. For example, if a stock is selling for $50, but it is worth $100 based on predictable future cash flows, then it is an undervalued stock. The undervalued stock has the intrinsic value below the investment's true intrinsic value.  
Numerous popular books discuss undervalued stocks. Examples are The Intelligent Investor by Benjamin Graham, also known as ""The Dean of Wall Street,"" and The Warren Buffett Way by Robert Hagstrom. The Intelligent Investor puts forth Graham's principles that are based on mathematical calculations such as the price/earning ratio. He was less concerned with the qualitative aspects of a business such as the nature of a business, its growth potential and its management. For example, Amazon, Facebook, Netflix and Tesla in 2016, although they had a promising future, would not have appealed to Graham, since their price-earnings ratios were too high. Graham's ideas had a significant influence on the young Warren Buffett, who later became a famous US billionaire.

",3
Finance,Appraisal Institute,"The Appraisal Institute (AI), headquartered in Chicago, Illinois, is an international association of professional real estate appraisers. It was founded in January 1991 when the American Institute of Real Estate Appraisers (AIREA) and the Society of Residential Appraisers merged. The AIREA and the Society were respectively founded in 1932 and 1935. Real estate appraisal emerged as a profession at this point in response to the crash of home values as a result of the Great Depression, building on the intellectual frameworks developed over the course of the 1920s by land value theorists like Ernest McKinley Fisher, Frederick Babcock, Homer Hoyt, and Richard T. Ely. As of February 2007, the Appraisal Institute has more than 21,000 members and 99 chapters throughout the United States, Canada, and overseas.
The group publishes the Appraisal Journal.",3
Finance,Graham number,"Graham's number is an immense number that arose as an upper bound on the answer of a problem in the mathematical field of Ramsey theory. It is much larger than many other large numbers such as Skewes's number and Moser's number, both of which are in turn much larger than a googolplex. As with these, it is so large that the observable universe is far too small to contain an ordinary digital representation of Graham's number, assuming that each digit occupies one Planck volume, possibly the smallest measurable space. But even the number of digits in this digital representation of Graham's number would itself be a number so large that its digital representation cannot be represented in the observable universe.  Nor even can the number of digits of that number—and so forth, for a number of times far exceeding the total number of Planck volumes in the observable universe. Thus Graham's number cannot be expressed even by physical universe-scale power towers of the form 
  
    
      
        
          a
          
            
              b
              
                
                  c
                  
                    
                      ⋅
                      
                        
                          ⋅
                          
                            ⋅
                          
                        
                      
                    
                  
                
              
            
          
        
      
    
    {\displaystyle a^{b^{c^{\cdot ^{\cdot ^{\cdot }}}}}}
  .
However, Graham's number can be explicitly given by computable recursive formulas using Knuth's up-arrow notation or equivalent, as was done by Graham.  As there is a recursive formula to define it, it is much smaller than typical busy beaver numbers.  Though too large to be computed in full, the sequence of digits of Graham's number can be computed explicitly through simple algorithms; the last thirteen digits are ...7262464195387.  With Knuth's up-arrow notation, Graham's number is 
  
    
      
        
          g
          
            64
          
        
      
    
    {\displaystyle g_{64}}
  , where

Graham's number is named after the American mathematician Ronald Graham, who used the number in conversations with popular science writer Martin Gardner as a simplified explanation of the upper bounds of the problem he was working on. In 1977, Gardner described the number in Scientific American, introducing it to the general public.  At the time of its introduction, it was the largest specific positive integer ever to have been used in a published mathematical proof.  The number was described in the 1980 Guinness Book of World Records, adding to its popular interest.  Other specific integers (such as TREE(3)) known to be far larger than Graham's number have since appeared in many serious mathematical proofs, for example in connection with Harvey Friedman's various finite forms of Kruskal's theorem. Additionally, smaller upper bounds on the Ramsey theory problem from which Graham's number derived have since been proven to be valid.

",3
Finance,Liquidation value,"Liquidation value is the likely price of an asset when it is allowed insufficient time to sell on the open market, thereby reducing its exposure to potential buyers. Liquidation value is typically lower than fair market value. Unlike cash or securities, certain illiquid assets, like real estate, often require a period of several months in order to obtain their fair market value in a sale, and will generally sell for a significantly lower price if a sale is forced to occur in a shorter time period. The liquidation value may be either the result of a forced liquidation or an orderly liquidation. Either value assumes that the sale is consummated by a seller who is compelled to sell and assumes an exposure period which is less than market normal.
The most common definition used by real estate appraisers is as followsThe most probable price that a specified interest in real property is
likely to bring under all of the following conditions:

Consummation of a sale will occur within a severely limited future marketing period specified by the client.
The actual market conditions currently prevailing are those to which the appraised property interest is subject.
The buyer is acting prudently and knowledgeably.
The seller is under extreme compulsion to sell.
The buyer is typically motivated.
The buyer is acting in what he or she considers his or her best interest.
A limited marketing effort and time will be allowed for the completion of a sale.
Payment will be made in cash in U.S. dollars or in terms of financial arrangements comparable thereto.
The price represents the normal consideration for the property sold, unaffected by special or creative financing or sales concessions granted by anyone associated with the sale.Note that this definition differs from the most commonly used definitions of market value or fair market value.

",3
Finance,Intermediated research,"In finance, intermediated research is a type of fundamental analysis or investment analysis of a business to establish its value for investors that attempts to avoid commercial pressure or influence.
Many banks and brokers provide research to the investment community, however this form of research suffers from a real or perceived lack of objectivity. For example, this research may be subject to influence from within a bank from, say, investment bankers keen to win company’s IPO mandate.
An alternative form is known as independent research or alternative research, this is research that is not provided by a bank or broker. However, someone has to fund the costs of conducting the research, and when the funder is the company being researched, this form of independent research is termed “sponsored” or “company-paid” research. Unfortunately, with the subject company paying directly for these services, this form of research suffers from a real or perceived lack of objectivity, which reduces its value to investors and hence to the companies themselves.
Intermediated research improves significantly upon the sponsored research model, by introducing important safeguards into the commercial and research process framework. The key structure is that the company has no choice in its allocation to a research provider; once matched with the research provider, the company is under a long term contract in order to minimize commercial pressure or influence; and the fees paid to the research provider are not sufficiently material for the company to be able to exert any influence over the content or conclusions of the research report. Collectively, these measures enhance the value of the report to investors and consequently, to the company itself.
The intermediated research framework includes the further protections; ensuring that the independent research firms involved have no investment banking or brokerage operations in their business models; conduct no traditional company-paid research; deliver a standard template for analysis of every company so that all standard topics are covered; and avoiding ratings and target prices in the reports, since these can risk becoming a focus of pressure exerted on the research provider by the subject company.",3
Finance,Book value,"In accounting, book value  is the value of an asset according to its balance sheet account balance. For assets, the value is based on the original cost of the asset less any depreciation, amortization or impairment costs made against the asset. Traditionally, a company's book value is its total assets minus intangible assets and liabilities. However, in practice, depending on the source of the calculation, book value may variably include goodwill, intangible assets, or both. The value inherent in its workforce, part of the intellectual capital of a company, is always ignored.  When intangible assets and goodwill are explicitly excluded, the metric is often specified to be ""tangible book value"".
In the United Kingdom, the term net asset value may refer to the book value of a company.",3
Finance,Film finance,"Film finance is an aspect of film production that occurs during the development stage prior to pre-production, and is concerned with determining the potential value of a proposed film. 
In the United States, the value is typically based on a forecast of revenues (generally 10 years for films and 20 years for television shows), beginning with theatrical release, and including DVD sales, and release to cable broadcast television networks both domestic and international and inflight airline licensing.",3
Finance,Renu Sud Karnad,"Renu Sud Karnad is an Indian businesswoman and the managing director of India's largest private sector bank Housing Development Finance Corp. Ltd. Additionally she also holds seven other positions for companies like HDFC Property Ventures Ltd., HDFC Education & Development Services Pvt Ltd. (both are subsidiaries of HDFC Ltd.) and Non-Executive Chairman at GlaxoSmithKline Pharmaceuticals Ltd. She is also the Vice Chairman-Governing Council at Indraprastha Cancer Society and Research Centre and part of the board of 17 other companies.",3
Finance,Period of financial distress,"A period of financial distress occurs when the price of a company or an asset or an index of a set of assets in a market is declining with the danger of a sudden crash of value occurring, either because the company is experiencing increasing problems of cash flow or a deteriorating credit balance or because the price had become too high as a result of a speculative bubble that has now peaked.",3
Finance,Turnaround stock,A turnaround stock is a share with a high P/E ratio but low price-to-book ratio.,3
Finance,Total value of ownership,"Total value of ownership (TVO) or total value of opportunity, is a methodology of measuring and analyzing the business value of IT investments. Gartner Group designed this methodology in 2003.TVO differs from total cost of ownership (TCO) in that TVO considers the benefits of alternative investments. It is a comparative measurement that evaluates the TCO and any additional benefits, such as the mobility of laptops when compared to desktop computers.",3
Finance,Accounting entity,"An Accounting Entity is simply an Entity for which accounting records are to be kept.
The main requirements for something to be considered an ""accounting entity"" are:

It can own property the value of which can be measured in financial terms
It can incur debts or liabilities which can also be measured in financial terms
It can therefore be assigned a value for its net worth or solvency which is the difference between the twoExamples of accounting entities include corporations, clubs, trusts, partnerships and individuals.",3
Finance,Portal:Banks,"The human back, also called the dorsum, is the large posterior area of the human body, rising from the top of the buttocks to the back of the neck. It is the surface of the body opposite from the chest and the abdomen. The vertebral column runs the length of the back and creates a central area of recession. The breadth of the back is created by the shoulders at the top and the pelvis at the bottom.
Back pain is a common medical condition, generally benign in origin.",3
Finance,Asset,"In financial accounting, an asset is any resource owned or controlled by a business or an economic entity. It is anything (tangible or intangible) that can be used to produce positive economic value. Assets represent value of ownership that can be converted into cash (although cash itself is also considered an asset).
The balance sheet of a firm records the monetary value of the assets owned by that firm. It covers money and other valuables belonging to an individual or to a business.Assets can be grouped into two major classes: tangible assets and intangible assets. Tangible assets contain various subclasses, including current assets and fixed assets. Current assets include cash, inventory, accounts receivable, while fixed assets include land, buildings and equipment.
Intangible assets are non-physical resources and rights that have a value to the firm because they give the firm an advantage in the marketplace. Intangible assets include goodwill, copyrights, trademarks, patents, computer programs, and financial assets, including financial investments, bonds, and stocks.

",3
Finance,Audit technology,"An information technology audit, or information systems audit, is an examination of the management controls within an Information technology (IT) infrastructure and business applications. The evaluation of evidence obtained determines if the information systems are safeguarding assets, maintaining data integrity, and operating effectively to achieve the organization's goals or objectives. These reviews may be performed in conjunction with a financial statement audit, internal audit, or other form of attestation engagement.
IT audits are also known as automated data processing audits (ADP audits) and computer audits.
They were formerly called electronic data processing audits (EDP audits).

",3
Finance,Financial analysis,"Financial analysis (also referred to as financial statement analysis or accounting analysis or Analysis of finance) refers to an assessment of the viability, stability, and profitability of a business, sub-business or project. 
It is performed by professionals who prepare reports using ratios and other techniques, that make use of information taken from financial statements and other reports. These reports are usually presented to top management as one of their bases in making business decisions.  
Financial analysis may determine if a business will:

Continue or discontinue its main operation or part of its business;
Make or purchase certain materials in the manufacture of its product;
Acquire or rent/lease certain machineries and equipment in the production of its goods;
Issue  shares or negotiate for a bank loan to increase its working capital;
Make decisions regarding investing or lending capital;
Make other decisions that allow management to make an informed selection on various alternatives in the conduct of its business.",3
Finance,Investment value,"Investment value is the value of a property to a particular investor.  In the U.S. and U.K., it is equal to market value for the investor who has the capacity to put the property to good use—its highest-and-best-use, its most valuable use. For other investors with limited capacity or vision, investment value is lower because they cannot put the property to use in a way that is maximally productive.",3
Finance,Terminal value (finance),"In finance, the terminal value (also known as “continuing value” or “horizon value” or ""TV"") of a security is the present value at a future point in time of all future cash flows when we expect stable growth rate forever. It is most often used in multi-stage discounted cash flow analysis, and allows for the limitation of cash flow projections to a several-year period; see Forecast period (finance). 
Forecasting results beyond such a period is impractical and exposes such projections to a variety of risks limiting their validity, primarily the great uncertainty involved in predicting industry and macroeconomic conditions beyond a few years.
Thus, the terminal value allows for the inclusion of the value of future cash flows occurring beyond a several-year projection period while satisfactorily mitigating many of the problems of valuing such cash flows. 
The terminal value is calculated in accordance with a stream of projected future free cash flows in discounted cash flow analysis. 
For whole-company valuation purposes, there are two methodologies used to calculate the Terminal Value.",3
Finance,Adjusted present value,"Adjusted present value (APV) is a valuation method introduced in 1974 by Stewart Myers. The idea is to value the project as if it were all equity financed (""unleveraged""), and to then add the present value of the tax shield of debt – and other side effects.Technically, an APV valuation model looks similar to a standard DCF model. However, instead of WACC, cash flows would be discounted at the unlevered cost of equity, and tax shields at either the cost of debt (Myers) or following later academics also with the unlevered cost of equity. APV and the standard DCF approaches should give the identical result if the capital structure remains stable.According to Myers, the value of the levered firm (Value levered, Vl) is equal to the value of the firm with no debt (Value unlevered, Vu) plus the present value of the tax savings due to the tax deductibility of interest payments, the so-called value of the tax shield (VTS). Myers proposes calculating the VTS by discounting the tax savings at the cost of debt (Kd). The argument is that the risk of the tax saving arising from the use of debt is the same as the risk of the debt.The method is to calculate the NPV of the project as if it is all-equity financed (so called ""base case""). Then the base-case NPV is adjusted for the benefits of financing. Usually, the main benefit is a tax shield resulted from tax deductibility of interest payments. Another benefit can be a subsidized borrowing at sub-market rates. The APV method is especially effective when a leveraged buyout case is considered since the company is loaded with an extreme amount of debt, so the tax shield is substantial.

",3
Finance,Mortgage modification,"Mortgage modification is a process where the terms of a mortgage are modified outside the original terms of the contract agreed to by the lender and borrower (i.e. mortgagee and mortgagor in mortgage states; Trustee and Trustor in Trust Deed states). In general, any loan can be modified, and the process is referred to as loan modification or debt rescheduling.",3
Finance,Sum of Digits depreciation,"In accountancy, depreciation refers to two aspects of the same concept: first, the actual decrease of fair value of an asset, such as the decrease in value of factory equipment each year as it is used and wear, and second, the allocation in accounting statements of the original cost of the assets to periods in which the assets are used (depreciation with the matching principle).Depreciation is thus the decrease in the value of assets and the method used to reallocate, or ""write down"" the cost of a tangible asset (such as equipment) over its useful life span. Businesses depreciate long-term assets for both accounting and tax purposes. The decrease in value of the asset affects the balance sheet of a business or entity, and the method of depreciating the asset, accounting-wise, affects the net income, and thus the income statement that they report. Generally, the cost is allocated as depreciation expense among the periods in which the asset is expected to be used.
Methods of computing depreciation, and the periods over which assets are depreciated, may vary between asset types within the same business and may vary for tax purposes. These may be specified by law or accounting standards, which may vary by country. There are several standard methods of computing depreciation expense, including fixed percentage, straight line, and declining balance methods. Depreciation expense generally begins when the asset is placed in service. For example, a depreciation expense of 100 per year for five years may be recognized for an asset costing 500.
Depreciation has been defined as the diminution in the utility or value of an asset and is a non-cash expense. It does not result in any cash outflow; it just means that the asset is not worth as much as it used to be. Causes of depreciation are natural wear and tear.",3
Finance,Required rate of return,"In finance, discounted cash flow (DCF) analysis is a method of valuing a security, project, company, or asset using the concepts of the time value of money. 
Discounted cash flow analysis is widely used in investment finance, real estate development, corporate financial management and patent valuation. It was used in industry as early as the 1700s or 1800s, widely discussed in financial economics in the 1960s, and became widely used in U.S. courts in the 1980s and 1990s.",3
Finance,Business valuation,"Business valuation is a process and a set of procedures used to estimate the economic value of an owner's interest in a business.  Here various valuation techniques are used by financial market participants to determine the price they are willing to pay or receive to effect a sale of the business.
In addition to estimating the selling price of a business, the same valuation tools are often used by business appraisers to resolve disputes related to estate and gift taxation, divorce litigation, allocate business purchase price among business assets, establish a formula for estimating the value of partners' ownership interest for buy-sell agreements, and many other business and legal purposes such as in shareholders deadlock, divorce litigation and estate contest.Specialized business valuation credentials include the Chartered Business Valuator (CBV) offered by the CBV Institute, ASA and CEIV from the American Society of Appraisers, and the CVA by the National Association of Certified Valuators and Analysts. 
In some cases, the court would appoint a forensic accountant as the joint-expert doing the business valuation.  Here, attorneys should always be prepared to have their expert's report withstand the scrutiny of cross-examination and criticism. Business valuation is distinct from stock valuation, which is about calculating theoretical values of listed companies and their stocks, for the purposes of share trading and investment management. 
This distinction extends to the use of the results: stock investors intend to profit from price movement, whereas a business owner is focused on the enterprise as a total, going concern.
A further distinction is re corporate finance: 
the transactions here are generally handled by a business broker; 
whereas where two corporates are involved, the transaction and valuation is within the realm of ""mergers and acquisitions"", and is handled by an investment bank; see Mergers and acquisitions § Business valuation and Corporate finance § Investment and project valuation.",3
Finance,Financial analyst,"Financial analysis (also referred to as financial statement analysis or accounting analysis or Analysis of finance) refers to an assessment of the viability, stability, and profitability of a business, sub-business or project. 
It is performed by professionals who prepare reports using ratios and other techniques, that make use of information taken from financial statements and other reports. These reports are usually presented to top management as one of their bases in making business decisions.  
Financial analysis may determine if a business will:

Continue or discontinue its main operation or part of its business;
Make or purchase certain materials in the manufacture of its product;
Acquire or rent/lease certain machineries and equipment in the production of its goods;
Issue  shares or negotiate for a bank loan to increase its working capital;
Make decisions regarding investing or lending capital;
Make other decisions that allow management to make an informed selection on various alternatives in the conduct of its business.",3
Finance,Data valuation,"In computer science, data validation is the process of ensuring data has undergone data cleansing to ensure they have data quality, that is, that they are both correct and useful. It uses routines, often called ""validation rules"", ""validation constraints"", or ""check routines"", that check for correctness, meaningfulness, and security of data that are input to the system. The rules may be implemented through the automated facilities of a data dictionary, or by the inclusion of explicit application program validation logic of the computer and its application.
This is distinct from formal verification, which attempts to prove or disprove the correctness of algorithms for implementing a specification or property.",3
Finance,Valuation (finance),"In finance, valuation is the process of determining the present value (PV) of an asset. In a business context, it is often the hypothetical price that a third party would pay for a given asset. Valuations can be done on assets (for example, investments in marketable securities such as companies' shares and related rights, business enterprises, or intangible assets such as patents, data and trademarks) or on liabilities (e.g., bonds issued by a company). Valuations are needed for many reasons such as investment analysis, capital budgeting, merger and acquisition transactions, financial reporting, taxable events to determine the proper tax liability.",3
Finance,Contingent claim valuation,"In finance, a contingent claim is a derivative whose future payoff depends on the value of another “underlying” asset, or more generally, that is dependent on the realization of some uncertain future event. 
These are so named, since there is only a payoff under certain contingencies. 
Any derivative instrument that is not a contingent claim is called a forward commitment.The prototypical contingent claim is an option, the right to buy or sell the underlying asset at a specified exercise price by a certain expiration date;  whereas (vanilla) swaps, forwards, and futures are forward commitments, since these grant no such optionality.Contingent claims are applied under financial economics in developing models and theory, and in corporate finance as a valuation framework.
This approach originates with Robert C. Merton,
  
decomposing the value of a corporate into a set of options in his ""Merton model"" of credit risk.

",3
Finance,Quantum valebant,"Quantum valebant is a Latin phrase meaning ""as much as they were worth"". It is sometimes used in its singular form, quantum valebat, meaning “as much as it was worth"". It is a common count at law very similar to quantum meruit. The two legal actions differ only in that quantum meruit is used to recover the reasonable value of services rendered, while quantum valebant is used to recover the reasonable value of goods sold and delivered. This count is considered a type of assumpsit.",3
Finance,Present value of growth opportunities,"In corporate finance, the present value of growth opportunities (PVGO) is a valuation measure applied to growth stocks.
It represents the component of the company’s stock value that corresponds to (expected) growth in earnings. 
It thus allows an analyst to assess the extent to which the share price represents the current business, and to what extent it reflects assumptions about the future.
As a proportion of market cap, PVGO can then also be used in relative valuation, i.e. when comparing between two investments  (see similar re PEG ratio).
PVGO is calculated as follows:

PVGO = share price - earnings per share ÷ cost of capital.This arises by thinking of the value of a company as inhering two components:
(i) the present value of existing earnings, i.e. the company continuing as if under a ""no-growth policy"";
and (ii) the present value of the company's growth opportunities.
PVGO can then simply be calculated as the difference between the stock price and the present value of its zero-growth-earnings; this second term uses the formula for a perpetuity (see Dividend discount model § Some properties of the model).",3
Finance,Industrial and provident society,"An industrial and provident society (IPS) is a body corporate registered for carrying on any industries, businesses, or trades specified in or authorised by its rules.The members of a society benefit from the protection of limited liability much like other corporate forms, but unlike companies for example, each member will normally only have one vote at a General Meeting regardless of their shareholding. The governance of a society is therefore democratically oriented rather than financially oriented.
The legal form originated in the United Kingdom of Great Britain and Ireland and became the traditional legal form taken by trading organisations with democratic governance including:

co-operatives (which trade for the benefit of their members);
societies for the benefit of the community (which trade for the benefit of the broader community).In Great Britain the Co-operative and Community Benefit Societies Act 2014 has renamed these societies as co-operative or community benefit societies. 
The term industrial and provident society is still used in statute in New Zealand, the Republic of Ireland and within the UK in Northern Ireland.",3
Finance,Public commercial assets,"Public Commercial Assets are the assets owned by the public sector able to generate income if managed professionally.Public Commercial Assets are a sub-sector of the asset side of the Public Sector Balance Sheet, that reports the totals of assets and liabilities that the government controls.
According to IMF research, total public sector assets have a value equivalent to 2×GDP globally. Net worth (assets minus liabilities) would be equivalent to some 21% of GDP.Real estate is the single largest segment of all assets, globally. According to research from McKinsey Global Institute, Global net worth has risen as interest rates have fallen, since 2000 mainly due to the prices of real estate triple in value between 2000 to 2020. Most governments do not keep a complete record of all the real estate it owns, thus making it difficult to value, manage or develop and put these assets to their most productive uses.

",3
Finance,Beneish M-score,"The Beneish model is a statistical model that uses financial ratios calculated with accounting data of a specific company in order to check if it is likely (high probability) that the reported earnings of the company have been manipulated.

",3
Finance,Dividend discount model,"In finance and investing, the dividend discount model (DDM) is a method of valuing the price of a company's stock based on the fact that its stock is worth the sum of all of its future dividend payments, discounted back to their present value. In other words, DDM is used to value stocks based on the net present value of the future dividends. The constant-growth form of the DDM is sometimes referred to as the Gordon growth model (GGM), after Myron J. Gordon of the Massachusetts Institute of Technology, the University of Rochester, and the University of Toronto, who published it along with Eli Shapiro in 1956 and made reference to it in 1959. Their work borrowed heavily from the theoretical and mathematical ideas found in John Burr Williams 1938 book ""The Theory of Investment Value,"" which put forth the dividend discount model 18 years before Gordon and Shapiro.
When dividends are assumed to grow at a constant rate, the variables are: 
  
    
      
        P
      
    
    {\displaystyle P}
   is the current stock price. 
  
    
      
        g
      
    
    {\displaystyle g}
   is the constant growth rate in perpetuity expected for the dividends. 
  
    
      
        r
      
    
    {\displaystyle r}
   is the constant cost of equity capital for that company. 
  
    
      
        
          D
          
            1
          
        
      
    
    {\displaystyle D_{1}}
   is the value of dividends at the end of the first period.

  
    
      
        P
        =
        
          
            
              D
              
                1
              
            
            
              r
              −
              g
            
          
        
      
    
    {\displaystyle P={\frac {D_{1}}{r-g}}}",3
Finance,Tone at the top,"""Tone at the top"" is a term that originated in the field of accounting and is used to describe an organization's general ethical climate, as established by its board of directors, audit committee, and senior management. Having good tone at the top is believed by business ethics experts to help prevent fraud and other unethical practices. The very same idea is expressed in negative terms by the old saying ""A fish rots from the head down"".",3
Finance,Pre-money valuation,"A pre-money valuation is a term widely used in the private equity and venture capital industries. It refers to the valuation of a company or asset prior to an investment or financing. If an investment adds cash to a company, the company will have a valuation after the investment that is equal to the pre-money valuation plus the cash amount. That is, the pre-money valuation refers to the company's valuation before the investment. It is used by equity investors in the primary market, such as venture capitalists, private equity investors, corporate investors and angel investors. They may use it to determine how much equity they should be issued in return for their investment in the company. This is calculated on a fully diluted basis. For example, all warrants and options issued are taken into account.
Startups and venture capital-backed companies usually receive multiple rounds of financing rather than a big lump sum. This is in order to decrease the risk for investors and to motivate entrepreneurs. These rounds are conventionally named Round A, Round B, Round C, etc. Pre-money and post-money valuation concepts apply to each round.",3
Finance,Accounting reform,"Accounting reform is an expansion of accounting rules that goes beyond financial measures for both individual economic entities and national economies.  It is advocated by those who consider the focus of the current standards and practices wholly inadequate to the task of measuring and reporting the activity, success, and failure of the modern enterprise, including government.
The real debate concerns concepts such as whether to report transactions, such as asset acquisitions, at their cost or their current market values. The former, traditional approach, appeals for its reliability but can quickly lose its relevance due to inflation and other factors; the latter, an increasingly common approach, is appealing for its relevance but is less reliable due to the need to use subjective measures. Accounting standards setters such as the International Accounting Standards Board attempt to balance relevance and reliability.",3
Finance,Expected commercial value,"Expected commercial value (ECV; also Estimated commercial value) 

is a prospect-weighted value for a ""project"" with unclear conclusions; it is similar to expected net existing value (ENPV). 
In general ECV is used as a supplementary capital budgeting technique, in that it allows an analyst to compare each project's expected value against its net present value as usually calculated, i.e. using planned and contracted costs.
The company can thereby maximize the value and worth of its portfolio of projects, while working within its budget constraints.
As with ENPV, developments are defined to represent different project outcomes, with each scenario being assigned a possibility. A project value is computed for each scenario, and the expected commercial value is obtained by multiplying each situation's value by the scenario odds and adding the results.  
Depending on the procedures used to estimate the value of the project under each scenario, ECV can be a useful way to address project uncertainties. However, as indicated below, the technique often involves explanations that may or may not be appropriate.
Several techniques are used to estimate the probabilities and cashflows of the scenarios; often, the project may be broken down into stages which are represented in a decision tree. In reality, technical and commercial successes are not definite outcomes. There are changeable degrees of technical success and, assuming the product is launched, commercial sales could be anywhere within a variety of possibilities. Still, depending on the assertion, the simple formula may provide a satisfactory calculation. More generally, because ECV is a simplified version of ENPV, it has the limitations of the more general approach (including omission of non-financial sources of project value, and the potential for insufficient treatment of risk).",3
Finance,Tredefina,"Treuhandverwaltung für das Deutsch-Niederländische Finanzabkommen GmbH (Tredefina) was a public law institution originally formed in 1920 by the Weimar Republic which during the Nazi occupation of Europe was used by CEO Alexander Kreuter to purchase Aryanized companies. Originally created to administer a revolving loan from the Netherlands of 140 million Dutch guilders, Tredefina remained active until the early 21st century.",3
Finance,Quantitative analyst,"Quantitative analysis is the use of mathematical and statistical methods in finance and investment management. Those working in the field are quantitative analysts (quants). Quants tend to specialize in specific areas which may include derivative structuring or pricing, risk management, algorithmic trading and investment management. The occupation is similar to those in industrial mathematics in other industries. The process usually consists of searching vast databases for patterns, such as correlations among liquid assets or price-movement patterns (trend following or mean reversion). The resulting strategies may involve high-frequency trading. 
Although the original quantitative analysts were ""sell side quants"" from market maker firms, concerned with derivatives pricing and risk management, the meaning of the term has expanded over time to include those individuals involved in almost any application of mathematical finance, including the buy side. Applied quantitative analysis is commonly associated with quantitative investment management which includes a variety of methods such as statistical arbitrage, algorithmic trading and electronic trading.
Some of the larger investment managers using quantitative analysis include Renaissance Technologies, D. E. Shaw & Co., and AQR Capital Management.

",3
Finance,Capital appreciation,"Capital appreciation is an increase in the price or value of assets. It may refer to appreciation of company stocks or bonds held by an investor, an increase in land valuation,  or other upward revaluation of fixed assets.
Capital appreciation may occur passively and gradually, without the investor taking any action. It is distinguished from a capital gain which is the profit achieved by selling an asset. Capital appreciation may or may not be shown in financial statements; if it is shown, by revaluation of the asset, the increase is said to be ""recognized"". Once the asset is sold, the appreciation since the date of initially buying the asset becomes a ""realized"" gain.
When the term is used in reference to stock valuation, capital appreciation is the goal of an investor seeking long term growth. It is growth in the principal amount invested, but not necessarily an increase in the current income from the asset.
In the context of investment in a mutual fund, capital appreciation refers to a rise in the value of the securities in a portfolio which contributes to the growth in net asset value. A capital appreciation fund is a fund for which it is its primary goal, and accordingly invests in growth stocks.

",3
Finance,Mark to model,"Mark-to-Model refers to the practice of pricing a position or portfolio at prices determined by financial models, in contrast to allowing the market to determine the price. Often the use of models is necessary where a market for the financial product is not available, such as with 
complex financial instruments. One shortcoming of Mark-to-Model is that it gives an artificial illusion of liquidity, and the actual price of the product depends on the accuracy of the financial models
used to estimate the price.

On the other hand it is argued that Asset managers and Custodians have a real problem valuing illiquid assets in their portfolios even though many of these assets are perfectly sound and the asset manager has no intention of selling them. Assets should be valued at mark to market prices as required by the Basel rules. However mark to market prices should not be used in isolation, but rather compared to model prices to test their validity. Models should be improved to take into account the greater amount of market data available. New methods and new data are available to help improve models and these should be used. In the end all prices start off from a model.",3
Finance,Outline of accounting,"The following outline is provided as an overview of and topical guide to accounting:
Accounting – measurement, statement or provision of assurance about financial information primarily used by managers, investors, tax authorities and other decision makers to make resource allocation decisions within companies, organizations, and public agencies. The terms derive from the use of financial accounts.",3
Finance,Mid-year adjustment,"Valuation using discounted cash flows (DCF valuation) is a method of estimating the current value of a company based on projected future cash flows adjusted for the time value of money.
The cash flows are made up of those within the “explicit” forecast period, together with a continuing or terminal value that represents the cash flow stream after the forecast period.
In several contexts, DCF valuation is referred to as the ""income approach"".
Discounted cash flow valuation was used in industry as early as the 1700s or 1800s; it was explicated by John Burr Williams in his The Theory of Investment Value in 1938; it was widely discussed in financial economics in the 1960s; and became widely used in U.S. courts in the 1980s and 1990s.
This article details the mechanics of the valuation, via a worked example, including modifications typical for startups, private equity and venture capital, corporate finance ""projects"", and mergers and acquisitions.
See Discounted cash flow for further discussion, and Valuation (finance) § Valuation overview for context.",3
Finance,Public Financial Management,"Public Financial Management (PFM), provides a framework for parliamentary authorisation and scrutiny of the Government's expenditure proposals and the Government's management of its assets and liabilities, including:
establish lines of responsibility for effective and efficient management and use of public financial resources
specify the principles for responsible fiscal management in the conduct of fiscal policy and require regular reporting on the extent to which the Government's fiscal policy is consistent with those principles
specify the minimum financial and non-financial reporting obligations of Ministers, departments, Offices of Parliament and certain other agencies
provide for the application of financial management incentives and for the accountability of specified central government organisations
safeguard public assets by providing statutory authority and control for the borrowing of money, issuing of securities, use of derivative transactions, investment of funds, operation of bank accounts and giving of guarantees and indemnitiesPublic sector performance management approach emphasises, among other things, clear objectives and clear lines of responsibility, greater freedom to manage, and a corresponding expectation of greater accountability for results. Such a system requires good measures of performance that interested external parties can trust. This requires that public sector entities to prepare financial information that:
uses accrual accounting concepts and statements
is in accordance with financial reporting standards approved by an independent standard setter, and
in the case of annual financial statements, complies with generally accepted accounting practice (IPSASB) and is audited by an independent auditor.",3
Finance,Intellectual property valuation,"Valuation is considered one of the most critical areas in finance; it plays a key role in many areas of finance such as buy/sell, solvency, merger and acquisition.",3
Finance,Channel check,"In financial analysis, a channel check is third-party research on a company's business based on collecting information from the distribution channels of the company. It may be conducted in order to value the company, to perform due diligence in various contexts, and the like. Industries where channel checks are more often conducted include retail, technology, commodities, etc.
It is a practice performed by third party researchers and financial analysts in order to collect information about a company's business. The Channel Check process includes interviewing people within other organizations connected to the company's supply and distribution channels. These interviews usually occur without the target company's knowledge. For example, a channel check could include one or multiple conversations with a store manager to understand their targeted customer. Analysts generally look for top products, customer buying patterns and past performance.
Analysts could also contact one or several suppliers or vendors to obtain information about the targeted company. In these interviews analysts are looking for quantity of materials being demanded and prices. Suppliers could also help Analysts to see the “Bigger Picture” of a company's production plans, new products and more. Suppliers may also give an indication of the raw material availability, finished product inventory levels, promotion plans to the Analysts.
Channel checks can give insights complementary to balance sheet analysis, such as distributor and retailer attitudes towards a product and its competitors, seasonal and geographic variation, inventory levels (notably channel stuffing), and so on.",3
Finance,Depreciation (economics),"In economics, depreciation is the gradual decrease in the economic value of the capital stock of a firm, nation or other entity, either through physical depreciation, obsolescence or changes in the demand for the services of the capital in question. If the capital stock is 
  
    
      
        
          K
          
            t
          
        
      
    
    {\displaystyle K_{t}}
   in one period 
  
    
      
        t
      
    
    {\displaystyle t}
  , gross (total)  investment spending on newly produced capital is 
  
    
      
        
          I
          
            t
          
        
      
    
    {\displaystyle I_{t}}
   and depreciation is 
  
    
      
        
          D
          
            t
          
        
      
    
    {\displaystyle D_{t}}
  , the capital stock in the next period, 
  
    
      
        
          K
          
            t
            +
            1
          
        
      
    
    {\displaystyle K_{t+1}}
  , is 
  
    
      
        
          K
          
            t
          
        
        +
        
          I
          
            t
          
        
        −
        
          D
          
            t
          
        
      
    
    {\displaystyle K_{t}+I_{t}-D_{t}}
  . The net increment to the capital stock is the difference between gross investment and depreciation, and is called net investment.",3
Finance,The Theory of Investment Value,"John Burr Williams (November 27, 1900 – September 15, 1989) was an American economist, recognized as an important figure in the field of fundamental analysis, and for his analysis of stock prices as reflecting their ""intrinsic value"".He is best known for his 1938 text The Theory of Investment Value, based on his PhD thesis, in which he articulated the theory of discounted cash flow (DCF) based valuation, and in particular, dividend based valuation.

",3
Finance,DIRTI 5,"In accounting and economics the DIRTI 5 is an acronym for ""Depreciation, Interest, Repairs, Taxes, and Insurance"". Total fixed cost includes the DIRTI 5, which are unavoidable for any capital asset of significant value.",3
Finance,Designated Professional Body,"According to the  UK Financial Conduct Authority  (FCA), a dedicated professional body is one designated by the Treasury under section 326 of the Act (Designation of professional bodies) for the purposes of the Act (Provision of Financial Services by Members of the Professions).
The following professional bodies have been designated in the Financial Services and Markets Act 2000 (Designated Professional Bodies) Order 2001 (SI 2001/1226), the Financial Services and Markets Act 2000 (Designated Professional Bodies) (Amendment) Order 2004 (SI 2004/3352) and the Financial Services and Markets Act 2000 (Designated Professional Bodies) (Amendment) Order 2006 (SI 2006/58):

The Law Society of England & Wales;
The Law Society of Scotland;
The Law Society of Northern Ireland;
The Institute of Chartered Accountants in England and Wales;
The Institute of Chartered Accountants of Scotland;
The Institute of Chartered Accountants in Ireland;
The Association of Chartered Certified Accountants;
The Institute of Actuaries;
The Council for Licensed Conveyancers; and
The Royal Institution of Chartered Surveyors.Under Section 325(4) of the FSMA, Designated Professional Bodies are required to cooperate with the FCA in a number of ways, including information sharing, in order for the FCA to be able to perform its functions.",3
Finance,Residual income valuation,"Residual income valuation (RIV; also, residual income model and residual income method, RIM) is an approach to equity valuation that formally accounts for the cost of equity capital.  Here, ""residual"" means in excess of any opportunity costs measured relative to the book value of shareholders' equity; residual income (RI) is then the income generated by a firm after accounting for the true cost of capital. The approach is largely analogous to the EVA/MVA based approach, with similar logic and advantages. Residual Income valuation has its origins in Edwards & Bell (1961), Peasnell (1982), and Ohlson (1995).

",3
Finance,Accretion/dilution analysis,"Accretion/dilution analysis is a type of M&A financial modelling performed in the pre-deal phase to evaluate the effect of the transaction on shareholder value and to check whether EPS for buying shareholders will increase or decrease post-deal. Generally, shareholders do not prefer dilutive transactions; however, if the deal may generate enough value to become 
 accretive in a reasonable time, a proposed combination is justified. 
Aside is a simplified example. A real-life accretion/dilution analysis may be much more complex if the deal is structured as cash-and-stock-for-stock, if preferred shares and dilutive instruments are involved, if debt and transaction fees are substantial, and so on. Generally, if the buying company has a higher P/E multiple than that of the target, the deal is likely to be accretive. The reverse is true for a dilutive transaction.

",3
Finance,Risk assurance,"Risk assurance is often associated with accounting practices and is a growing industry whereby internal processes are developed to create a ""checks and balances"" system. These checks predominantly identify differences between risk appetite and real risk .Business risk refers to factors that can affect the company, both internally and externally. There are various types of business risks: strategic, compliance, financial and operational.  Risk assurance aims to mitigate any of these areas. As such, companies can pre-analyse the industry to scout for potential risks or if a risk has already occurred, managers can analyse the problem in an attempt to mitigate the effects. 
Risk assurance involves tiers of internal processes including management and internal controls, financial control and security, inspection, compliance, internal audit and leadership teams that are aware of the companies internal and external risks. Following internal processes, assurance requires an external audit team who examines the internal processes effectiveness and reports to senior management with successes and areas for redevelopment.Auditors in risk assurance auditing filter information technology general controls (ITGCs) and completing a system and organisation control (SOC 1) report.Internal control is a large component of risk assurance whereby an entity's management design processes to provide reasonable assurance regarding the achievement of operational objectives, reporting and compliance. 
Internal control's 5 components include:
1.     Control environment
2.     Risk assessment
3.     Control activities
4.     Information and communication
5.     Monitoring activitiesPhysical internal control are accounting procedures that prevent fraud and ensure operational efficiency such as CCTV, passwords, and security locks. Internal audits are another internal control and play a role in corporate governance. These audits evaluate the effectiveness of a businesses' internal control. Another internal control is having different employees delegated to different tasks in a transaction.",3
Finance,Unicorn (finance),"In business, a unicorn is a privately held startup company valued at over US$1 billion.: 1270  The term was first popularised in 2013 by venture capitalist Aileen Lee, choosing the mythical animal to represent the statistical rarity of such successful ventures.According to CB Insights, there are more than 803 unicorns as of August 2021. The largest unicorns included ByteDance, SpaceX and Stripe. Also according to CB Insights, there are now 30 unicorns with over $10 billion valuation in the world, including SpaceX, Getir, Goto, J&T Express, Stripe, and Klarna. They have been given the name ""decacorn"".

",3
Finance,International Ethics Standards Board for Accountants,The International Ethics Standards Board for Accountants (IESBA) develops and promotes the International Code of Ethics for Professional Accountants (including International Independence Standards). The IESBA also supports debate on issues related to accounting ethics and auditor independence.,3
Finance,Equivalence number method,"The equivalence number method is a cost calculation method for co-production in cost and activity accounting. The resulting costs of the input factors are allocated to the individual products according to a weighting key, the so-called equivalence numbers.",3
Finance,Contingent value rights,"In corporate finance, 
Contingent Value Rights (CVR) are rights granted by an acquirer to a company’s shareholders,  facilitating the transaction where some uncertainty is inherent.
CVRs may be separately tradeable  securities; they are occasionally acquired (or shorted) by specialized hedge funds.",3
Finance,Cyclically adjusted price-to-earnings ratio,"The price-earnings ratio, also known as P/E ratio, P/E, or PER, is the ratio of a company's share (stock) price to the company's earnings per share. The ratio is used for valuing companies and to find out whether they are overvalued or undervalued. 

  
    
      
        P
        
          /
        
        E
        =
        
          
            Share Price
            Earnings per Share
          
        
      
    
    {\displaystyle P/E={\frac {\text{Share Price}}{\text{Earnings per Share}}}}
  As an example, if share A is trading at $24 and the earnings per share for the most recent 12-month period is $3, then share A has a P/E ratio of $24/($3 per year) = 8. Put another way, the purchaser of the share is investing $8 for every dollar of annual earnings; or, if earnings stayed constant it would take 8 years to recoup the share price. Companies with losses (negative earnings) or no profit have an undefined P/E ratio (usually shown as ""not applicable"" or ""N/A""); sometimes, however, a negative P/E ratio may be shown.",3
Finance,Morningstar Rating for Funds,"The Morningstar Rating for Funds, or the Star Rating, debuted in 1985, a year after Morningstar was founded. The 1- to 5-star system, ""looks at a fund's risk-adjusted return based on its performance over three, five and 10 years and on its volatility. The highest rating of five stars is bestowed on the 10 percent of funds that perform the best."" Funds need to be at least three years old to be rated.
Originally, funds were compared in four broad asset classes until the ratings methodology was revised in 2002 to rank and rate funds in 50 categories.  In 2006, the Morningstar Rating was applied to exchange-traded funds.",3
Finance,OpenTuition,"OpenTuition.com is an online learning site, providing free online training in accountancy and financial services. Founded by John Moffat in 2008, it is based in Riga, Latvia.
OpenTuition has over 500,000 registered students both in the UK and overseas who are studying for the professional accountancy qualifications:  ACCA,  CIMA  and AAT.OpenTuition publishes free electronic text books and streams free lectures for the following ACCA examinations: Fundamental Level: BT  Business and Technology, MA Management Accounting, FA Financial Accounting, LW Corporate and Business Law, PM Performance Management, TX Taxation, FR Financial Reporting, AA Audit and Assurance, and FM Financial Management.
The Professional level: Essentials (compulsory) exams: SBL Strategic Business Leader; SBR Strategic Business Reporting; Options (two papers required): AFM Advanced Financial Management; APM Advanced Performance Management; ATX Advanced Taxation; AAA Advanced Audit and Assurance.
OpenTuition is a registered CIMA tuition provider, free e-books, tests and lectures are published for the CIMA Certificate in Business Accounting and CIMA Professional Qualification.
OpenTuition study resources include such subjects as: financial accounting, management accounting, financial reporting, taxation, company law, audit and assurance and financial management.
OpenTuition have discussion forums for all ACCA papers, OBU, CIMA, FIA, AAT and others.
OpenTuition received international recognition among accountancy professionals in London, winning two prizes, the first in 2010 as the best accountancy learning site and in 2011 for the best accountancy study resource.

",3
Finance,Valuation risk,"Valuation risk is the risk that an entity suffers a loss when trading an asset or a liability due to a difference between the accounting value and the price effectively obtained in the trade. 
In other words, valuation risk is the uncertainty about the difference between the value reported in the balance sheet for an asset or a liability and the price that the entity could obtain if it effectively sold the asset or transferred the liability (the so-called “exit price”). 
This risk is especially significant for financial instruments with complex features and limited liquidity, that are valued using internally developed pricing models. Valuation errors can result for instance from missing consideration of risk factors, inaccurate modeling of risk factors, or inaccurate modeling of the sensitivity of instrument prices to risk factors. Errors are more likely when models use inputs that are unobservable or for which little information is available, and when financial instruments are illiquid so that the accuracy of pricing models cannot be verified with regular market trades.",3
Finance,Convention of conservatism,"In  accounting, the convention of conservatism, also known as the doctrine of prudence, is a policy of anticipating possible future losses but not future gains. This policy tends to understate rather than overstate net assets and net income, and therefore lead companies to ""play safe"". When given a choice between several outcomes where the probabilities of occurrence are equally likely, you should recognize that transaction resulting in the lower amount of profit, or at least the deferral of a profit.In accounting, it states that when choosing between two solutions, the one that will be least likely to overstate assets and income should be selected. Essentially, ""expected losses are losses but expected gains are not gains"".
The conservatism principle is the foundation for the lower of cost or market rule, which states that you should record inventory at the lower of either its acquisition cost or its current market value.
Conservatism plays an important role in a number of accounting rules, including the allowance for doubtful debts and the lower of cost or market rule.",3
Finance,Public sector net worth,"The change in public sector net worth in any given forecast year is largely driven by the operating balance and property, plant and equipment revaluations.Research suggests that the main fiscal factor driving bond yields hence appears to be government net worth.Focusing on net worth as the most comprehensive measure of fiscal position incentivizes the public sector to invest the proceeds of borrowing in productive investments rather than use debt to finance consumption spending. Net worth also provides a tool for assessing whether government policy is fair to future generations from a financial point of view; negative, or declining, net worth indicates that past or present consumption will need to be funded by future taxation.

",3
Finance,Cash value added,"Cash value added (CVA) is a measure of business profitability defined as the EBITDA generated by the business, less tax, less its required return. 
The required return is an annuity based on the purchase price of the assets in use in the business, inflated to today's value of money, the weighted average cost of capital (WACC) and the economic life of the assets.
CVA can also be expressed as an index, where the CVA is divided by the required return. An index of more than 1.0 will indicate profitability while an index below 1.0 will indicate value destruction.",3
Finance,Fair value,"In accounting and in most schools of economic thought, fair value is a rational and unbiased estimate of the potential market price of a good, service, or asset. The derivation takes into account such objective factors as the costs associated with production or replacement, market conditions and matters of supply and demand.  Subjective factors may also be considered such as the risk characteristics, the cost of and return on capital, and individually perceived utility.",3
Finance,Stock valuation,"In financial markets, stock valuation is the method of calculating theoretical values of companies and their stocks. The main use of these methods is to predict future market prices, or more generally, potential market prices, and thus to profit from price movement – stocks that are judged undervalued (with respect to their theoretical value) are bought, while stocks that are judged overvalued are sold, in the expectation that undervalued stocks will overall rise in value, while overvalued stocks will generally decrease in value.
In the view of fundamental analysis, stock valuation based on fundamentals aims to give an estimate of the intrinsic value of a stock, based on predictions of the future cash flows and profitability of the business. Fundamental analysis may be replaced or augmented by market criteria – what the market will pay for the stock, disregarding intrinsic value. These can be combined as ""predictions of future cash flows/profits (fundamental)"", together with ""what will the market pay for these profits?"" These can be seen as ""supply and demand"" sides – what underlies the supply (of stock), and what drives the (market) demand for stock?
Stock valuation is distinct from business valuation, which is about calculating the economic value of an owner's interest in a business, used to determine the price interested parties would be willing to pay or receive to effect a sale of the business.
Re. valuation in cases where both parties are corporations, see under Mergers and acquisitions and Corporate finance.",3
Finance,Paper valuation,"Paper Valuation is the value of privately held shares that is not directly tradeable at an exchange.
This notional value, though, is as yet untested on real buyers. 
The opposite of paper value is exchangeable value, and is the value that is directly monetizable as long as there is a willing buyer and a willing seller.
Thus, if the aside exchange was made as an ""Exchange Valuation"" this new company valuation would be tradeable directly on the stock exchange. One problem with Paper Valuation is that is not that easy to monetize in a short time period.
This valuation concept is a cornerstone in the stock exchange world. Value exchange is paramount to its existence.",3
Finance,Public Wealth Fund,"A sovereign wealth fund (SWF), sovereign investment fund, or social wealth fund is a state-owned investment fund that invests in real and financial assets such as stocks, bonds, real estate, precious metals, or in alternative investments such as private equity fund or hedge funds. Sovereign wealth funds invest globally. Most SWFs are funded by revenues from commodity exports or from foreign-exchange reserves held by the central bank.  
Some sovereign wealth funds may be held by a central bank, which accumulates the funds in the course of its management of a nation's banking system; this type of fund is usually of major economic and fiscal importance.  Other sovereign wealth funds are simply the state savings that are invested by various entities for the purposes of investment return, and that may not have a significant role in fiscal management.
The accumulated funds may have their origin in, or may represent, foreign currency deposits, gold, special drawing rights (SDRs) and International Monetary Fund (IMF) reserve positions held by central banks and monetary authorities, along with other national assets such as pension investments, oil funds, or other industrial and financial holdings. These are assets of the sovereign nations that are typically held in domestic and different reserve currencies (such as the dollar, euro, pound, and yen). Such investment management entities may be set up as official investment companies, state pension funds, or sovereign funds, among others.
There have been attempts to distinguish funds held by sovereign entities from foreign-exchange reserves held by central banks. Sovereign wealth funds can be characterized as maximizing long-term return, with foreign exchange reserves serving short-term ""currency stabilization"", and liquidity management. Many central banks in recent years possess reserves massively in excess of needs for liquidity or foreign exchange management.  Moreover, it is widely believed most have diversified hugely into assets other than short-term, highly liquid monetary ones, though almost no data is publicly available to back up this assertion.

",3
Finance,Bal Krishen Rathore,"Bal Krishen Rathore is a UAE based businessman, investor and entrepreneur of Indian origin and the Chairman and CEO of Century Financial. He was listed in the top 100 inspiring leaders in the UAE by Arabian Business. He has been granted the Golden Visa by the government of UAE in 2021.

",3
Finance,Flotation cost,"Flotation cost is the total cost incurred by a company in offering its securities to the public. They arise from expenses such as underwriting fees, legal fees and registration fees. Firms are well advised to consider the magnitude of these fees as they also impact how much capital they can raise from an initial public offering. The more is the flotation cost the less viable is the source.",3
Finance,Value added,"A value-added tax (VAT), known in some countries as a goods and services tax (GST), is a type of tax that is assessed incrementally. It is levied on the price of a product or service at each stage of production, distribution, or sale to the end consumer. If the ultimate consumer is a business that collects and pays to the government VAT on its products or services, it can reclaim the tax paid. It is similar to, and is often compared with, a sales tax. VAT is an indirect tax because the person who ultimately pays the tax is not necessarily the same person as the one who pays the tax to the tax authorities.
VAT essentially compensates for the shared service and infrastructure provided in a certain locality by a state and funded by its taxpayers that were used in the provision of that product or service. Not all localities require VAT to be charged, and exports are often exempt. VAT is usually implemented as a destination-based tax, where the tax rate is based on the location of the consumer and applied to the sales price. The terms VAT, GST, and the more general consumption tax are sometimes used interchangeably. VAT raises about a fifth of total tax revenues both worldwide and among the members of the Organisation for Economic Co-operation and Development (OECD).: 14  As of 2018, 166 of the 193 countries with full UN membership employ a VAT, including all OECD members except the United States,: 14  where many states use a sales tax system instead.
There are two main methods of calculating VAT: the credit-invoice or invoice-based method and the subtraction or accounts-based method. In the credit-invoice method, sales transactions are taxed, the customer is informed of the VAT on the transaction, and businesses may receive a credit for the VAT paid on input materials and services. The credit-invoice method is by far the more common and is used by all national VATs except for Japan. In the subtraction method, a business at the end of a reporting period, calculates the value of all taxable sales, subtracts the sum of all taxable purchases, and applies the VAT rate to the difference. The subtraction method VAT is currently used only by Japan although it, often by using the name ""flat tax,"" has been part of many recent tax reform proposals by US politicians. With both methods, there are exceptions in the calculation method for certain goods and transactions that are created to help collection or to counter tax fraud and evasion.",3
Finance,Income approach,"The income approach is one of three major groups of methodologies, called valuation approaches, used by appraisers. It is particularly common in commercial real estate appraisal and in business appraisal. The fundamental math is similar to the methods used for financial valuation, securities analysis, or bond pricing. However, there are some significant and important modifications when used in real estate or business valuation.
While there are quite a few acceptable methods under the rubric of the income approach, most of these methods fall into three categories: direct capitalization, discounted cash flow, and gross income multiplier.",3
Finance,Public sector balance sheet,"A Public Sector Balance Sheet, like a balance sheet in the corporate world, reports comprehensively on what a government owns and owes, as well as its own capital. As such, it is a critical element of a system of Public Financial Management. A balance sheet, or statement of financial position, recognises and discloses the assets, liabilities, and net worth at a given point in time, for a government entity, a government or the whole public sector. An important metric for the fiscal position of the whole public sector is public sector net worth.
For a government at any level, local, regional or national, the balance sheet offers greater fiscal transparency, being more comprehensive than the conventional metrics of debt and deficits. 
The quality of the financial statements depends on the quality of data used and what basis of accounting is used to compose the balance sheet and the other financial statements.
Willem Buiter and the IMF argued in 1983 for the use of public sector balance sheets to improve public financial management.Following a financial crisis, the New Zealand government passed its Public Finance Act (PFA) in 1989, introducing accrual budgeting, appropriations and accounting, publishing the world's first public sector balance sheet based on audited accounting records rather than statistical estimates.The IMF shifted its Government Finance Statistics Manual from a cash to an accrual basis in 2001. It is more recently emphasising the importance of government balance sheets on a global basis, albeit using statistical rather than accounting data.IFAC and CIPFA predict that in 2025, almost half the world's governments will adopt accrual-based accounting.  Far fewer, however, will be using accrual information at the heart of their financial management and budget systems. For example, the UK's Whole of Government Accounts, which reports its public sector real estate assets, does not have a mandate to assign a fair market value to the assets, and its financial management framework pays very little attention to net worth creation.The use of proper public sector balance sheets rests upon the use of accrual accounting throughout the public financial management system, making it integral to financial and budgetary decision-making.
Level 1
At level 1, governments focus their financial decision-making and reporting almost entirely on cash flows and levels of debt, though information on debt is usually constrained to the nominal value of the debt. This results in assets, especially non-financial assets, being poorly managed, along with insurance obligations.
Level 2
At level 2, budgeting and appropriations focus on cash flows, while ex post reporting covers the full spectrum of assets and liabilities. Because decision-making within the budgeting system does not utilize accrual information, it is sub-optimal. While transparency is improved with accrual reporting, the failure to use the information for management purposes reduces both its value and the incentives to produce it in a timely manner.
Level 3
At level 3, financial decision-making utilizes a more comprehensive set of information and should result in greater attention being placed on asset utilization and management, and on the incurrence and management of non-debt liabilities. However, because the appropriations, which are legally binding, are cash measures, there remain strong incentives to focus on cash flows in management decision-making and control.
Level 4
At level 4, the financial system is fully based on a comprehensive set of information covering all assets and liabilities, revenues, and expenses. This enables better informed decision-making that reflects all resources and flows, including cash flows. The measures, signals and incentives generated by the system are consistent in encouraging optimal use of all resources.",3
Finance,Cann v Willson,"Cann v Willson (1888) 39 Ch D 39, is an English tort law case, concerning negligent valuation.",3
Finance,Economic value added,"In corporate finance, as part of fundamental analysis, economic value added is an estimate of a firm's economic profit, or the value created in excess of the required return of the company's shareholders. EVA is the net profit less the capital charge ($) for raising the firm's capital. The idea is that value is created when the return on the firm's economic capital employed exceeds the cost of that capital. This amount can be determined by making adjustments to GAAP accounting. There are potentially over 160 adjustments but in practice, only several key ones are made, depending on the company and its industry.

",3
Finance,EV/Ebitda,"Enterprise value/EBITDA (more commonly referred to by the acronym EV/EBITDA) is a popular valuation multiple used to determine the fair market value of a company. By contrast to the more widely available P/E ratio (price-earnings ratio) it includes debt as part of the value of the company in the numerator and excludes costs such as the need to replace depreciating plant, interest on debt, and taxes owed from the earnings or denominator. It is the most widely used valuation multiple based on  enterprise value and is often used as an alternative to the P/E ratio when valuing companies believed to be in a high-growth phase, and thus credits enterprises with higher startup costs, high debt relative to equity, and lower realised earnings.

",3
Finance,Relative valuation,"Relative valuation also called valuation using multiples is the notion of comparing the price of an asset to the market value of similar assets. In the field of securities investment, the idea has led to important practical tools, which could presumably spot pricing anomalies. These tools have subsequently become instrumental in enabling analysts and investors to make vital decisions on asset allocation.",3
Finance,Financial Modeling World Cup,"The Financial Modeling World Cup (FMWC) is a financial modeling competition. The competition was started in September 2020. Contestants solve real-life financial problems, in the form of case studies, by building financial models in Microsoft Excel spreadsheet software. Stages held through the year contribute to a global leaderboard. The event is sponsored by financial services firm AG Capital and Microsoft.",3
Finance,Value date,"Value date, in finance, is the date when the value of an asset that fluctuates in price is determined. The value date is used when there is a possibility for discrepancies due to differences in the timing of asset valuation. It usually applies to forward currency contracts, options and other derivatives, interest payable or receivable.
The value date can also mean:

the date when the entry to an account is considered effective in accounting.
the delivery date of funds traded in banking. For spot transactions it is the future date on which the trade is settled. In the case of a spot foreign exchange trade it is normally two days after a transaction is agreed upon.
the date the tax payment would coincide with the payment date in online banking, and retail payment gateways online.",3
Finance,Multilateral exchange,"A multilateral exchange is a transaction, or forum for transactions, which involve more than two parties.
For example, Alice gives Bob an apple in exchange for an orange, that is a bilateral exchange.
A multilateral exchange would involve a third party, for example:
Alice gives an apple to Bob who gives an orange to Charles, who gives a pear to Alice.
In the real world, such transactions are spread over time, and involved items of different values, and involve many more parties. A special type of accounting is used for this, called mutual credit, or credit clearing.",3
Finance,Approved Publication Arrangement,"With MiFID II directive being in force in January 2018, Approved Publication Arrangements (APA) data should  increase transparency in the OTC markets by publishing quotes for pre-trade transparency, and trades for post-trade transparency. An APA is an organisation authorised to publish trade reports on behalf of investment firms according to Article (4)(1)(52) MiFID II.In finance, people usually use APA to refer to the data they provide, and not only the organization which provides the data.",3
Finance,Investment theory,"Parental investment, in evolutionary biology and evolutionary psychology, is any parental expenditure (e.g. time, energy, resources) that benefits offspring. Parental investment may be performed by both males and females (biparental care), females alone (exclusive maternal care) or males alone (exclusive paternal care). Care can be provided at any stage of the offspring's life, from pre-natal (e.g. egg guarding and incubation in birds, and placental nourishment in mammals) to post-natal (e.g. food provisioning and protection of offspring).
Parental investment theory, a term coined by Robert Trivers in 1972, predicts that the sex that invests more in its offspring will be more selective when choosing a mate, and the less-investing sex will have intra-sexual competition for access to mates. This theory has been influential in explaining sex differences in sexual selection and mate preferences, throughout the animal kingdom and in humans.",3
Finance,Post-money valuation,"Post-money valuation is a way of expressing the value of a company after an investment has been made. This value is equal to the sum of the pre-money valuation and the amount of new equity.These valuations are used to express how much ownership external investors, such as venture capitalists and angel investors, receive when they make a cash injection into a company.  The amount external investors invest into a company is equal to the company's post-money valuation multiplied by the fraction of the company those investors own after the investment. Equivalently, the implied post-money valuation is calculated as the dollar amount of investment divided by the equity stake gained in an investment.
More specifically, the post-money valuation of a financial investment deal is given by the formula 
  
    
      
        P
        M
        V
        =
        N
        ×
        P
      
    
    {\textstyle PMV=N\times P}
  , where PMV is the post-money valuation, N is the number of shares the company has after the investment, and P is the price per share at which the investment was made. This formula is similar to the market capitalization formula used to express the value of public companies.

",3
Finance,Piotroski F-score,"Piotroski F-score is a number between 0 and 9 which is used to assess strength of company's financial position. The score is used by financial investors in order to find the best value stocks (nine being the best). The score is named after Stanford accounting professor Joseph Piotroski.

",3
Finance,DreamAhead College Investment Plan,"DreamAhead College Investment Plan is a higher education savings program administered by the State of Washington. The plan was created in 2016 by the Washington State Legislature, and statutorily known as the Washington College Savings Plan (RCW 28B.95.032), and opened for nationwide participation in 2018. It is one of two 529 programs offered by the state, the other being the Guaranteed Education Tuition Program (known as GET), which is a prepaid program. The programs are supported by Washington College Savings Plans (WA529), a division of Washington Student Achievement Council.",3
Finance,Consignment,"Consignment involves selling one's personal goods (clothing, furniture, etc.) through a third-party vendor such as a consignment store or online thrift store. The owner of the goods pays the third-party a portion of the sale for facilitating the sale. Consignors maintain the rights to their property until the item is sold or abandoned. Many consignment shops and online consignment platforms have a set day limit before an item expires for sale (usually 60–90 days).
The consignment stock is stock legally owned by one party, but held by another, meaning that the risk and rewards regarding to the said stock remains with the first party while the second party is responsible for distribution or retail operations.The verb ""consign"" means ""to send"" and therefore the noun ""consignment"" means ""sending goods to another person"". In the case of ""retail consignment"" or ""sales consignment"" (often just referred to as a ""consignment""), goods are sent to the agent for the purpose of sale. The ownership of these goods remains with the sender. The agent sells the goods on behalf of the sender according to instructions. The sender of goods is known as the ""consignor"" and the agent entrusted with the custody and care of the goods is known as the ""consignee"".",3
Finance,German income approach,"The German income approach (German: Ertragswertverfahren, abbr. EWV) is the standard approach used in Germany for the valuing of property that produces  a stream of future cash flows.",3
Finance,Quantitative analysis (finance),"Quantitative analysis is the use of mathematical and statistical methods in finance and investment management. Those working in the field are quantitative analysts (quants). Quants tend to specialize in specific areas which may include derivative structuring or pricing, risk management, algorithmic trading and investment management. The occupation is similar to those in industrial mathematics in other industries. The process usually consists of searching vast databases for patterns, such as correlations among liquid assets or price-movement patterns (trend following or mean reversion). The resulting strategies may involve high-frequency trading. 
Although the original quantitative analysts were ""sell side quants"" from market maker firms, concerned with derivatives pricing and risk management, the meaning of the term has expanded over time to include those individuals involved in almost any application of mathematical finance, including the buy side. Applied quantitative analysis is commonly associated with quantitative investment management which includes a variety of methods such as statistical arbitrage, algorithmic trading and electronic trading.
Some of the larger investment managers using quantitative analysis include Renaissance Technologies, D. E. Shaw & Co., and AQR Capital Management.

",3
Finance,Fiscal pedaling,"Fiscal pedaling (a calque from Brazilian Portuguese: pedalada fiscal, or simply pedaladas) is a governmental creative accounting technique involving the use of state-owned banks to front funds required for paying general government obligations without officially declaring a loan, thus hiding these transfers from public scrutiny and delaying repayment from the Treasury to these banks.  As such it is a kind of ""overdraft"" implying a positive balance sheet that does not really exist.  Sometimes the term fiscal backpedaling is used.The term gained popularity with the Brazilian Presidential election of 2014, in which President Rousseff was reelected. She was later accused of fiscal pedaling during the campaign, for allowing this delay in repayment to government-owned banks by the Tesouro Nacional (Brazilian Treasury) which is also the entity which oversees these banks. Her opponents argued that this amounted to undeclared loans by these banks to the Treasury, which is prohibited by the Brazilian Constitution and a violation of the Fiscal Responsibility Law.  This led to the impeachment of Dilma Rousseff beginning in 2015 on multiple charges including fiscal pedaling, and her subsequent removal from office a year later..
One possible motivation for fiscal pedaling is political advantage, in that it permits a government to conceal the true extent of its fiscal obligations during a political campaign. President Rousseff's government was accused of using these accounting techniques during the bitterly fought campaign of 2014, with the funding thus obtained allegedly used to support programs for the poor, credits to farmers, and subsidies for low-income housing. Supporters claimed this was standard practice in Brazil and had been engaged in by previous Presidents, and that the opposition to her was purely political.",3
Finance,Par value,"In null-hypothesis significance testing, the p-value is the probability of obtaining test results at least as extreme as the result actually observed, under the assumption that the null hypothesis is correct. A very small p-value means that such an extreme observed outcome would be very unlikely under the null hypothesis. Reporting p-values of statistical tests is common practice in academic publications of many quantitative fields. Since the precise meaning of p-value is hard to grasp, misuse is widespread and has been a major topic in metascience.",3
Finance,Land value tax,"A land value tax (LVT) is a levy on the value of land without regard to buildings, personal property and other improvements. It is also known as a location value tax, a site valuation tax, split rate tax, or a site-value rating,
Land value taxes are generally favored by economists as they do not cause economic inefficiency, and reduce inequality. A land value tax is a progressive tax, in that the tax burden falls on land owners, because land ownership  is correlated with wealth and income. The land value tax has been referred to as ""the perfect tax"" and the economic efficiency of a land value tax has been accepted since the eighteenth century. Economists since Adam Smith and David Ricardo have advocated this tax because it does not hurt economic activity or discourage or subsidize development.
LVT is associated with Henry George, whose ideology became known as Georgism. George argued that taxing the land value is most logical source of public revenue because the supply of land is fixed and because public infrastructure improvements would be reflected in (and thus paid for) by increased land values.Land value taxation is currently implemented throughout Denmark, Estonia, Lithuania, Russia, Singapore, and Taiwan; it has also been applied to lesser extents in parts of Australia, Mexico (Mexicali), and the United States (e.g., Pennsylvania).",3
Finance,Sum of perpetuities method,"The sum of perpetuities method (SPM)   is a way of valuing a business assuming that investors discount the future earnings of a firm regardless of whether earnings are paid as dividends or retained.  SPM is an alternative to the Gordon growth model (GGM)  and can be applied to business or stock valuation if the business is assumed to have constant earnings and/or dividend growth.  The variables are:

  
    
      
        P
      
    
    {\displaystyle P}
   is the value of the stock or business

  
    
      
        E
      
    
    {\displaystyle E}
   is a company's earnings

  
    
      
        G
      
    
    {\displaystyle G}
   is the company's constant growth rate

  
    
      
        K
      
    
    {\displaystyle K}
   is the company's risk adjusted discount rate

  
    
      
        D
      
    
    {\displaystyle D}
   is the company's dividend payment
  
    
      
        P
        =
        (
        
          
            
              E
              ∗
              G
            
            
              K
              
                2
              
            
          
        
        )
        +
        (
        
          
            D
            K
          
        
        )
      
    
    {\displaystyle P=({\frac {E*G}{K^{2}}})+({\frac {D}{K}})}",3
Finance,Depreciation,"In several fields, especially computing, deprecation is the discouragement of use of some terminology, feature, design, or practice, typically because it has been superseded or is no longer considered efficient or safe, without completely removing it or prohibiting its use. Typically, deprecated materials are not completely removed to ensure legacy compatibility or back up practice in case new methods are not functional in an odd scenario.
It can also imply that a feature, design, or practice will be removed or discontinued entirely in the future.",3
Finance,Valuation using discounted cash flows,"Valuation using discounted cash flows (DCF valuation) is a method of estimating the current value of a company based on projected future cash flows adjusted for the time value of money.
The cash flows are made up of those within the “explicit” forecast period, together with a continuing or terminal value that represents the cash flow stream after the forecast period.
In several contexts, DCF valuation is referred to as the ""income approach"".
Discounted cash flow valuation was used in industry as early as the 1700s or 1800s; it was explicated by John Burr Williams in his The Theory of Investment Value in 1938; it was widely discussed in financial economics in the 1960s; and became widely used in U.S. courts in the 1980s and 1990s.
This article details the mechanics of the valuation, via a worked example, including modifications typical for startups, private equity and venture capital, corporate finance ""projects"", and mergers and acquisitions.
See Discounted cash flow for further discussion, and Valuation (finance) § Valuation overview for context.",3
Finance,Owner earnings,"Owner earnings is a valuation method detailed by Warren Buffett in Berkshire Hathaway's annual report in 1986. He stated that the value of a company is simply the total of the net cash flows (owner earnings) expected to occur over the life of the business, minus any reinvestment of earnings.Buffett defined owner earnings as follows:

""These represent (a) reported earnings plus (b) depreciation, depletion, amortization, and certain other non-cash charges ... less (c) the average annual amount of capitalized expenditures for plant and equipment, etc. that the business requires to fully maintain its long-term competitive position and its unit volume ... Our owner-earnings equation does not yield the deceptively precise figures provided by GAAP, since (c) must be a guess - and one sometimes very difficult to make. Despite this problem, we consider the owner earnings figure, not the GAAP figure, to be the relevant item for valuation purposes ... All of this points up the absurdity of the 'cash flow' numbers that are often set forth in Wall Street reports. These numbers routinely include (a) plus (b) - but do not subtract (c).""",3
Finance,Finnfund,"Finnfund, Finnish Fund for Industrial Cooperation Ltd  (in Finnish Teollisen yhteistyön rahasto Oy) is a Finnish development financier and impact investor, that offers long-term investment loans and venture capital to private companies for projects in developing countries. Finnfund’s statutory duty is to promote economic and social development in developing countries.",3
Finance,Shrinkage (accounting),"In accounting, inventory shrinkage (sometimes shortened to shrinkage or shrink) occurs when a retailer has fewer items in stock than in the inventory list due to clerical error, goods being damaged, lost, or stolen between the point of manufacture (or purchase from a supplier) and the point of sale. This affects profit: if shrinkage is large, profits decrease. This leads retailers to increase prices to make up for losses, passing the cost of shrinkage onto customers.In 2008, the retail industry in the United States experienced shrinkage rates of around 1.52% of sales. During the same year, retailers in Europe and Asia Pacific reported average shrinkage of about 1.27% and 1.20% of sales, respectively.",3
Finance,Trade exchange,"A local exchange trading system (also local employment and trading system or local energy transfer system; abbreviated LETS) is a locally initiated, democratically organised, not-for-profit community enterprise that provides a community information service and records transactions of members exchanging goods and services by using locally created currency. LETS allow people to negotiate the value of their own hours or services, and to keep wealth in the locality where it is created.Similar trading systems around the world are also known as Community Exchange Systems, Mutual Credit trading systems, Clearing Circles, Trade Exchanges or Time Banks. These all use 'metric currencies' – currencies that measure, as opposed to the fiat currencies used in conventional value exchange. These are all a type of alternative or complementary currency.In the 21st century, the internet-based networks haves been used to link individual LETS systems, into national or global networks.",3
Finance,Valuation using multiples,"In economics, valuation using multiples, or “relative valuation”, is a process that consists of:

identifying comparable assets (the peer group) and obtaining market values for these assets.
converting these market values into standardized values relative to a key statistic, since the absolute prices cannot be compared. This process of standardizing creates valuation multiples.
applying the valuation multiple to the key statistic of the asset being valued, controlling for any differences between asset and the peer group that might affect the multiple.Multiples analysis is one of the oldest methods of analysis.  It was well understood in the 1800s and widely used by U.S. courts during the 20th century, although it has recently declined as Discounted Cash Flow and more direct market-based methods have become more popular.
""Comparable company analysis"",  closely related, was introduced by economists at Harvard Business School in the 1930's.",3
Finance,Value investing,"Value investing is an investment paradigm that  involves buying securities that appear underpriced by some form of fundamental analysis. The various forms of value investing derive from the investment philosophy first taught by Benjamin Graham and David Dodd at Columbia Business School in 1928, and subsequently developed in their 1934 text Security Analysis.
The early value opportunities identified by Graham and Dodd included stock in public companies trading at discounts to book value or tangible book value, those with high dividend yields, and those having low price-to-earning multiples, or low price-to-book ratios.
High-profile proponents of value investing, including Berkshire Hathaway chairman Warren Buffett, have argued that the essence of value investing is buying stocks at less than their intrinsic value. The discount of the market price to the intrinsic value is what Benjamin Graham called the ""margin of safety"". For the last 25 years, under the influence of Charlie Munger, Buffett expanded the value investing concept with a focus on ""finding an outstanding company at a sensible price"" rather than generic companies at a bargain price. Hedge fund manager Seth Klarman has described value investing as rooted in a rejection of the efficient-market hypothesis (EMH). While the EMH proposes that securities are accurately priced based on all available data, value investing proposes that some equities are not accurately priced.Graham never used the phrase value investing – the term was coined later to help describe his ideas and has resulted in significant misinterpretation of his principles, the foremost being that Graham simply recommended cheap stocks. The Heilbrunn Center at Columbia Business School is the current home of the Value Investing Program.",3
Finance,Renting,"Renting, also known as hiring or letting, is an agreement where a payment is made for the temporary use of a good, service or property owned by another. A gross lease is when the tenant pays a flat rental amount and the landlord pays for all property charges regularly incurred by the ownership. An example of renting is equipment rental. Renting can be an example of the sharing economy.",3
Finance,Customer Profitability Analysis,"Customer Profitability Analysis (in short CPA) is a management accounting and a credit underwriting method, allowing businesses and lenders to determine the profitability of each customer or segments of customers, by attributing profits and costs to each customer separately. CPA can be applied at the individual customer level (more time consuming, but providing a better understanding of business situation) or at the level of customer aggregates / groups (e.g. grouped by number of transactions, revenues, average transaction size, time since starting business with the customer, distribution channels, etc.).
CPA is a ""retrospective"" method, which means it analyses past events of different customers, in order to calculate customer profitability for each customer. Equally, research suggests that that credit score does not necessarily impact the lenders' profitability.

",3
Finance,The Growth X,"The Growth X is commonly used to describe the pattern created when plotting the market value of a successful growth company against its relative valuation over time.  Early on in a company's life cycle (particularly with internet investments), companies can demand high valuations despite little or negative earnings.  When the company breaks even, its valuation seems inflated from a relative valuation standpoint (market value divided by the company's earnings, EBITDA, or cash flow).  Over time as the earnings power grows, the relative valuation begins to fall as earnings often growth faster than the market value (stock price).This pattern can be observed in most successful companies in recent history (AAPL, GOOG, FB).  The Growth X is commonly used among growth and venture capital investors, and is believed to be coined by Spencer Walsh and Vidur Singhal, two prominent Silicon Valley internet investors.Much like other technical indicators, The Growth X is often disputed and depends on a company's ability to continually grow earnings.  If investors bid up the market value of the company faster than the earnings growth rate, then The Growth X will not form, and the relative valuation will stay flat or continue to rise.  Eventually relative valuations fall as growth prospects diminish, but this can often occur quickly and cause a step function down in valuation multiples.",3
Finance,Project finance model,"A project finance model is a specialized financial model, the purpose of which is to assess the economic feasibility of the project in question. The model's output can also be used in structuring, or ""sculpting"", the project finance deal.
The context: project finance is the long-term financing of infrastructure and industrial projects based upon the projected cash flows of the project - rather than the balance sheets of its sponsors. The project is therefore only feasible when the project is capable of producing enough cash to cover all operating and debt-servicing expenses over the whole tenor of the debt. 
Most importantly, therefore, the model is used to determine the maximum amount of debt the project company (Special-purpose entity) can maintain - and the corresponding debt repayment profile; there are several related metrics here, the most important of which is arguably the Debt Service Coverage Ratio (DSCR).",3
Finance,Shadow banking in China,"Chinese shadow banking refers to underground financial activity that takes place outside of traditional banking regulations and systems. China has one of the largest shadow banking industries with approximately 40% of the country's outstanding loans tied up in shadow banking activities. Shadow banking in China arose after the People's Bank of China became the central bank in 1983. This encouraged commercial enterprises and private investors to place more of their money in financial products, causing the banking industry to grow.",3
Finance,Fed model,"The ""Fed model"" or ""Fed Stock Valuation Model"" (FSVM), is a disputed theory of equity valuation that compares the stock market's forward earnings yield to the nominal yield on long-term government bonds, and that the stock market – as a whole – is fairly valued, when the one-year forward-looking I/B/E/S earnings yield equals the 10-year nominal Treasury yield; deviations suggest over-or-under valuation.The relationship has only held in the United States, and only for two main periods: 1921 to 1928 and from 1987 to 2000.  It has been shown to be flawed on a theoretical basis, fails to hold in long-term analysis of data (both in the United States, and international markets), and has poor predictive power for future returns on a 1, 5 and 10-year basis. The relationship can breakdown completely at very low real yields (from natural forces, or where yields are artificially suppressed by quantitative easing); in such circumstances, without additional central bank support for the stock market (e.g. use of the Greenspan put by the Fed in 2020, or the Bank of Japan's purchase of equities post-2013), the relationship collapses.The Fed model is used by Wall Street sales desks as it almost always gives a ""buy signal"", and has rarely signaled stocks are overvalued.  Some academics say the relationship, when it appears, is driven by the allocation of the Fed's balance sheet to Wall Street banks via repurchase agreements as part of Fed put stimulus (i.e. the relationship reflects the investment strategy these banks follow using borrowed Fed funds when the Fed is stimulating asset prices, e.g. Wall Street banks lending to Long-Term Capital Management-type vehicles being a noted example).The term was coined in 1997–99 by Deutsche Bank analyst Dr. Edward Yardeni commenting on a report on the July 1997 Humphrey-Hawkins testimony by the then-Fed Chair, Alan Greenspan on equity valuations.  In 2014, Yardeni noted that the predictive power of the Fed model stopped working almost as soon as he noted the relationship. The term was never formally endorsed by the Fed, however, Greenspan made further references to the relationship.  In December 2020, the Fed Chair Jerome Powell, invoked the relationship to justify stock market valuations that were approaching levels not seen since the 1999–2000 Dot-com bubble or the 1929 market bubble, due to exceptional monetary looseness by the Fed.",3
Finance,Overtrading,"Overtrading is a term in financial statement analysis. Overtrading often occurs when companies expand their own operations too quickly (aggressively).  Overtraded companies enter a negative cycle, where an increase in interest expenses negatively impacts the net profit, which leads to lesser working capital, and that leads to increased borrowings, which in turn leads to interest expenses and the cycle continues.  Overtraded companies eventually face liquidity problems and can run out of working capital.",3
Finance,Non-financial asset,"A financial asset is a non-physical asset whose value is derived from a contractual claim, such as bank deposits, bonds, and participations in companies' share capital. Financial assets are usually more liquid than other tangible assets, such as commodities or real estate.The opposite of financial assets is non-financial assets, which include both tangible property (sometimes also called real assets) such as land, real estate or commodities, and intangible assets such as intellectual property, including copyrights, patents, trademarks and data.",3
Finance,Deprival value,"Deprival value 
is a concept used in accounting theory to determine the appropriate measurement basis for assets.  It is an alternative to historical cost and fair value or mark to market accounting.  Some writers prefer terms such as 'value to the owner' or 'value to the firm'.  Deprival value is also sometimes advocated for liabilities, in which case another term such as 'Relief value' may be used.
The deprival value of an asset is the extent to which the entity is ""better off"" because it holds the asset. This may be thought of as the answer to the following questions, all of which are equivalent: - What amount would just compensate the entity for the loss of the asset? - What loss would the entity sustain if deprived of the asset? - How much would the entity rationally pay to acquire the asset (if it did not already hold it)?",3
Finance,"Furniture, fixtures and equipment (accounting)","Furniture, fixtures, and equipment (or FF&E) (sometimes Furniture, furnishings, and equipment) is an accounting term used in valuing, selling, or liquidating a company or a building.
FF&E are movable furniture, fixtures, or other equipment that have no permanent connection to the structure of a building or utilities. These items depreciate substantially but are important costs to consider when valuing a company, especially in liquidation.
Examples of FF&E include desks, chairs, computers, electronic equipment, tables, bookcases, and partitions.
Sometimes the term FF&A is used (furniture, fixtures, and accessories).",3
Finance,General account,"A general account generally refers to the combined or aggregate investments and other assets of an insurance company available to pay claims and benefits to which insured entities or policyholders are entitled.  The general account may also be considered everything that is not represented by a separate accounts of the firm, if such separate account has been established by the company.  Should a firm have no separate accounts, then its only account is the general account.  The term should not be thought of narrowly in terms of a bank account or general ledger account, but rather the broader concept introduced in the first sentence.
Policyholders of insurance policies (that are not associated with separate accounts) do not have a legal or other direct interest or right to the assets or investments of the insurance company's general account but rather these obligations for benefits or claims are general obligations of the company.  In this case, policyholders are subject to credit risk of the insurance company-- that is, should the insurance company fail or go bankrupt, the claims or cash values of policies are not directly backed or collateralized by the company's investments and other assets.  In the U.S., state insurance departments examine (audit) insurance companies to evaluate many things, principally to see if the company is sound and policyholder interests are protected. A.M. Best is an example of an insurance rating agency who evaluates and rates many companies on various factors such as financial strength, claims-paying and other policyholder servicing experiences.",3
Finance,Decentralized finance,"Decentralized finance (DeFi) offers financial instruments without relying on intermediaries such as brokerages, exchanges, or banks by using smart contracts on a blockchain. DeFi platforms allow people to lend or borrow funds from others, speculate on price movements on assets using derivatives, trade cryptocurrencies, insure against risks, and earn interest in savings-like accounts. DeFi uses a layered architecture and highly composable building blocks. Some applications promote high interest rates but are subject to high risk. As of February 2022, the value of assets used in decentralized finance amounted to $200 billion.

",3
Finance,First Chicago Method,"The First Chicago Method or Venture Capital Method is a business valuation approach used by venture capital and private equity investors that combines elements of both a multiples-based valuation and a discounted cash flow (DCF) valuation approach. The First Chicago Method was first developed by, and consequently named for, the venture capital arm of the First Chicago bank, the predecessor of private equity firms Madison Dearborn Partners and GTCR.

It was first discussed academically in 1987.",3
Finance,Store of value,"A store of value is any commodity or asset that would normally retain purchasing power into the future and is the function of the asset that can be saved, retrieved and exchanged at a later time, and be predictably useful when retrieved.The most common store of value in modern times has been money, currency, or a commodity like a precious metal or financial capital. The point of any store of value is risk management due to a stable demand for the underlying asset.

",3
Finance,Drawdown cover ratio,"Drawdown cover ratio is one of the key terms in project finance funding agreements.
It compares the projected maximum debt outstanding with the forecast net present value of the project cash flows during the term of the loan.",3
Finance,Fair value accounting and the subprime mortgage crisis,"The United States subprime mortgage crisis was a multinational financial crisis that occurred between 2007 and 2010 that contributed to the 2007–2008 global financial crisis. It was triggered by a large decline in US home prices after the collapse of a housing bubble, leading to mortgage delinquencies, foreclosures, and the devaluation of housing-related securities. Declines in residential investment preceded the Great Recession and were followed by reductions in household spending and then business investment. Spending reductions were more significant in areas with a combination of high household debt and larger housing price declines.The housing bubble preceding the crisis was financed with mortgage-backed securities (MBSes) and collateralized debt obligations (CDOs), which initially offered higher interest rates (i.e. better returns) than government securities, along with attractive risk ratings from rating agencies. While elements of the crisis first became more visible during 2007, several major financial institutions collapsed in September 2008, with significant disruption in the flow of credit to businesses and consumers and the onset of a severe global recession.There were many causes of the crisis, with commentators assigning different levels of blame to financial institutions, regulators, credit agencies, government housing policies, and consumers, among others. Two proximate causes were the rise in subprime lending and the increase in housing speculation. The percentage of lower-quality subprime mortgages originated during a given year rose from the historical 8% or lower range to approximately 20% from 2004 to 2006, with much higher ratios in some parts of the U.S. A high percentage of these subprime mortgages, over 90% in 2006 for example, had an interest rate that increased over time. Housing speculation also increased, with the share of mortgage originations to investors (i.e. those owning homes other than primary residences) rising significantly from around 20% in 2000 to around 35% in 2006–2007. Investors, even those with prime credit ratings, were much more likely to default than non-investors when prices fell. These changes were part of a broader trend of lowered lending standards and higher-risk mortgage products, which contributed to U.S. households becoming increasingly indebted. The ratio of household debt to disposable personal income rose from 77% in 1990 to 127% by the end of 2007.When U.S. home prices declined steeply after peaking in mid-2006, it became more difficult for borrowers to refinance their loans. As adjustable-rate mortgages began to reset at higher interest rates (causing higher monthly payments), mortgage delinquencies soared. Securities backed with mortgages, including subprime mortgages, widely held by financial firms globally, lost most of their value. Global investors also drastically reduced purchases of mortgage-backed debt and other securities as part of a decline in the capacity and willingness of the private financial system to support lending. Concerns about the soundness of U.S. credit and financial markets led to tightening credit around the world and slowing economic growth in the U.S. and Europe.
The crisis had severe, long-lasting consequences for the U.S. and European economies. The U.S. entered a deep recession, with nearly 9 million jobs lost during 2008 and 2009, roughly 6% of the workforce. The number of jobs did not return to the December 2007 pre-crisis peak until May 2014. U.S. household net worth declined by nearly $13 trillion (20%) from its Q2 2007 pre-crisis peak, recovering by Q4 2012. U.S. housing prices fell nearly 30% on average and the U.S. stock market fell approximately 50% by early 2009, with stocks regaining their December 2007 level during September 2012. One estimate of lost output and income from the crisis comes to ""at least 40% of 2007 gross domestic product"". Europe also continued to struggle with its own economic crisis, with elevated unemployment and severe banking impairments estimated at €940 billion between 2008 and 2012. As of January 2018, U.S. bailout funds had been fully recovered by the government, when interest on loans is taken into consideration. A total of $626B was invested, loaned, or granted due to various bailout measures, while $390B had been returned to the Treasury. The Treasury had earned another $323B in interest on bailout loans, resulting in an $109B profit as of January 2021.",3
Finance,Financial stability,"The Financial Stability Board (FSB) is an international body that monitors and makes recommendations about the global financial system. It was established after the G20 London summit in April 2009 as a successor to the Financial Stability Forum (FSF). The Board includes all G20 major economies, FSF members, and the European Commission. Hosted and funded by the Bank for International Settlements, the board is based in Basel, Switzerland, and is established as not-for-profit association under Swiss law.The FSB represented the G20 leaders' first major international institutional innovation. U.S. Treasury Secretary Tim Geithner has described it as ""in effect, a fourth pillar"" of the architecture of global economic governance. The FSB has been assigned a number of important tasks, working alongside the International Monetary Fund, World Bank, and the World Trade Organization.
Unlike most multilateral financial institutions, the FSB lacks a legal form and any formal power, given that its charter is an informal and nonbinding memorandum of understanding for cooperation adopted by its members.

",3
Finance,Dividend puzzle,"The dividend puzzle is a concept in finance in which companies that pay dividends are rewarded by investors with higher valuations, even though, according to many economists, it should not matter to investors whether a firm pays dividends or not. The reasoning goes that dividends, from the investor’s point of view, should have no effect on the process of valuing equity because the investor already owns the firm and, thus, he/she should be indifferent to either getting the dividends or having them re-invested in the firm. Another reason for economists to be puzzled is that equity holders pay a higher tax rate on dividend payouts compared to capital gains from the firm repurchasing shares as an alternative payout policy. 
The puzzle evolved from the Modigliani–Miller theorems of 1959 and 1961.
The reasons for the dividend puzzle have been attributed to a wide range of factors, including uncertainties, psychological/behavioral economics issues, tax-related matters, and asymmetric information.",3
Finance,Business valuation standard,"Business Valuation Standards (BVS) are codes of practice that are used in business valuation.  The major business appraisal standards are these:

CICBV Practice Standards. Published by the CBV Institute.
Uniform Standards of Professional Appraisal Practice (USPAP). Standards 9 and 10 cover business valuation and reporting standards. Published by the Appraisal Foundation.
International Valuation Standards. Published by the International Valuation Standards Council.
Statement on Standards for Valuation Services (SSVS No 1). Published by the American Institute of CPAs.In addition, each of the three major United States valuation societies — the American Society of Appraisers (ASA), American Institute of Certified Public Accountants (CPA/ABV), and the National Association of Certified Valuation Analysts (NACVA) — has its own set of Business Valuation Guidelines, which it requires all of its accredited members to adhere to.  The AICPA's standards are published as Statement on Standards for Valuation Services No.1 and the ASA's guidelines are published as the ASA Business Valuation Guidelines, which largely follow the USPAP Standard requirements.  All AICPA members are required to follow SSVS1.  Additionally, the majority of the State Accountancy Boards have adopted SSVS1 for CPAs licensed in their state.",3
Finance,Benjamin Graham formula,"The  Benjamin Graham formula is a formula proposed by investor and professor of Columbia University, Benjamin Graham, often referred to as the ""father of value investing"". Published in his book, The Intelligent Investor, Graham devised the formula for lay investors to help them with the valuation of growth stocks in vogue at the time of the formula's publication.
He did however caution that the use of this equation was not appropriate for companies ""below-par"" debt position: ""My advice to analysts would be to limit your appraisals to enterprises of investment quality, excluding from that category such as do not meet specific criteria of financial strength"".",3
Technology,Action model learning,"Action model learning (sometimes abbreviated action learning) is an area of machine learning concerned with creation and modification of software agent's knowledge about effects and preconditions of the actions that can be executed within its environment. This knowledge is usually represented in logic-based action description language and used as the input for automated planners.
Learning action models is important when goals change. When an agent acted for a while, it can use its accumulated knowledge about actions in the domain to make better decisions. Thus, learning action models differs from reinforcement learning. It enables reasoning about actions instead of expensive trials in the world. Action model learning is a form of inductive reasoning, where new knowledge is generated based on agent's observations. It differs from standard supervised learning in that correct input/output pairs are never presented, nor imprecise action models explicitly corrected.
Usual motivation for action model learning is the fact that manual specification of action models for planners is often a difficult, time consuming, and error-prone task (especially in complex environments).",2
Technology,Linear separability,"In Euclidean geometry, linear separability is a property of two sets of points. This is most easily visualized in two dimensions (the Euclidean plane) by thinking of one set of points as being colored blue and the other set of points as being colored red. These two sets are linearly separable if there exists at least one line in the plane with all of the blue points on one side of the line and all the red points on the other side. This idea immediately generalizes to higher-dimensional Euclidean spaces if the line is replaced by a hyperplane.
The problem of determining if a pair of sets is linearly separable and finding a separating hyperplane if they are, arises in several areas.  In statistics and machine learning, classifying certain types of data is a problem for which good algorithms exist that are based on this concept.

",2
Technology,Artificial intelligence in hiring,"Artificial intelligence (AI) in hiring involves the use of technology to automate aspects of the hiring process. Advances in artificial intelligence, such as the advent of machine learning and the growth of big data, enable AI to be utilized to recruit, screen, and predict the success of applicants. Proponents of artificial intelligence in hiring claim it reduces bias, assists with finding qualified candidates, and frees up human resource workers' time for other tasks, while opponents worry that AI perpetuates inequalities in the workplace and will eliminate jobs.

",2
Technology,Security Vision,"Security Vision – software meant for automation of information security management system (ISMS) organisation.
Software of this kind is a representative of security operations center (SOC).",2
Technology,Pwnie Awards,The Pwnie Awards recognize both excellence and incompetence in the field of information security. Winners are selected by a committee of security industry professionals from nominations collected from the information security community. The awards are presented yearly at the Black Hat Security Conference.,2
Technology,Enterprise information security architecture,"Enterprise information security architecture (ZBI) is a part of enterprise architecture focusing on information security throughout the enterprise.  The name implies a difference that may not exist between small/medium-sized businesses and larger organizations.

",2
Technology,Wargame (hacking),"In hacking, a wargame (or war game) is a cyber-security challenge and mind sport in which the competitors must exploit or defend a vulnerability in a system or application, or gain or prevent access to a computer system.A wargame usually involves a capture the flag logic, based on pentesting, semantic URL attacks, knowledge-based authentication, password cracking, reverse engineering of software (often JavaScript, C and assembly language), code injection, SQL injections, cross-site scripting, exploits, IP address spoofing, forensics, and other hacking techniques.",2
Technology,Content Threat Removal,"Content Threat Removal (CTR) is a cyber security technology intended to defeat the threat posed by handling digital content in cyberspace. Unlike other defences, including antivirus software and sandboxed execution, it does not rely on being able to detect threats. Similarly to Content Disarm and Reconstruction, CTR is designed to remove the threat without knowing whether it has done so, and acts without knowing if data contains a threat or not.
Detection strategies work by detecting unsafe content, and then blocking or removing that content. Content that is deemed safe is delivered to its destination. In contrast, Content Threat Removal assumes all data is hostile and delivers none of it to the destination, regardless of whether it is actually hostile. Although no data is delivered, the business information carried by the data is delivered, but using new data created for the purpose.

",2
Technology,Multilinear principal component analysis,"Within statistics, Multilinear principal component analysis (MPCA)  is a multilinear extension of principal component analysis (PCA). MPCA is employed in the analysis of n-way arrays, i.e. a cube or hyper-cube of numbers, also informally referred to as a ""data tensor"".  N-way arrays may be decomposed, analyzed, or modeled by 

linear tensor models such as CANDECOMP/Parafac, or
multilinear tensor models, such as multilinear principal component analysis (MPCA), or multilinear independent component analysis (MICA), etc.The origin of MPCA can be traced back to the Tucker decomposition and Peter Kroonenberg's ""M-mode PCA/3-mode PCA"" work. In 2000, De Lathauwer et al. restated Tucker and Kroonenberg's work in clear and concise numerical computational terms in their SIAM paper entitled ""Multilinear Singular Value Decomposition"", (HOSVD) and in their paper ""On the Best Rank-1 and Rank-(R1, R2, ..., RN ) Approximation of Higher-order Tensors"".Circa 2001, Vasilescu reframed the data analysis, recognition and synthesis problems as multilinear tensor problems based on the insight that most observed data are the compositional consequence of several causal factors of data formation, and are well suited for multi-modal data tensor analysis.  The power of the tensor framework was showcased by analyzing human motion joint angles, facial images or textures in terms of their causal factors of data formation in the following works: Human Motion Signatures
(CVPR 2001, ICPR 2002), face recognition – TensorFaces,
(ECCV 2002, CVPR 2003, etc.) and computer graphics – TensorTextures (Siggraph 2004).
Historically, MPCA has been referred to as ""M-mode PCA"", a terminology which was coined by Peter Kroonenberg in 1980. In 2005, Vasilescu and Terzopoulos introduced the Multilinear PCA terminology as a way to better differentiate between linear and multilinear tensor decomposition, as well as, to better differentiate between the work that computed 2nd order statistics associated with each data tensor mode(axis), and subsequent work on Multilinear Independent Component Analysis that computed higher order statistics associated with each tensor mode/axis.
Multilinear PCA may be applied to compute the causal factors of data formation, or as signal processing tool on data tensors whose individual observation have either been vectorized, or whose observations are treated as matrix and concatenated into a data tensor.
MPCA computes a set of orthonormal matrices associated with each mode of the data tensor which are analogous to the orthonormal row and column space of a matrix computed by the matrix SVD.  This transformation aims to capture as high a variance as possible, accounting for as much of the variability in the data associated with each data tensor mode(axis).

",2
Technology,Bag-of-words model,"The bag-of-words model is a simplifying representation used in natural language processing and information retrieval (IR). In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity. The bag-of-words model has also been used for computer vision.The bag-of-words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.An early reference to ""bag of words"" in a linguistic context can be found in Zellig Harris's 1954 article on Distributional Structure.The Bag-of-words model is one example of a Vector space model.

",2
Technology,Security breach notification laws,"Security breach notification laws or data breach notification laws are laws that require individuals or entities affected by a data breach, unauthorized access to data, to notify their customers and other parties about the breach, as well as take specific steps to remedy the situation based on state legislature. Data breach notification laws have two main goals. The first goal is to allow individuals a chance to mitigate risks against data breaches. The second goal is to promote company incentive to strengthen data security.Together, these goals work to minimize consumer harm from data breaches, including impersonation, fraud, and identity theft.Such laws have been irregularly enacted in all 50 U.S. states since 2002. Currently, all 50 states have enacted forms of data breach notification laws. It should be noted though, that there is no federal data breach notification law, despite previous legislative attempts. These laws were enacted in response to an escalating number of breaches of consumer databases containing personally identifiable information. Similarly, multiple other countries, like the European Unions's General Data Protection Regulation (GDPR) and Australia's Privacy Amendment (Notifiable Data Breaches) Act 2017 (Cth), have added data breach notification laws to combat the increasing occurrences of data breaches.The rise in data breaches conducted by both countries and individuals is evident and alarming, as the number of reported data breaches has increased from 421 in 2011, to 1,091 in 2016, and 1,579 in 2017 according to the Identity Theft Resource Center (ITRC). It has also impacted millions of people and gained increasing public awareness due to large data breaches such as the October 2017 Equifax breach that exposed almost 146 million individual's personal information.

",2
Technology,Systems development life cycle,"In systems engineering, information systems and software engineering, the systems development life cycle (SDLC), also referred to as the application development life-cycle, is a process for planning, creating, testing, and deploying an information system. The systems development life cycle concept applies to a range of hardware and software configurations, as a system can be composed of hardware only, software only, or a combination of both. There are usually six stages in this cycle: requirement analysis, design, development and testing, implementation, documentation, and evaluation.",2
Technology,Stochastic block model,"The stochastic block model is a generative model for random graphs. This model tends to produce graphs containing communities, subsets of nodes characterized by being connected with one another with particular edge densities. For example, edges may be more common within communities than between communities. Its mathematical formulation has been firstly introduced in 1983 in the field of social network by Holland et al. The stochastic block model is important in statistics, machine learning, and network science, where it serves as a useful benchmark for the task of recovering community structure in graph data.

",2
Technology,Weak supervision,"Weak supervision is a branch of machine learning where noisy, limited, or imprecise sources are used to provide supervision signal for labeling large amounts of training data in a supervised learning setting. This approach alleviates the burden of obtaining hand-labeled data sets, which can be costly or impractical. Instead, inexpensive weak labels are employed with the understanding that they are imperfect, but can nonetheless be used to create a strong predictive model.

",2
Technology,Representer theorem,"For computer science, in statistical learning theory, a representer theorem is any of several related results stating that a minimizer 
  
    
      
        
          f
          
            ∗
          
        
      
    
    {\displaystyle f^{*}}
   of a regularized empirical risk functional defined over a reproducing kernel Hilbert space can be represented as a finite linear combination of kernel products evaluated on the input points in the training set data.",2
Technology,Anomaly detection,"In data analysis, anomaly detection (also referred to as outlier detection and sometimes as novelty detection) is generally understood to be the identification of rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behaviour. Such examples may arouse suspicions of being generated by a different mechanism, or appear inconsistent with the remainder of that set of data.Anomaly detection finds application in many domains including cyber security, medicine, machine vision, statistics, neuroscience, law enforcement and financial fraud to name only a few. Anomalies were initially searched for clear rejection or omission from the data to aid statistical analysis, for example to compute the mean or standard deviation. They were also removed to better predictions from models such as linear regression, and more recently their removal aids the performance of machine learning algorithms. However, in many applications anomalies themselves are of interest and are the observations most desirous in the entire data set, which need to be identified and separated from noise or irrelevant outliers.
Three broad categories of anomaly detection techniques exist. Supervised anomaly detection techniques require a data set that has been labeled as ""normal"" and ""abnormal"" and involves training a classifier. However, this approach is rarely used in anomaly detection due to the general unavailability of labelled data and the inherent unbalanced nature of the classes. Semi-supervised anomaly detection techniques assume that some portion of the data is labelled. This may be any combination of the normal or anomalous data, but more often than not the techniques construct a model representing normal behavior from a given normal training data set, and then test the likelihood of a test instance to be generated by the model. Unsupervised anomaly detection techniques assume the data is unlabelled and are by far the most commonly used due to their wider and relevant application.

",2
Technology,BlueBorne (security vulnerability),"BlueBorne is a type of security vulnerability with Bluetooth implementations in Android, iOS, Linux and Windows. It affects many electronic devices such as laptops, smart cars, smartphones and wearable gadgets. One example is CVE-2017-14315.  The vulnerabilities were first reported by Armis, an IoT security firm, on 12 September 2017. According to Armis, ""The BlueBorne attack vector can potentially affect all devices with Bluetooth capabilities, estimated at over 8.2 billion devices today [2017].""",2
Technology,Natarajan dimension,"In the theory of Probably Approximately Correct Machine Learning, the Natarajan dimension characterizes the complexity of learning a set of functions, generalizing from the Vapnik-Chervonenkis dimension for boolean functions to multi-class functions. Originally introduced as the Generalized Dimension by Natarajan, it was subsequently renamed the Natarajan Dimension by Haussler and Long.",2
Technology,Formal concept analysis,"In information science, formal concept analysis (FCA) is a principled way of deriving a concept hierarchy or formal ontology from a collection of objects and their properties. Each concept in the hierarchy represents the objects sharing some set of properties; and each sub-concept in the hierarchy represents a subset of the objects (as well as a superset of the properties) in the concepts above it. The term was introduced by Rudolf Wille in 1981, and builds on the mathematical theory of lattices and ordered sets that was developed by Garrett Birkhoff and others in the 1930s.
Formal concept analysis finds practical application in fields including data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.",2
Technology,Intrusion tolerance,"Intrusion tolerance is a fault-tolerant design approach to defending information systems against malicious attacks. In that sense, it is also a computer security approach. Abandoning the conventional aim of preventing all intrusions, intrusion tolerance instead calls for triggering mechanisms that prevent intrusions from leading to a system security failure. There are two major variants of intrusion tolerance mechanisms: mechanisms based on redundancy (e.g., as in Byzantine fault tolerance); mechanisms based on intrusion detection (e.g., with an intrusion detection system) and reaction.",2
Technology,CloudPassage,"CloudPassage is a company that provides an automation platform, delivered via software as a service, that improves security for private, public, and hybrid cloud computing environments. CloudPassage is headquartered in San Francisco.

",2
Technology,Enrollment over Secure Transport,"The Enrollment over Secure Transport, or EST is a cryptographic protocol that describes an X.509 certificate management protocol targeting public key infrastructure (PKI) clients that need to acquire client certificates and associated certificate authority (CA) certificates. EST is described in RFC 7030. EST has been put forward as a replacement for SCEP, being easier to implement on devices already having an HTTPS stack. EST uses HTTPS as transport and leverages TLS for many of its security attributes. EST has described standardized URLs and uses the well-known Uniform Resource Identifiers (URIs) definition codified in RFC 5785.",2
Technology,Latent space,"A latent space, also known as a latent feature space or embedding space, is an embedding of a set of items within a manifold in which items which resemble each other more closely are positioned closer to one another in the latent space. Position within the latent space can be viewed as being defined by a set of latent variables that emerge from the resemblances from the objects.
In most cases, the dimensionality of the latent space is chosen to be lower than the dimensionality of the feature space from which the data points are drawn, making the construction of a latent space an example of dimensionality reduction, which can also be viewed as a form of data compression or machine learning.
A number of algorithms exist to create latent space embeddings given a set of data items and a similarity function.

",2
Technology,Active learning (machine learning),"Active learning is a special case of machine learning in which a learning algorithm can interactively query a user (or some other information source) to label new data points with the desired outputs. In statistics literature, it is sometimes also called optimal experimental design. The information source is also called teacher or oracle.
There are situations in which unlabeled data is abundant but manual labeling is expensive. In such a scenario, learning algorithms can actively query the user/teacher for labels. This type of iterative supervised learning is called active learning. Since the learner chooses the examples, the number of examples to learn a concept can often be much lower than the number required in normal supervised learning. With this approach, there is a risk that the algorithm is overwhelmed by uninformative examples.  Recent developments are dedicated to multi-label active learning, hybrid active learning and active learning in a single-pass (on-line) context, combining concepts from the field of machine learning (e.g. conflict and ignorance) with adaptive, incremental learning policies in the field of online machine learning.

",2
Technology,Security hacker,"A security hacker is someone who explores methods for breaching defenses and exploiting weaknesses in a computer system or network. Hackers may be motivated by a multitude of reasons, such as profit, protest, information gathering, challenge, recreation, or evaluation of a system weaknesses to assist in formulating defenses against potential hackers. The subculture that has evolved around hackers is often referred to as the ""computer underground"".Longstanding controversy surrounds the meaning of the term ""hacker"". In this controversy, computer programmers reclaim the term hacker, arguing that it refers simply to someone with an advanced understanding of computers and computer networks and that cracker is the more appropriate term for those who break into computers, whether computer criminals (black hats) or computer security experts (white hats). A 2014 article noted that ""the black-hat meaning still prevails among the general public"".",2
Technology,Biometric device,"A biometric device is a security identification and authentication device.  Such devices use automated methods of verifying or recognising the identity of a living person based on a physiological  or behavioral characteristic. These characteristics include fingerprints, facial images, iris and voice recognition.

",2
Technology,Cyber Threat Intelligence Integration Center,"The Cyber Threat Intelligence Integration Center (CTIIC) is a new United States federal government agency that will be a fusion center between existing agencies and the private sector for real-time use against cyber attacks. CTIIC was created due to blocked efforts in Congress that were stymied over liability and privacy concerns of citizens.CTIIC was formally announced by Lisa Monaco February 10, 2015 at the Wilson Center. The agency will be within the Office of the Director of National Intelligence.",2
Technology,Leakage (machine learning),"In statistics and machine learning, leakage (also known as data leakage or target leakage) is the use of information in the model training process which would not be expected to be available at prediction time, causing the predictive scores (metrics) to overestimate the model's utility when run in a production environment.Leakage is often subtle and indirect, making it hard to detect and eliminate. Leakage can cause a statistician or modeler to select a suboptimal model, which could be outperformed by a leakage-free model.",2
Technology,Zero-knowledge service,"In cloud computing, the term zero-knowledge (or occasionally no-knowledge or zero access) refers to software services that store, transfer or manipulate data such that it is only accessible to its owner, not to the service provider. This is accomplished by encrypting the raw data at the client side or end-to-end (in case of one or more clients, respectively), without disclosing the password to the service provider. This means neither the service provider, nor any third party that might intercept the data, can ever decrypt and access the data on their own, allowing the client a higher degree of privacy than would otherwise be possible. In addition, zero-knowledge services usually aspire to hold as little metadata as possible, so as not to jeopardize clients' privacy by holding data beyond what is functionally needed by the service.
The term ""zero-knowledge"" was popularized by backup service SpiderOak, which later switched to using the term ""no knowledge"" to avoid confusion with the computer science concept of zero-knowledge proof.
Providers of zero-knowledge services include:

SpiderOak
Tresorit
Sync.com
NordPass
Cubbit
ProtonMail
Signal
LucidLink

",2
Technology,Probability matching,"Probability matching is a decision strategy in which predictions of class membership are proportional to the class base rates.  Thus, if in the training set positive examples are observed 60% of the time, and negative examples are observed 40% of the time, then the observer using a probability-matching strategy will predict (for unlabeled examples) a class label of ""positive"" on 60% of instances, and a class label of ""negative"" on 40% of instances.  
The optimal Bayesian decision strategy (to maximize the number of correct predictions, see Duda, Hart & Stork (2001)) in such a case is to always predict ""positive"" (i.e., predict the majority category in the absence of other information), which has 60% chance of winning rather than matching which has 52% of winning  (where p is the probability of positive realization, the result of matching would be 
  
    
      
        
          p
          
            2
          
        
        +
        (
        1
        −
        p
        
          )
          
            2
          
        
      
    
    {\displaystyle p^{2}+(1-p)^{2}}
  , here 
  
    
      
        .6
        ×
        .6
        +
        .4
        ×
        .4
      
    
    {\displaystyle .6\times .6+.4\times .4}
  ).  The probability-matching strategy is of psychological interest because it is frequently employed by human subjects in decision and classification studies (where it may be related to Thompson sampling).
The only case when probability matching will yield same results as Bayesian decision strategy mentioned above is when all class base rates are the same. So, if in the training set positive examples are observed 50% of the time, then the Bayesian strategy would yield 50% accuracy (1 × .5), just as probability matching (.5 ×.5 + .5 × .5).",2
Technology,High Assurance Guard,"A High Assurance Guard (HAG) is a Multilevel security computer device which is used to communicate between different Security Domains, such as NIPRNet to SIPRNet. A HAG is one example of a Controlled Interface between security levels. HAGs are approved through the Common Criteria process.

",2
Technology,American Innovation and Competitiveness Act,"The American Innovation and Competitiveness Act (AICA) is a United States federal law enacted in 2017 by President Barack Obama that aims to invest in cybersecurity and cryptography research. The legislation was initially introduced in the Senate by Cory Gardner (R-CO) and Gary Peters (D-MI). The legislation serves as a reauthorization of the 2010 America COMPETES Act that expired in 2013.The legislation updates instructions to the National Science Foundation and the National Institute of Standards and Technology (NIST), with a director of security position being created in the latter latter. AICA supports the coordination of citizen science and crowdsourcing by Federal agencies to accomplish their missions.",2
Technology,Word2vec,"Word2vec is a technique for natural language processing published in 2013. The word2vec algorithm uses a neural network model to learn word associations from a large corpus of text. Once trained, such a model can detect synonymous words or suggest additional words for a partial sentence. As the name implies, word2vec represents each distinct word with a particular list of numbers called a vector. The vectors are chosen carefully such that a simple mathematical function (the cosine similarity between the vectors) indicates the level of semantic similarity between the words represented by those vectors.

",2
Technology,Statistical learning theory,"Statistical learning theory is a framework for machine learning drawing from the fields of statistics and functional analysis. Statistical learning theory deals with the statistical inference problem of finding a predictive function based on data. Statistical learning theory has led to successful applications in fields such as computer vision, speech recognition, and bioinformatics.",2
Technology,Relying party,"A relying party (RP) is a computer term used to refer to a server providing access to a secure software application.
Claims-based applications, where a claim is a statement an entity makes about itself in order to establish access, are also called relying party (RP) applications. RPs can also be called “claims aware applications” and “claims-based applications”. Web applications and services can both be RPs.With a Security Token Service (STS), the RP redirects clients to an STS which authenticates the client and issues it a security token containing a set of claims about the client's identity, which it can present to the RP. Instead of the application authenticating the user directly, the RP can extract these claims from the token and use them for identity related tasks.The OpenID standard defines a situation whereby a cooperating site can act as an RP, allowing the user to log into multiple sites using one set of credentials.  The user benefits from not having to share their login credentials with multiple sites, and the operators of the cooperating site avoid having to develop their own login mechanism.An application demonstrating the concept of relying party is software running on mobile devices, which can be used not only for granting user access to software applications, but also for secure building access, without the user having to enter their credentials each time.",2
Technology,Cyber Intelligence Sharing and Protection Act,"The Cyber Intelligence Sharing and Protection Act (CISPA H.R. 3523 (112th Congress), H.R. 624 (113th Congress), H.R. 234 (114th Congress)) was a proposed law in the United States which would allow for the sharing of Internet traffic information between the U.S. government and technology and manufacturing companies. The stated aim of the bill is to help the U.S. government investigate cyber threats and ensure the security of networks against cyberattacks.The legislation was introduced on November 30, 2011, by Representative Michael Rogers (R-MI) and 111 co-sponsors. It was passed in the House of Representatives on April 26, 2012, but was not passed by the U.S. Senate. President Barack Obama's advisers have argued that the bill lacks confidentiality and civil liberties safeguards, and the White House said he would veto it.In February 2013, the House reintroduced the bill and it passed in the United States House of Representatives on April 18, 2013, but stalled and was not voted upon by the Senate. On July 10, 2014 a similar bill, the Cybersecurity Information Sharing Act (CISA), was introduced in the Senate.In January 2015, the House reintroduced the bill again. The bill has been referred to the Committee on Intelligence, and as of February 2, 2015 to the Subcommittee on Crime, Terrorism, Homeland Security, and Investigations and Subcommittee on Constitution and Civil Justice to see if it will come to the House for a vote. In December 2015 a version of CISPA was hidden in the total federal budget.
CISPA had garnered favor from corporations and lobbying groups such as Microsoft, Facebook, AT&T, IBM, and the United States Chamber of Commerce, which look on it as a simple and effective means of sharing important cyber threat information with the government. It has however been criticized by advocates of Internet privacy and civil liberties, such as the Electronic Frontier Foundation, the American Civil Liberties Union, Free Press, Fight for the Future, and Avaaz.org, as well as various conservative and libertarian groups including the Competitive Enterprise Institute, TechFreedom, FreedomWorks, Americans for Limited Government, Liberty Coalition, and the American Conservative Union. Those groups argue CISPA contains too few limits on how and when the government may monitor a private individual's Internet browsing information. Additionally, they fear that such new powers could be used to spy on the general public rather than to pursue malicious hackers.Some critics saw wording included in CISPA as a second attempt to protect intellectual property after the Stop Online Piracy Act was taken off the table by Congress after it met opposition. Intellectual property theft was initially listed in the bill as a possible cause for sharing Web traffic information with the government, though it was removed in subsequent drafts.",2
Technology,Public computer,"A public computer (or public access computer) is any of various computers available in public areas. Some places where public computers may be available are libraries, schools, or dedicated facilities run by government.
Public computers share similar hardware and software components to personal computers, however, the role and function of a public access computer is entirely different. A public access computer is used by many different untrusted individuals throughout the course of the day. The computer must be locked down and secure against both intentional and unintentional abuse. Users typically do not have authority to install software or change settings. A personal computer, in contrast, is typically used by a single responsible user, who can customize the machine's behavior to their preferences.
Public access computers are often provided with tools such as a PC reservation system to regulate access.
The world's first public access computer center was the Marin Computer Center in California, co-founded by David and Annie Fox in 1977.",2
Technology,Ablation (artificial intelligence),"In artificial intelligence (AI), particularly machine learning (ML), ablation is the removal of a component of an AI system. An ablation study investigates the performance of an AI system by removing certain components to understand the contribution of the component to the overall system. The term is an analogy with biology (removal of components of an organism), and is particularly used in the analysis of artificial neural nets by analogy with ablative brain surgery. Other analogies include other neuroscience biological systems such as Drosophilla central nervous system and the vertebrate brain. Ablation studies require that a system exhibit graceful degradation: the system must continue to function even when certain components are missing or degraded. According to some researchers, ablation studies have been deemed a convenient technique in investigating artificial intelligence and its durability to structural damages. Ablation studies damage and/or remove certain components in a controlled setting to investigate all possible outcomes of system failure; this characterizes how each action impacts the system's overall performance and capabilities. The ablation process can be used to test systems that perform tasks such as speech recognition, visual object recognition, and robot control.",2
Technology,Matrix regularization,"In the field of statistical learning theory, matrix regularization generalizes notions of vector regularization to cases where the object to be learned is a matrix. The purpose of regularization is to enforce conditions, for example sparsity or smoothness, that can produce stable predictive functions. For example, in the more common vector framework, Tikhonov regularization optimizes over

  
    
      
        
          min
          
            x
          
        
        ‖
        A
        x
        −
        y
        
          ‖
          
            2
          
        
        +
        λ
        ‖
        x
        
          ‖
          
            2
          
        
      
    
    {\displaystyle \min _{x}\|Ax-y\|^{2}+\lambda \|x\|^{2}}
  to find a vector 
  
    
      
        x
      
    
    {\displaystyle x}
   that is a stable solution to the regression problem. When the system is described by a matrix rather than a vector, this problem  can be written as

  
    
      
        
          min
          
            X
          
        
        ‖
        A
        X
        −
        Y
        
          ‖
          
            2
          
        
        +
        λ
        ‖
        X
        
          ‖
          
            2
          
        
        ,
      
    
    {\displaystyle \min _{X}\|AX-Y\|^{2}+\lambda \|X\|^{2},}
  where the vector norm enforcing a regularization penalty on 
  
    
      
        x
      
    
    {\displaystyle x}
   has been extended to a matrix norm on 
  
    
      
        X
      
    
    {\displaystyle X}
  .
Matrix regularization has applications in matrix completion, multivariate regression, and multi-task learning. Ideas of feature and group selection can also be extended to matrices, and these can be generalized to the nonparametric case of multiple kernel learning.

",2
Technology,Prior knowledge for pattern recognition,"Pattern recognition is a very active field of research intimately bound to machine learning. Also known as classification or statistical classification, pattern recognition aims at building a classifier that can determine the class of an input pattern. This procedure, known as training, corresponds to learning an unknown decision function based only on a set of input-output pairs 
  
    
      
        (
        
          
            x
          
          
            i
          
        
        ,
        
          y
          
            i
          
        
        )
      
    
    {\displaystyle ({\boldsymbol {x}}_{i},y_{i})}
   that form the training data (or training set). Nonetheless, in real world applications such as character recognition, a certain amount of information on the problem is usually known beforehand. The incorporation of this prior knowledge into the training is the key element that will allow an increase of performance in many applications.

",2
Technology,Inductive programming,"Inductive programming (IP) is a special area of automatic programming, covering research from artificial intelligence and programming, which addresses learning of typically declarative (logic or functional) and often recursive programs from incomplete specifications, such as input/output examples or constraints.
Depending on the programming language used, there are several kinds of inductive programming. Inductive functional programming, which uses functional programming languages such as Lisp or Haskell, and most especially inductive logic programming, which uses logic programming languages such as Prolog and other logical representations  such as description logics, have been more prominent, but other (programming) language paradigms have also been used, such as constraint programming or probabilistic programming.

",2
Technology,Proof-carrying code,"Proof-carrying code (PCC) is a software mechanism that allows a host system to verify properties about an application via a formal proof that accompanies the application's executable code.  The host system can quickly verify the validity of the proof, and it can compare the conclusions of the proof to its own security policy to determine whether the application is safe to execute.  This can be particularly useful in ensuring memory safety (i.e. preventing issues like buffer overflows).
Proof-carrying code was originally described in 1996 by George Necula and Peter Lee.",2
Technology,WS-SecurityPolicy,"WS-SecurityPolicy is a web services specification, created by IBM and 12 co-authors, that has become an OASIS standard as of version 1.2. It extends the fundamental security protocols specified by the WS-Security, WS-Trust and WS-SecureConversation by offering mechanisms to represent the capabilities and requirements of web services as policies. Security policy assertions are based on the WS-Policy framework. 
Policy assertions can be used to require more generic security attributes like transport layer security <TransportBinding>, message level security <AsymmetricBinding> or timestamps, and specific attributes like token types. 
Most policy assertion can be found in following categories:

Protection assertions identify the elements of a message that are required to be signed, encrypted or existent.
Token assertions specify allowed token formats (SAML, X509, Username etc.).
Security binding assertions control basic security safeguards like transport and message level security, cryptographic algorithm suite and required timestamps.
Supporting token assertions add functions like user sign-on using a username token.Policies can be used to drive development tools to generate code with certain capabilities, or may be used at runtime to negotiate the security aspects of web service communication. Policies may be attached to WSDL elements such as service, port, operation and message, as defined in WS Policy Attachment.",2
Technology,Matchbox Educable Noughts and Crosses Engine,"The Matchbox Educable Noughts and Crosses Engine (sometimes called the Machine Educable Noughts and Crosses Engine or MENACE) was a mechanical computer made from 304 matchboxes designed and built by artificial intelligence researcher Donald Michie in 1961. It was designed to play human opponents in games of noughts and crosses (tic-tac-toe) by returning a move for any given state of play and to refine its strategy through reinforcement learning.
Michie did not have a computer readily available, so he worked around this restriction by building it out of matchboxes. The matchboxes used by Michie each represented a single possible layout of a noughts and crosses grid. When the computer first played, it would randomly choose moves based on the current layout. As it played more games, through a reinforcement loop, it disqualified strategies that led to losing games, and supplemented strategies that led to winning games. Michie held a tournament against MENACE in 1961, wherein he experimented with different openings.
Following MENACE's maiden tournament against Michie, it demonstrated successful artificial intelligence in its strategy. Michie's essays on MENACE's weight initialisation and the BOXES algorithm used by MENACE became popular in the field of computer science research. Michie was honoured for his contribution to machine learning research, and was twice commissioned to program a MENACE simulation on an actual computer.",2
Technology,Open security,"Open security is the use of open source philosophies and methodologies to approach computer security and other information security challenges. Traditional application security is based on the premise that any application or service (whether it is malware or desirable) relies on security through obscurity.Open source approaches have created technology such as Linux (and to some extent, the Android operating system). Additionally, open source approaches applied to documents have inspired wikis and their largest example, Wikipedia. Open security suggests that security breaches and vulnerabilities can be better prevented or ameliorated when users facing these problems collaborate using open source philosophies.This approach requires that users be legally allowed to collaborate, so relevant software would need to be released under a license that is widely accepted to be open source; examples include the Massachusetts Institute of Technology (MIT) license, the Apache 2.0 license, the GNU Lesser General Public License (LGPL), and the GNU General Public License (GPL). Relevant documents would need to be under a generally accepted ""open content"" license; these include Creative Commons Attribution (CC-BY) and Attribution Share Alike (CC-BY-SA) licenses, but not Creative Commons ""non-commercial"" licenses or ""no-derivative"" licenses.On the developer side, legitimate software and service providers can have independent verification and testing of their source code. On the information technology side, companies can aggregate common threats, patterns, and security solutions to a variety of security issues.

",2
Technology,The Master Algorithm,"The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World is a book by Pedro Domingos released in 2015. Domingos wrote the book in order to generate interest from people outside the field.

",2
Technology,Host Based Security System,"The Host Based Security System (HBSS) is the official name given to the United States Department of Defense (DOD) commercial off-the-shelf (COTS) suite of software applications used within the DOD to monitor, detect, and defend the DOD computer networks and systems.  The Enterprise-wide Information Assurance and computer Network Defense Solutions Steering Group (ESSG) sponsored the acquisition of the HBSS System for use within the DOD Enterprise Network.  HBSS is deployed on both the Non-Classified Internet Protocol Routed Network (NIPRNet) and Secret Internet Protocol Routed Network (SIPRNet) networks, with priority given to installing it on the NIPRNet.  HBSS is based on McAfee, Inc's ePolicy Orchestrator (ePO) and other McAfee point product security applications such as Host Intrusion Prevention System (HIPS).

",2
Technology,Cybersex trafficking,"Cybersex trafficking, live streaming sexual abuse, webcam sex tourism/abuse or ICTs (Information and Communication Technologies)-facilitated sexual exploitation is a cybercrime involving sex trafficking and the live streaming of coerced sexual acts and/or rape on webcam.Cybersex trafficking is distinct from other sex crimes. Victims are transported by traffickers to 'cybersex dens', which are locations with webcams and internet-connected devices with live streaming software. There, victims are forced to perform sexual acts on themselves or other people in sexual slavery or raped by the traffickers or assisting assaulters in live videos. Victims are frequently ordered to watch the paying live distant consumers or purchasers on shared screens and follow their commands. It is often a commercialized, cyber form of forced prostitution. Women, children, and people in poverty are particularly vulnerable to coerced internet sex. The computer-mediated communication images produced during the crime are a type of rape pornography or child pornography that is filmed and broadcast in real time and can be recorded.There is no data about the magnitude of cybersex trafficking in the world. The technology to detect all incidents of the live streaming crime has not been developed yet. Millions of reports of cybersex trafficking are sent to authorities annually. It is a billion-dollar, illicit industry that was brought on with the Digital Age and is connected to globalization. It has surged from the world-wide expansion of telecommunications and global proliferation of the internet and smartphones, particularly in developing countries. It has also been facilitated by the use of software, encrypted communication systems, and network technologies that are constantly evolving, as well as the growth of international online payment systems with wire transfer services and cryptocurrencies that hide the transactor's identities.The transnational nature and global scale of cybersex trafficking necessitate a united response by the nations, corporations, and organizations of the world to reduce incidents of the crime; protect, rescue, and rehabilitate victims; and arrest and prosecute the perpetrators. Some governments have initiated advocacy and media campaigns that focus on awareness of the crime. They have also implemented training seminars held to teach law enforcement, prosecutors, and other authorities, as well as NGO workers, to combat the crime and provide trauma-informed aftercare service. New legislation combating cybersex trafficking is needed in the twenty-first century.",2
Technology,Multivariate adaptive regression spline,"In statistics, multivariate adaptive regression splines (MARS) is a form of regression analysis introduced by Jerome H. Friedman in 1991. It is a non-parametric regression technique and can be seen as an extension of linear models that automatically models nonlinearities and interactions between variables.
The term ""MARS"" is trademarked and licensed to Salford Systems. In order to avoid trademark infringements, many open-source implementations of MARS are called ""Earth"".",2
Technology,Structural risk minimization,"Structural risk minimization (SRM) is an inductive principle of use in machine learning. Commonly in machine learning, a generalized model must be selected from a finite data set, with the consequent problem of overfitting – the model becoming too strongly tailored to the particularities of the training set and generalizing poorly to new data. The SRM principle addresses this problem by balancing the model's complexity against its success at fitting the training data. This principle was first set out in a 1974 paper by Vladimir Vapnik and Alexey Chervonenkis and uses the VC dimension.
In practical terms, Structural Risk Minimization is implemented by minimizing 
  
    
      
        
          E
          
            t
            r
            a
            i
            n
          
        
        +
        β
        H
        (
        W
        )
      
    
    {\displaystyle E_{train}+\beta H(W)}
  , where 
  
    
      
        
          E
          
            t
            r
            a
            i
            n
          
        
      
    
    {\displaystyle E_{train}}
   is the train error, the function 
  
    
      
        H
        (
        W
        )
      
    
    {\displaystyle H(W)}
   is called a regularization function, and 
  
    
      
        β
      
    
    {\displaystyle \beta }
   is a constant.  
  
    
      
        H
        (
        W
        )
      
    
    {\displaystyle H(W)}
   is chosen such that it takes large values on parameters 
  
    
      
        W
      
    
    {\displaystyle W}
   that belong to high-capacity subsets of the parameter space. Minimizing 
  
    
      
        H
        (
        W
        )
      
    
    {\displaystyle H(W)}
   in effect limits the capacity of the accessible subsets of the parameter space, thereby controlling the trade-off between minimizing the training error and minimizing the expected gap between the training error and test error.The SRM problem can be formulated in terms of data. Given n data points consisting of data x and labels y, the objective 
  
    
      
        J
        (
        θ
        )
      
    
    {\displaystyle J(\theta )}
   is often expressed in the following manner:

  
    
      
        J
        (
        θ
        )
        =
        
          
            1
            
              2
              n
            
          
        
        
          ∑
          
            i
            =
            1
          
          
            n
          
        
        (
        
          h
          
            θ
          
        
        (
        
          x
          
            i
          
        
        )
        −
        
          y
          
            i
          
        
        
          )
          
            2
          
        
        +
        
          
            λ
            2
          
        
        
          ∑
          
            j
            =
            1
          
          
            d
          
        
        
          θ
          
            j
          
          
            2
          
        
      
    
    {\displaystyle J(\theta )={\frac {1}{2n}}\sum _{i=1}^{n}(h_{\theta }(x^{i})-y^{i})^{2}+{\frac {\lambda }{2}}\sum _{j=1}^{d}\theta _{j}^{2}}
  
The first term is the mean squared error (MSE) term between the value of the learned model, 
  
    
      
        
          h
          
            θ
          
        
      
    
    {\displaystyle h_{\theta }}
  , and the given labels 
  
    
      
        y
      
    
    {\displaystyle y}
  . This term is the training error, 
  
    
      
        
          E
          
            t
            r
            a
            i
            n
          
        
      
    
    {\displaystyle E_{train}}
  , that was discussed earlier. The second term, places a prior over the weights, to favor sparsity and penalize larger weights. The trade-off coefficient, 
  
    
      
        λ
      
    
    {\displaystyle \lambda }
  , is a hyperparameter that places more or less importance on the regularization term. Larger 
  
    
      
        λ
      
    
    {\displaystyle \lambda }
   encourages sparser weights at the expense of a more optimal MSE, and smaller 
  
    
      
        λ
      
    
    {\displaystyle \lambda }
   relaxes regularization allowing the model to fit to data. Note that as 
  
    
      
        λ
        →
        ∞
      
    
    {\displaystyle \lambda \to \infty }
   the weights become zero, and as 
  
    
      
        λ
        →
        0
      
    
    {\displaystyle \lambda \to 0}
  , the model typically suffers from overfitting.",2
Technology,Democratic National Committee cyber attacks,"The Democratic National Committee cyber attacks took place in 2015 and 2016, in which two groups of Russian computer hackers infiltrated the Democratic National Committee (DNC) computer network, leading to a data breach. Cybersecurity experts, as well as the U.S. government, determined that the cyberespionage was the work of Russian intelligence agencies.
Forensic evidence analyzed by several cybersecurity firms, CrowdStrike, Fidelis, and Mandiant (or FireEye), strongly indicates that two Russian intelligence agencies separately infiltrated the DNC computer systems. The American cybersecurity firm CrowdStrike, which removed the hacking programs, revealed a history of encounters with both groups and had already named them, calling one of  them Cozy Bear and the other Fancy Bear, names which are used in the media.On December 9, 2016, the CIA told U.S. legislators the U.S. Intelligence Community concluded Russia conducted the cyberattacks and other operations during the 2016 U.S. election to assist Donald Trump in winning the presidency. Multiple U.S. intelligence agencies concluded that specific individuals tied to the Russian government provided WikiLeaks with the stolen emails from the DNC, as well as stolen emails from Hillary Clinton's campaign chairman, who was also the target of a cyberattack. These intelligence organizations additionally concluded Russia hacked the Republican National Committee (R.N.C.) as well as the D.N.C., but chose not to leak information obtained from the R.N.C.

",2
Technology,Inductive probability,"Inductive probability attempts to give the probability of future events based on past events. It is the basis for inductive reasoning, and gives the mathematical basis for learning and the perception of patterns. It is a source of knowledge about the world.
There are three sources of knowledge: inference, communication, and deduction. Communication relays information found using other methods.  Deduction establishes new facts based on existing facts.  Inference establishes new facts from data. Its basis is Bayes' theorem.
Information describing the world is written in a language. For example, a simple mathematical language of propositions may be chosen. Sentences may be written down in this language as strings of characters.  But in the computer it is possible to encode these sentences as strings of bits (1s and 0s). Then the language may be encoded so that the most commonly used sentences are the shortest. This internal language implicitly represents probabilities of statements.
Occam's razor says the ""simplest theory, consistent with the data is most likely to be  correct"". The ""simplest theory"" is interpreted as the representation of the theory written in this internal language. The theory with the shortest encoding in this internal language is most likely to be correct.",2
Technology,Pythia (machine learning),"Pythia is an ancient text restoration model that recovers missing characters from a damaged text input using deep neural networks. It was created by Yannis Assael, Thea Sommerschield, and Jonathan Prag, researchers from Google DeepMind and the University of Oxford.To study the society and the history of ancient civilisations, ancient history relies on disciplines such as Epigraphy, the study of ancient inscribed texts. Hundreds of thousands of these texts, known as inscriptions, have survived to our day, but are often damaged over the centuries. Illegible parts of the text must then be restored by specialists, called epigraphists, in order to extract meaningful information from the text and use it to expand our knowledge of the context in which the text was written. Pythia takes as input the damaged text, and is trained to return hypothesised restorations of ancient Greek inscriptions, working as an assistive aid for ancient historians. Its neural network architecture works at both the character- and word-level, thereby effectively handling long-term context information, and dealing efficiently with incomplete word representations. Pythia is applicable to any discipline dealing with ancient texts (philology, papyrology, codicology) and can work in any language (ancient or modern).",2
Technology,Tsetlin machine,A Tsetlin Machine is an Artificial Intelligence algorithm based on propositional logic.,2
Technology,Knowledge integration,"Knowledge integration is the process of synthesizing multiple knowledge models (or representations) into a common model (representation).
Compared to information integration, which involves merging information having different schemas and representation models, knowledge integration focuses more on synthesizing the understanding of a given subject from different perspectives.
For example, multiple interpretations are possible of a set of student grades, typically each from a certain perspective. An overall, integrated view and understanding of this information can be achieved if these interpretations can be put under a common model, say, a student performance index.
The Web-based Inquiry Science Environment (WISE), from the University of California at Berkeley has been developed along the lines of knowledge integration theory.
Knowledge integration has also been studied as the process of incorporating new information into a body of existing knowledge with an interdisciplinary approach.  This process involves determining how the new information and the existing knowledge interact, how existing knowledge should be modified to accommodate the new information, and how the new information should be modified in light of the existing knowledge.
A learning agent that actively investigates the consequences of new information can detect and exploit a variety of learning opportunities; e.g., to resolve knowledge conflicts and to fill knowledge gaps.  By exploiting these learning opportunities the learning agent is able to learn beyond the explicit content of the new information.
The machine learning program KI, developed by Murray and Porter at the University of Texas at Austin, was created to study the use of automated and semi-automated knowledge integration to assist knowledge engineers constructing a large knowledge base.
A possible technique which can be used is semantic matching. More recently, a technique useful to minimize the effort in mapping validation and visualization has been presented which is based on Minimal Mappings. Minimal mappings are high quality mappings such that i) all the other mappings can be computed from them in time linear in the size of the input graphs, and ii) none of them can be dropped without losing property i).
The University of Waterloo operates a Bachelor of Knowledge Integration undergraduate degree program as an academic major or minor. The program started in 2008.

",2
Technology,Social software engineering,"Social software engineering (SSE) is a branch of software engineering that is concerned with the social aspects of software development and the developed software.
SSE focuses on the socialness of both software engineering and developed software. On the one hand, the consideration of social factors in software engineering activities, processes and CASE tools is deemed to be useful to improve the quality of both development process and produced software. Examples include the role of situational awareness and multi-cultural factors in collaborative software development. On the other hand, the dynamicity of the social contexts in which software could operate (e.g., in a cloud environment) calls for engineering social adaptability as a runtime iterative activity. Examples include approaches which enable software to gather users' quality feedback and use it to adapt autonomously or semi-autonomously.
SSE studies and builds socially-oriented tools to support collaboration and knowledge sharing in software engineering. SSE also investigates the adaptability of software to the dynamic social contexts in which it could operate and the involvement of clients and end-users in shaping software adaptation decisions at runtime. Social context includes norms, culture, roles and responsibilities, stakeholder's goals and interdependencies, end-users perception of the quality and appropriateness of each software behaviour, etc.
The participants of the 1st International Workshop on Social Software Engineering and Applications (SoSEA 2008) proposed the following characterization:

Community-centered: Software is produced and consumed by and/or for a community rather than focusing on individuals
Collaboration/collectiveness: Exploiting the collaborative and collective capacity of human beings
Companionship/relationship: Making explicit the various associations among people
Human/social activities: Software is designed consciously to support human activities and to address social problems
Social inclusion: Software should enable social inclusion enforcing links and trust in communitiesThus, SSE can be defined as ""the application of processes, methods, and tools to enable community-driven creation, management, deployment, and use of software in online environments"".One of the main observations in the field of SSE is that the concepts, principles, and technologies made for social software applications are applicable to software development itself as software engineering is inherently a social activity. SSE is not limited to specific activities of software development. Accordingly, tools have been proposed supporting different parts of SSE, for instance, social system design or social requirements engineering. 
Consequently vertical market software, such as software development tools, engineering tools, marketing tools or software that helps users in a decision making process can profit from social components. Such vertical social software differentiates strongly in its user-base from traditional social software such as Yammer.

",2
Technology,Computational learning theory,"In computer science, computational learning theory (or just learning theory) is a subfield of artificial intelligence devoted to studying the design and analysis of machine learning algorithms.",2
Technology,Committee machine,"A committee machine is a type of artificial neural network using a divide and conquer strategy in which the responses of multiple neural networks (experts) are combined into a single response.  The combined response of the committee machine is supposed to be superior to those of its constituent experts.  Compare with ensembles of classifiers.

",2
Technology,System context diagram,"A system context diagram (SCD) in engineering is a diagram that defines the boundary between the system, or part of a system, and its environment, showing the entities that interact with it. This diagram is a high level view of a system. It is similar to a block diagram.

",2
Technology,Convolutional neural network,"In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of artificial neural network (ANN), most commonly applied to analyze visual imagery. CNNs are also known as Shift Invariant or Space Invariant Artificial Neural Networks (SIANN), based on the shared-weight architecture of the convolution kernels or filters that slide along input features and provide translation-equivariant responses known as feature maps. Counter-intuitively, most convolutional neural networks are only equivariant, as opposed to invariant, to translation. They have applications in image and video recognition, recommender systems, image classification, image segmentation, medical image analysis, natural language processing, brain–computer interfaces, and financial time series.CNNs are regularized versions of multilayer perceptrons. Multilayer perceptrons usually mean fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The ""full connectivity"" of these networks make them prone to overfitting data. Typical ways of regularization, or preventing overfitting, include: penalizing parameters during training (such as weight decay) or trimming connectivity (skipped connections, dropout, etc.) CNNs take a different approach towards regularization: they take advantage of the hierarchical pattern in data and assemble patterns of increasing complexity using smaller and simpler patterns embossed in their filters. Therefore, on a scale of connectivity and complexity, CNNs are on the lower extreme.
Convolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.
CNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns to optimize the filters (or kernels) through automated learning, whereas in traditional algorithms these filters are hand-engineered. This independence from prior knowledge and human intervention in feature extraction is a major advantage.",2
Technology,Large margin nearest neighbor,"Large margin nearest neighbor (LMNN) classification is a statistical machine learning algorithm for metric learning. It learns a pseudometric designed for k-nearest neighbor classification. The algorithm is based on semidefinite programming, a sub-class of convex optimization.
The goal of supervised learning (more specifically classification) is to learn a decision rule that can categorize data instances into pre-defined classes. The  k-nearest neighbor rule assumes a training data set of labeled instances (i.e. the classes are known). It classifies a new data instance with the class obtained from the majority vote of the k closest (labeled) training instances. Closeness is measured with a pre-defined metric. Large margin nearest neighbors is an algorithm that learns this global (pseudo-)metric in a supervised fashion to improve the classification accuracy of the k-nearest neighbor rule.",2
Technology,Programming by example,"In computer science, programming by example (PbE), also termed programming by demonstration or more generally as demonstrational programming, is an end-user development technique for teaching a computer new behavior by demonstrating actions on concrete examples. The system records user actions and infers a generalized program that can be used on new examples.
PbE is intended to be easier to do than traditional computer programming, which generally requires learning and using a programming language.  Many PbE systems have been developed as research prototypes, but few have found widespread real-world application.  More recently, PbE has proved to be a useful paradigm for creating scientific work-flows. PbE is used in two independent clients for the BioMOBY protocol: Seahawk and Gbrowse moby.
Also the programming by demonstration (PbD) term has been mostly adopted by robotics researchers for teaching new behaviors to the robot through a physical demonstration of the task. The usual distinction in literature between these terms is that in PbE the user gives a prototypical product of the computer execution, such as a row in the desired results of a query; while in PbD the user performs a sequence of actions that the computer must repeat, generalizing it to be used in different data sets. For final users, to automate a workflow in a complex tool (e.g. Photoshop), the most simple case of PbD is the  macro recorder.",2
Technology,Paraphrasing (computational linguistics),"Paraphrase or paraphrasing in computational linguistics is the natural language processing task of detecting and generating paraphrases. Applications of paraphrasing are varied including information retrieval, question answering, text summarization, and plagiarism detection. Paraphrasing is also useful in the evaluation of machine translation, as well as semantic parsing and generation of new samples to expand existing corpora.

",2
Technology,Product of experts,"Product of experts (PoE) is a machine learning technique. It models a probability distribution by combining the output from several simpler distributions.
It was proposed by Geoffrey Hinton, along with an algorithm for training the parameters of such a system.
The core idea is to combine several probability distributions (""experts"") by multiplying their density functions—making the PoE classification similar to an ""and"" operation. This allows each expert to make decisions on the basis of a few dimensions without having to cover the full dimensionality of a problem.
This is related to (but quite different from) a mixture model, where several probability distributions are combined via an ""or"" operation, which is a weighted sum of their density functions.",2
Technology,Systems modeling,"Systems modeling or system modeling is the interdisciplinary study of the use of models to conceptualize and construct systems in business and IT development.A common type of systems modeling is function modeling, with specific techniques such as the Functional Flow Block Diagram and IDEF0. These models can be extended using functional decomposition, and can be linked to requirements models for further systems partition.
Contrasting the functional modeling, another type of systems modeling is architectural modeling which uses the systems architecture to conceptually model the structure, behavior, and more views of a system.
The Business Process Modeling Notation (BPMN), a graphical representation for specifying business processes in a workflow, can also be considered to be a systems modeling language.

",2
Technology,Algorithmic inference,"Algorithmic inference gathers new developments in the statistical inference methods made feasible by the powerful computing devices widely available to any data analyst. Cornerstones in this field are computational learning theory, granular computing, bioinformatics, and, long ago, structural probability (Fraser 1966).
The main focus is on the algorithms which compute statistics rooting the study of a random phenomenon, along with the amount of data they must feed on to produce reliable results. This shifts the interest of mathematicians from the study of the distribution laws to the functional properties of the statistics, and the interest of computer scientists from the algorithms for processing data to the information they process.",2
Technology,Cyber self-defense,"In cybersecurity, cyber self-defense refers to self-defense against cyberattack. While it generally emphasizes active cybersecurity measures by computer users themselves, cyber self-defense is sometimes used to refer to the self-defense of organizations as a whole, such as corporate entities or entire nations. Surveillance self-defense is a variant of cyber self-defense and largely overlaps with it. Active and passive cybersecurity measures provide defenders with higher levels of cybersecurity, intrusion detection, incident handling and remediation capabilities.  Various sectors and organizations are legally obligated to adhere to cyber security standards.

",2
Technology,Discovery system (AI research),"A discovery system is an artificial intelligence system that attempts to discover new scientific concepts or laws.
Notable discovery systems have included:

Autoclass
Automated Mathematician
DALTON
Eurisko
Glauber
Machine for Questions and Answers
Stahl

",2
Technology,"Training, validation, and test data sets","In machine learning, a common task is the study and construction of algorithms that can learn from and make predictions on data. Such algorithms function by making data-driven predictions or decisions, through building a mathematical model from input data. These input data used to build the model are usually divided in multiple data sets. In particular, three data sets are commonly used in different stages of the creation of the model: training, validation and test sets.
The model is initially fit on a training data set, which is a set of examples used to fit the parameters (e.g. weights of connections between neurons in artificial neural networks) of the model. The model (e.g. a naive Bayes classifier) is trained on the training data set using a supervised learning method, for example using optimization methods such as gradient descent or stochastic gradient descent. In practice, the training data set often consists of pairs of an input vector (or scalar) and the corresponding output vector (or scalar), where the answer key is commonly denoted as the target (or label). The current model is run with the training data set and produces a result, which is then compared with the target, for each input vector in the training data set. Based on the result of the comparison and the specific learning algorithm being used, the parameters of the model are adjusted. The model fitting can include both variable selection and parameter estimation.
Successively, the fitted model is used to predict the responses for the observations in a second data set called the validation data set. The validation data set provides an unbiased evaluation of a model fit on the training data set while tuning the model's hyperparameters (e.g. the number of hidden units—layers and layer widths—in a neural network). Validation datasets can be used for regularization by early stopping (stopping training when the error on the validation data set increases, as this is a sign of over-fitting to the training data set).
This simple procedure is complicated in practice by the fact that the validation dataset's error may fluctuate during training, producing multiple local minima. This complication has led to the creation of many ad-hoc rules for deciding when over-fitting has truly begun.Finally, the test data set is a data set used to provide an unbiased evaluation of a final model fit on the training data set. If the data in the test data set has never been used in training (for example in cross-validation), the test data set is also called a holdout data set. The term ""validation set"" is sometimes used instead of ""test set"" in some literature (e.g., if the original data set was partitioned into only two subsets, the test set might be referred to as the validation set).Deciding the sizes and strategies for data set division in training, test and validation sets is very dependent on the problem and data available.

",2
Technology,National Cyber Security Awareness Month,"National Cyber Security Awareness Month (NCSAM) is observed in October in the United States of America. Started by the National Cyber Security Division within the Department of Homeland Security and the nonprofit National Cyber Security Alliance, the month raises awareness about the importance of cybersecurity.",2
Technology,Principle of least privilege,"In information security, computer science, and other fields, the principle of least privilege (PoLP), also known as the principle of minimal privilege or the principle of least authority, requires that in a particular abstraction layer of a computing environment, every module (such as a process, a user, or a program, depending on the subject) must be able to access only the information and resources that are necessary for its legitimate purpose.",2
Technology,Machine learning in bioinformatics,"Machine learning in bioinformatics is the application of machine learning algorithms to bioinformatics, including genomics, proteomics, microarrays, systems biology, evolution, and text mining.Prior to the emergence of machine learning, bioinformatics algorithms had to be programmed by hand; for problems such as protein structure prediction, this proved difficult. Machine learning techniques, such as deep learning can learn features of data sets, instead of requiring the programmer to define them individually. The algorithm can further learn how to combine low-level features into more abstract features, and so on. This multi-layered approach allows such systems to make sophisticated predictions when appropriately trained. These methods contrast with other computational biology approaches which, while exploiting existing datasets, do not allow the data to be interpreted and analyzed in unanticipated ways. In recent years, the size and number of available biological datasets have skyrocketed.",2
Technology,Information Security Automation Program,"The Information Security Automation Program (ISAP, pronounced “I Sap”) is a U.S. government multi-agency initiative to enable automation and standardization of technical security operations. While a U.S. government initiative, its standards based design can benefit all information technology security operations. The ISAP high level goals include standards based automation of security checking and remediation as well as automation of technical compliance activities (e.g. FISMA). ISAP's low level objectives include enabling standards based communication of vulnerability data, customizing and managing configuration baselines for various IT products, assessing information systems and reporting compliance status, using standard metrics to weight and aggregate potential vulnerability impact, and remediating identified vulnerabilities.
ISAP's technical specifications are contained in the related Security Content Automation Protocol (SCAP). ISAP's security automation content is either contained within, or referenced by, the National Vulnerability Database. 
ISAP is being formalized through a trilateral memorandum of agreement (MOA) between Defense Information Systems Agency (DISA), the National Security Agency (NSA), and the National Institute of Standards and Technology (NIST).  The Office of the Secretary of Defense (OSD) also participates and the Department of Homeland Security (DHS) funds the operation infrastructure on which ISAP relies (i.e., the National Vulnerability Database).",2
Technology,Learning with errors,"Learning with errors (LWE) is the computational problem of inferring a linear 
  
    
      
        n
      
    
    {\displaystyle n}
  -ary function 
  
    
      
        f
      
    
    {\displaystyle f}
   over a finite ring from given samples 
  
    
      
        
          y
          
            i
          
        
        =
        f
        (
        
          
            x
          
          
            i
          
        
        )
      
    
    {\displaystyle y_{i}=f(\mathbf {x} _{i})}
   some of which may be erroneous.
The LWE problem is conjectured to be hard to solve, and thus to be useful in cryptography.
More precisely, the LWE problem is defined as follows. Let 
  
    
      
        
          
            Z
          
          
            q
          
        
      
    
    {\displaystyle \mathbb {Z} _{q}}
   denote the ring of integers modulo 
  
    
      
        q
      
    
    {\displaystyle q}
   and let

  
    
      
        
          
            Z
          
          
            q
          
          
            n
          
        
      
    
    {\displaystyle \mathbb {Z} _{q}^{n}}
   denote the set of 
  
    
      
        n
      
    
    {\displaystyle n}
  -vectors over 
  
    
      
        
          
            Z
          
          
            q
          
        
      
    
    {\displaystyle \mathbb {Z} _{q}}
  . There exists a certain unknown linear function 
  
    
      
        f
        :
        
          
            Z
          
          
            q
          
          
            n
          
        
        →
        
          
            Z
          
          
            q
          
        
      
    
    {\displaystyle f:\mathbb {Z} _{q}^{n}\rightarrow \mathbb {Z} _{q}}
  , and the input to the LWE problem is a sample of pairs 
  
    
      
        (
        
          x
        
        ,
        y
        )
      
    
    {\displaystyle (\mathbf {x} ,y)}
  , where 
  
    
      
        
          x
        
        ∈
        
          
            Z
          
          
            q
          
          
            n
          
        
      
    
    {\displaystyle \mathbf {x} \in \mathbb {Z} _{q}^{n}}
   and 
  
    
      
        y
        ∈
        
          
            Z
          
          
            q
          
        
      
    
    {\displaystyle y\in \mathbb {Z} _{q}}
  , so that with high probability 
  
    
      
        y
        =
        f
        (
        
          x
        
        )
      
    
    {\displaystyle y=f(\mathbf {x} )}
  . Furthermore, the deviation from the equality is according to some known noise model. The problem calls for finding the function 
  
    
      
        f
      
    
    {\displaystyle f}
  , or some close approximation thereof, with high probability.
The LWE problem was introduced by Oded Regev in 2005 (who won the 2018 Gödel Prize for this work), it is a generalization of the parity learning problem. Regev showed that the LWE problem is as hard to solve as several worst-case lattice problems. Subsequently, the LWE problem has been used as a hardness assumption to create public-key cryptosystems, such as the ring learning with errors key exchange by Peikert.",2
Technology,Centurion guard,"The Centurion Guard is a PC hardware and software based security product developed by Centurion Technologies and released in 1996.  There were many different releases and versions of this product, and many were distributed in the Bill & Melinda Gates Foundation computers that were donated to libraries.",2
Technology,M-Theory (learning framework),"In Machine Learning and Computer Vision, M-Theory is a learning framework inspired by feed-forward processing in the ventral stream of visual cortex and originally developed for recognition and classification of objects in visual scenes. M-Theory was later applied to other areas, such as speech recognition. On certain image recognition tasks, algorithms based on a specific instantiation of M-Theory, HMAX, achieved human-level performance.The core principle of M-Theory is extracting representations invariant to various transformations of images (translation, scale, 2D and 3D rotation and others). In contrast with other approaches using invariant representations, in M-Theory they are not hardcoded into the algorithms, but learned. M-Theory also shares some principles with Compressed Sensing. The theory proposes multilayered hierarchical learning architecture, similar to that of visual cortex.",2
Technology,Human–computer interaction (security),"HCISec is the study of interaction between humans and computers, or human–computer interaction, specifically as it pertains to information security.  Its aim, in plain terms, is to improve the usability of security features in end user applications.  
Unlike HCI, which has roots in the early days of Xerox PARC during the 1970s, HCISec is a nascent field of study by comparison. Interest in this topic tracks with that of Internet security, which has become an area of broad public concern only in very recent years.
When security features exhibit poor usability, the following are common reasons:

they were added in casual afterthought
they were hastily patched in to address newly discovered security bugs
they address very complex use cases without the benefit of a software wizard
their interface designers lacked understanding of related security concepts
their interface designers were not usability experts (often meaning they were the application developers themselves)",2
Technology,Elastic matching,"Elastic matching is one of the pattern recognition techniques in computer science. Elastic matching (EM) is also known as deformable template, flexible matching, or nonlinear template matching.Elastic matching can be defined as an optimization problem of two-dimensional warping specifying corresponding pixels between subjected images.",2
Technology,Bayesian structural time series,"Bayesian structural time series (BSTS) model is a statistical technique used for feature selection, time series forecasting, nowcasting, inferring causal impact and other applications. The model is designed to work with time series data.
The model has also promising application in the field of analytical marketing. In particular, it can be used in order to assess how much different marketing campaigns have contributed to the change in web search volumes, product sales, brand popularity and other relevant indicators. Difference-in-differences models and interrupted time series designs are alternatives to this approach. ""In contrast to classical difference-in-differences schemes, state-space models make it possible to (i) infer the temporal evolution of attributable impact, (ii) incorporate empirical priors on the parameters in a fully Bayesian treatment, and (iii) flexibly accommodate multiple sources of variation, including the time-varying influence of contemporaneous covariates, i.e., synthetic controls.""",2
Technology,Transfer learning,"Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks.  This area of research bears some relation to the long history of psychological literature on transfer of learning, although practical ties between the two fields are limited. From the practical standpoint, reusing or transferring information from previously learned tasks for the learning of new tasks has the potential to significantly improve the sample efficiency of a reinforcement learning agent.

",2
Technology,Cybersecurity Information Sharing Act,"The Cybersecurity Information Sharing Act (CISA S. 2588 [113th Congress], S. 754 [114th Congress]) is a United States federal law designed to ""improve cybersecurity in the United States through enhanced sharing of information about cybersecurity threats, and for other purposes"". The law allows the sharing of Internet traffic information between the U.S. government and technology and manufacturing companies. The bill was introduced in the U.S. Senate on July 10, 2014, and passed in the Senate October 27, 2015.  Opponents question CISA's value, believing it will move responsibility from private businesses to the government, thereby increasing vulnerability of personal private information, as well as dispersing personal private information across seven government agencies, including the NSA and local police.
The text of the bill was incorporated by amendment into a consolidated spending bill in the U.S. House on December 15, 2015, which was signed into law by President Barack Obama on December 18, 2015.",2
Technology,PRODIGAL (computer system),"PRODIGAL (proactive discovery of insider threats using graph analysis and learning) is a computer system for predicting anomalous behavior among humans, by data mining network traffic such as emails, text messages and server log entries. It is part of DARPA's Anomaly Detection at Multiple Scales (ADAMS) project. The initial schedule is for two years and the budget $9 million.It uses graph theory, machine learning, statistical anomaly detection, and high-performance computing to scan larger sets of data more quickly than in past systems. The amount of data analyzed is in the range of terabytes per day. The targets of the analysis are employees within the government or defense contracting organizations; specific examples of behavior the system is intended to detect include the actions of Nidal Malik Hasan and WikiLeaks source Chelsea Manning. Commercial applications may include finance. The results of the analysis, the five most serious threats per day, go to agents, analysts, and operators working in counterintelligence.",2
Technology,Software configuration management,"In software engineering, software configuration management (SCM or S/W CM) is the task of tracking and controlling changes in the software, part of the larger cross-disciplinary field of configuration management.  SCM practices include revision control and the establishment of baselines.  If something goes wrong, SCM can determine what was changed and who changed it.  If a configuration is working well, SCM can determine how to replicate it across many hosts.
The acronym ""SCM"" is also expanded as source configuration management process and software change and configuration management.  However, ""configuration"" is generally understood to cover changes typically made by a system administrator.",2
Technology,Software bot,"A software bot is a type of software agent in the service of software project management and software engineering. A software bot has an identity and potentially personified aspects in order to serve their stakeholders. Software bots often compose software services and provide an alternative user interface, which is sometimes, but not necessarily conversational.
Software bots are typically used to execute tasks, suggest actions, engage in dialogue, and promote social and cultural aspects of a software project.The term bot is derived from robot. However, robots act in the physical world and software bots act only in digital spaces. Some software bots are designed and behave as chatbots, but not all chatbots are software bots.  Erlenhov et al. discuss the past and future of software bots and show that software bots have been adopted for many years.",2
Technology,STRIDE (security),"STRIDE is a model for identifying computer security threats developed by Praerit Garg and Loren Kohnfelder at Microsoft.   It provides a mnemonic for security threats in six categories.The threats are:

Spoofing
Tampering
Repudiation
Information disclosure (privacy breach or data leak)
Denial of service
Elevation of privilegeThe STRIDE was initially created as part of the process of threat modeling.  STRIDE is a model of threats, used to help reason and find threats to a system.  It is used in conjunction with a model of the target system that can be constructed in parallel.  This includes a full breakdown of processes, data stores, data flows, and trust boundaries.Today it is often used by security experts to help answer the question ""what can go wrong in this system we're working on?""
Each threat is a violation of a desirable property for a system:",2
Technology,Associative classifier,"An associative classifier (AC) is a kind of supervised learning model that uses association rules to assign a target value. The term associative classification was coined by Bing Liu et al., in which the authors defined a model made of rules ""whose right-hand side are restricted to the classification class attribute"".",2
Technology,Highway network,"In machine learning, the Highway Network was the first working very deep feedforward neural network with hundreds of layers, much deeper than previous artificial neural networks.
It uses skip connections modulated by learned gating mechanisms to regulate information flow, inspired by Long Short-Term Memory (LSTM) recurrent neural networks.
The advantage of a Highway Network over the common deep neural networks is that it solves or partially prevents the vanishing gradient problem, thus leading to easier to optimize neural networks.
The gating mechanisms facilitate information flow across many layers (""information highways"").Highway Networks have been used as part of text sequence labeling and speech recognition tasks.
An open-gated or gateless Highway Network variant called Residual neural network was used to win the ImageNet 2015 competition. This has become the most cited neural network of the 21st century.",2
Technology,Computer security compromised by hardware failure,"Computer security compromised by hardware failure is a branch of computer security applied to hardware.
The objective of computer security includes protection of information and property from theft, corruption, or natural disaster, while allowing the information and property to remain accessible and productive to its intended users. Such secret information could be retrieved by different ways. This article focus on the retrieval of data thanks to misused hardware or hardware failure. Hardware could be misused or exploited to get secret data. This article collects main types of attack that can lead to data theft.
Computer security can be comprised by devices, such as keyboards, monitors or printers (thanks to electromagnetic or acoustic emanation for example) or by components of the computer, such as the memory, the network card or the processor (thanks to time or temperature analysis for example).",2
Technology,Constrained conditional model,"A constrained conditional model (CCM) is a machine learning and inference framework that augments the learning of conditional (probabilistic or discriminative) models with declarative constraints. The constraint can be used as a way to incorporate expressive prior knowledge into the model and bias the assignments made by the learned model to satisfy these constraints. The framework can be used to support decisions in an expressive output space while maintaining modularity and tractability of training and inference.
Models of this kind have recently attracted much attention within the natural language processing (NLP) community.
Formulating problems as constrained optimization problems over the output of learned models has several advantages. It allows one to focus on the modeling of problems by providing the opportunity to incorporate domain-specific knowledge as global constraints using a first order language. Using this declarative framework frees the developer from low level feature engineering while capturing the problem's domain-specific properties and guarantying exact inference. From a machine learning perspective it allows decoupling the stage of model generation (learning) from that of the constrained inference stage, thus helping to simplify the learning stage while improving the quality of the solutions. For example, in the case of generating compressed sentences, rather than simply relying on a language model to retain the most commonly used n-grams in the sentence, constraints can be used to ensure that if a modifier is kept in the compressed sentence, its subject will also be kept.

",2
Technology,Cure53,"Cure53 is a German cybersecurity firm. The company was founded by Dr. Mario Heidrich, a client side security researcher.
After a report from Cure53 on the South Korean security app Smart Sheriff, that described the apps security holes as ""catastrophic"", the South Korean government ordered the Smart Sheriff to be shut down.

",2
Technology,Software Guard Extensions,"Intel Software Guard Extensions (SGX) is a set of security-related instruction codes that are built into some Intel central processing units (CPUs). They allow user-level and operating system code to define private regions of memory, called enclaves, whose contents is inaccessible from the outside. SGX is designed to be useful for implementing secure remote computation, secure web browsing, and digital rights management (DRM). Other applications include concealment of proprietary algorithms and of encryption keys.SGX involves encryption by the CPU of a portion of memory (the enclave). Data and code originating in the enclave are decrypted on the fly within the CPU, protecting them from being examined or read by other code, including code running at higher privilege levels such the operating system and any underlying hypervisors. While this can mitigate many kinds of attacks, it does not protect against side-channel attacks.A pivot by Intel in 2021 resulted in the deprecation of SGX from the 11th and 12th generation Intel Core Processors, but development continues on Intel Xeon for cloud and enterprise use.

",2
Technology,Separation of protection and security,"In computer sciences the separation of protection and security is a design choice. Wulf et al. identified protection as a mechanism and security as a policy, therefore making the protection-security distinction a particular case of the separation of mechanism and policy principle.  Many frameworks consider both as Security controls of varying types. For example, protection mechanisms would be considered technical controls, while a policy would be considered an administrative control.",2
Technology,Inductive bias,"The inductive bias (also known as learning bias) of a learning algorithm is the set of assumptions that the learner uses to predict outputs of given inputs that it has not encountered.In machine learning, one aims to construct algorithms that are able to learn to predict a certain target output. To achieve this, the learning algorithm is presented some training examples that demonstrate the intended relation of input and output values. Then the learner is supposed to approximate the correct output, even for examples that have not been shown during training.  Without any additional assumptions, this problem cannot be solved since unseen situations might have an arbitrary output value. The kind of necessary assumptions about the nature of the target function are subsumed in the phrase inductive bias.A classical example of an inductive bias is Occam's razor, assuming that the simplest consistent hypothesis about the target function is actually the best. Here consistent means that the hypothesis of the learner yields correct outputs for all of the examples that have been given to the algorithm.
Approaches to a more formal definition of inductive bias are based on mathematical logic. Here, the inductive bias is a logical formula that, together with the training data, logically entails the hypothesis generated by the learner. However, this strict formalism fails in many practical cases, where the inductive bias can only be given as a rough description (e.g. in the case of artificial neural networks), or not at all.

",2
Technology,Neural network quantum states,"Quantum neural networks are computational neural network models which are based on the principles of quantum mechanics. The first ideas on quantum neural computation were published independently in 1995 by Subhash Kak and Ron Chrisley, engaging with the theory of quantum mind, which posits that quantum effects play a role in cognitive function. However, typical research in quantum neural networks involves combining classical artificial neural network models (which are widely used in machine learning for the important task of pattern recognition) with the advantages of quantum information in order to develop more efficient algorithms. One important motivation for these investigations is the difficulty to train classical neural networks, especially in big data applications. The hope is that features of quantum computing such as quantum parallelism or the effects of interference and entanglement can be used as resources. Since the technological implementation of a quantum computer is still in a premature stage, such quantum neural network models are mostly theoretical proposals that await their full implementation in physical experiments.
Most Quantum neural networks are developed as feed-forward networks. Similar to their classical counterparts, this structure intakes input from one layer of qubits, and passes that input onto another layer of qubits. This layer of qubits evaluates this information and passes on the output to the next layer. Eventually the path leads to the final layer of qubits. The layers do not have to be of the same width, meaning they don't have to have the same number of qubits as the layer before or after it. This structure is trained on which path to take similar to classical artificial neural networks. This is discussed in a lower section. Quantum neural networks refer to three different categories: Quantum computer with classical data, classical computer with quantum data, and quantum computer with quantum data.",2
Technology,Semantic folding,"Semantic folding theory describes a procedure for encoding the semantics of natural language text in a semantically grounded binary representation. This approach provides a framework for modelling how language data is processed by the neocortex.

",2
Technology,Bayesian learning mechanisms,"Bayesian learning mechanisms are probabilistic causal models used in computer science to research the fundamental underpinnings of machine learning, and in cognitive neuroscience, to model conceptual development.Bayesian learning mechanisms have also been used in economics and cognitive psychology to study social learning in theoretical models of herd behavior.",2
Technology,Count sketch,"Count sketch  is a type of dimensionality reduction that is particularly efficient in statistics, machine learning and algorithms.
It was invented by 
Moses Charikar, Kevin Chen and Martin Farach-Colton in an effort to speed up the AMS Sketch by Alon, Matias and Szegedy for approximating the frequency moments of streams.The sketch is nearly identical to the Feature hashing algorithm by John Moody, but differs in its use of hash functions with low dependence, which makes it more practical.
In order to still have a high probability of success, the median trick is used to aggregate multiple count sketches, rather than the mean.
These properties allow use for explicit kernel methods, bilinear pooling in neural networks and is a cornerstone in many numerical linear algebra algorithms.",2
Technology,Eager learning,"In artificial intelligence, eager learning is a learning method in which the system tries to construct a general, input-independent target function during training of the system, as opposed to lazy learning, where generalization beyond the training data is delayed until a query is made to the system. 
The main advantage gained in employing an eager learning method, such as an artificial neural network, is that the target function will be approximated globally during training, thus requiring much less space than using a lazy learning system. Eager learning systems also deal much better with noise in the training data. Eager learning is an example of offline learning, in which post-training queries to the system have no effect on the system itself, and thus the same query to the system will always produce the same result.
The main disadvantage with eager learning is that it is generally unable to provide good local approximations in the target function.",2
Technology,System appreciation,"System appreciation is an activity often included in the maintenance phase of software engineering projects.  Key deliverables from this phase include documentation that describes what the system does in terms of its functional features, and how it achieves those features in terms of its architecture and design.  Software architecture recovery is often the first step within System appreciation.

",2
Technology,Security log,"A security log is used to track security-related information on a computer system. Examples include:

Windows Security Log
Internet Connection Firewall security logAccording to Stefan Axelsson, ""Most UNIX installations do not run any form of security logging software, mainly because the security logging facilities are expensive in terms of disk storage, processing time, and the cost associated with analyzing the audit trail, either manually or by special software.""",2
Technology,OpenNN,"OpenNN (Open Neural Networks Library) is a software library written in the C++ programming language which implements neural networks, a main area of deep learning research. The library is open-source, licensed under the GNU Lesser General Public License.

",2
Technology,SMBGhost,"SMBGhost (or SMBleedingGhost or CoronaBlue) is a type of security vulnerability, with wormlike features, that affects Windows 10 computers and was first reported publicly on 10 March 2020. A Proof-of-Concept (PoC) exploit code was published 1 June 2020 on GitHub by a security researcher. The code could possibly spread to millions of unpatched computers, resulting in as much as tens of billions of dollars in losses.Microsoft recommends all users of Windows 10 versions 1903 and 1909 and Windows Server versions 1903 and 1909 to install patches, and states, ""We recommend customers install updates as soon as possible as publicly disclosed vulnerabilities have the potential to be leveraged by bad actors ... An update for this vulnerability was released in March [2020], and customers who have installed the updates, or have automatic updates enabled, are already protected.""  Workarounds, according to Microsoft, such as disabling SMB compression and blocking port 445, may help but may not be sufficient.According to the advisory division of Homeland Security, ""Malicious cyber actors are targeting unpatched systems with the new [threat], ... [and] strongly recommends using a firewall to block server message block ports from the internet and to apply patches to critical- and high-severity vulnerabilities as soon as possible.""",2
Technology,Multiple instance learning,"In machine learning, multiple-instance learning (MIL) is a type of supervised learning.  Instead of receiving a set of instances which are individually labeled, the learner receives a set of labeled bags, each containing many instances. In the simple case of multiple-instance binary classification, a bag may be labeled negative if all the instances in it are negative.  On the other hand, a bag is labeled positive if there is at least one instance in it which is positive.  From a collection of labeled bags, the learner tries to either (i) induce a concept that will label individual instances correctly or (ii) learn how to label bags without inducing the concept.
Babenko (2008) gives a simple example for MIL. Imagine several people, and each of them has a key chain that contains few keys. Some of these people are able to enter a certain room, and some aren’t. The task is then to predict whether a certain key or a certain key chain can get you into that room. To solve this problem we need to find the exact key that is common for all the “positive” key chains. If we can correctly identify this key, we can also correctly classify an entire key chain - positive if it contains the required key, or negative if it doesn't.",2
Technology,Sparse dictionary learning,"Sparse coding is a representation learning method which aims at finding a sparse representation of the input data (also known as sparse coding) in the form of a linear combination of basic elements as well as those basic elements themselves. These elements are called atoms and they compose a dictionary. Atoms in the dictionary are not required to be orthogonal, and they may be an over-complete spanning set. This problem setup also allows the dimensionality of the signals being represented to be higher than the one of the signals being observed. The above two properties lead to having seemingly redundant atoms that allow multiple representations of the same signal but also provide an improvement in sparsity and flexibility of the representation.
One of the most important applications of sparse dictionary learning is in the field of compressed sensing or signal recovery. In compressed sensing, a high-dimensional signal can be recovered with only a few linear measurements provided that the signal is sparse or nearly sparse. Since not all signals satisfy this sparsity condition, it is of great importance to find a sparse representation of that signal such as the wavelet transform or the directional gradient of a rasterized matrix. Once a matrix or a high dimensional vector is transferred to a sparse space, different recovery algorithms like basis pursuit, CoSaMP or fast non-iterative algorithms can be used to recover the signal.
One of the key principles of dictionary learning is that the dictionary has to be inferred from the input data. The emergence of sparse dictionary learning methods was stimulated by the fact that in signal processing one typically wants to represent the input data using as few components as possible. Before this approach the general practice was to use predefined dictionaries (such as Fourier or wavelet transforms). However, in certain cases a dictionary that is trained to fit the input data can significantly improve the sparsity, which has applications in data decomposition, compression and analysis and has been used in the fields of image denoising and classification, video and audio processing. Sparsity and overcomplete dictionaries have immense applications in image compression, image fusion and inpainting.",2
Technology,Ugly duckling theorem,"The ugly duckling theorem is an argument showing that classification is not really possible without some sort of bias. More particularly, it assumes finitely many properties combinable by logical connectives, and finitely many objects; it asserts that any two different objects share the same number of (extensional) properties. The theorem is named after Hans Christian Andersen's 1843 story ""The Ugly Duckling"", because it shows that a duckling is just as similar to a swan as two swans are to each other. It was derived by Satosi Watanabe in 1969.: 376–377 ",2
Technology,Probabilistic numerics,"Probabilistic numerics is a scientific field at the intersection of statistics, machine learning and applied mathematics, where tasks in numerical analysis including finding numerical solutions for integration, linear algebra, optimisation and differential equations are seen as problems of statistical, probabilistic, or Bayesian inference.",2
Technology,Mixed criticality,"A mixed criticality system is a system containing computer hardware and software that can execute several applications of different criticality, such as safety-critical and non-safety critical, or of different Safety Integrity Level (SIL). Different criticality applications are engineered to different levels of assurance, with high criticality applications being the most costly to design and verify. These kinds of systems are typically embedded in a machine such as an aircraft whose safety must be ensured.",2
Technology,Secure state,"A secure state is an information systems security term to describe where entities in a computer system are divided into subjects and objects, and it can be formally proven that each state transition preserves security by moving from one secure state to another secure state. Thereby it can be inductively proven that the system is secure. As defined in the Bell–LaPadula model, the secure state is built on the concept of a state machine with a set of allowable states in a system. The transition from one state to another state is defined by transition functions.
A system state is defined to be ""secure"" if the only permitted access modes of subjects to objects are in accordance with a security policy.",2
Technology,Sample complexity,"The sample complexity of a machine learning algorithm represents the number of training-samples that it needs in order to successfully learn a target function.
More precisely, the sample complexity is the number of training-samples that we need to supply to the algorithm, so that the function returned by the algorithm is within an arbitrarily small error of the best possible function, with probability arbitrarily close to 1.
There are two variants of sample complexity:

The weak variant fixes a particular input-output distribution;
The strong variant takes the worst-case sample complexity over all input-output distributions.The No free lunch theorem, discussed below, proves that, in general, the strong sample complexity is infinite, i.e. that there is no algorithm that can learn the globally-optimal target function using a finite number of training samples.
However, if we are only interested in a particular class of target functions (e.g, only linear functions) then the sample complexity is finite, and it depends linearly on the VC dimension on the class of target functions.

",2
Technology,Site Security Handbook,"The Site Security Handbook, RFC 2196, is a guide on setting computer security policies and procedures for sites that have systems on the Internet (however, the information provided should also be useful to sites not yet connected to the Internet).  The guide lists issues and factors that a site must consider when setting their own policies.  It makes a number of recommendations and provides discussions of relevant areas.
This guide is only a framework for setting security policies and procedures.  In order to have an effective set of policies and procedures, a site will have to make many decisions, gain agreement, and then communicate and implement these policies.
The guide is a product of the IETF SSH working group, and was published in 1997, obsoleting the earlier RFC 1244 from 1991.",2
Technology,Security type system,"In computer science, a type system can be described as a syntactic framework which contains a set of rules that are used to assign a type property (int, boolean, char etc.) to various components of a computer program, such as variables or functions. A security type system works in a similar way, only with a main focus on the security of the computer program, through information flow control. Thus, the various components of the program are assigned security types, or labels. The aim of a such system is to ultimately be able to verify that a given program conforms to the type system rules and satisfies non-interference. Security type systems is one of many security techniques used in the field of language-based security, and is tightly connected to information flow and information flow policies.
In simple terms, a security type system can be used to detect if there exists any kind of violation of confidentiality or integrity in a program, i.e. the programmer wants to detect if the program is in line with the information flow policy or not.",2
Technology,Zardoz (computer security),"In computer security, the Zardoz list, more formally known as the Security-Digest list, was a famous semi-private full disclosure mailing list run by Neil Gorsuch from 1989 through 1991. It identified weaknesses in systems and gave directions on where to find them. Zardoz is most notable for its status as a perennial target for computer hackers, who sought archives of the list for information on undisclosed software vulnerabilities.",2
Technology,Attention (machine learning),"In neural networks, attention is a technique that mimics cognitive attention. The effect enhances some parts of the input data while diminishing other parts — the thought being that the network should devote more focus to that small but important part of the data. Learning which part of the data is more important than others depends on the context and is trained by gradient descent.
Attention-like mechanisms were introduced in the 1990s under names like multiplicative modules, sigma pi units, and hypernetworks. Its flexibility comes from its role as ""soft weights"" that can change during runtime, in contrast to standard weights that must remain fixed at runtime.  Uses of attention include  memory in neural Turing machines, reasoning tasks in differentiable neural computers, language processing in transformers, and multi-sensory data processing (sound, images, video, and text) in perceivers.

",2
Technology,Stegomalware,"Stegomalware is a type of malware that uses steganography to hinder detection. Steganography is the practice of concealing a file, message, image, or video within another file, message, image, video or network traffic. This type of malware operates by building a steganographic system to hide malicious data within its resources and then extracts and executes them dynamically. It is considered one of the most sophisticated and stealthy ways of obfuscation.
The term of `stegomalware' was introduced by researchers in the context of mobile malware and presented at Inscrypt conference in 2014. However, the fact that (mobile) malware could potentially utilize steganography was already presented in earlier works: the use of steganography in malware was first applied to botnets communicating over probabilistically unobservable channels, mobile malware based on covert channels was proposed in the same year. Steganography was later applied to other components of malware engineering such as return-oriented programming and compile-time obfuscation, among others.The Europol-supported CUING initiative monitors the use of steganography in malware.",2
Technology,Cyber risk quantification,"Cyber risk quantification involves the application of risk quantification techniques to an organization's cybersecurity risk.  Cyber risk quantification is the process of evaluating the cyber risks that have been identified and then validating, measuring and analyzing the available cyber data using mathematical modeling techniques to accurately represent the organization's cybersecurity environment in a manner that can be used to make informed cybersecurity infrastructure investment and risk transfer decisions.  Cyber risk quantification is a supporting activity to cybersecurity risk management; cybersecurity risk management is a component of enterprise risk management and is especially important in organizations and enterprises that are highly dependent upon their information technology (IT) networks and systems for their business operations.
One method of quantifying cyber risk is the value-at-risk (VaR) method that is discussed at the January 2015 World Economic Forum meeting.  At this meeting, VaR was studied and researched and deemed to be a viable method of quantifying cyber risk. 
A well known framework for cyber risk quantification is called FAIRTM (Factor Analysis of Information Risk). The FAIR Institute is a non-profit professional organization committed to furthering the science of cyber and operational risk measurement and management. Cyber-Risk Quantification can be an automated or software supported process allowing Users to construct mathematical models to quantify Cyber-Security risks.",2
Technology,Under-fitting,"In mathematical modeling, overfitting is ""the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit to additional data or predict future observations reliably"". An overfitted model is a mathematical model that contains more parameters than can be justified by the data. The essence of overfitting is to have unknowingly extracted some of the residual variation (i.e., the noise) as if that variation represented underlying model structure.: 45 Underfitting occurs when a mathematical model cannot adequately capture the underlying structure of the data. An under-fitted model is a model where some parameters or terms that would appear in a correctly specified model are missing. Under-fitting would occur, for example, when fitting a linear model to non-linear data. Such a model will tend to have poor predictive performance.
The possibility of over-fitting exists because the criterion used for selecting the model is not the same as the criterion used to judge the suitability of a model. For example, a model might be selected by maximizing its performance on some set of training data, and yet its suitability might be determined by its ability to perform well on unseen data; then over-fitting occurs when a model begins to ""memorize"" training data rather than ""learning"" to generalize from a trend. 
As an extreme example, if the number of parameters is the same as or greater than the number of observations, then a model can perfectly predict the training data simply by memorizing the data in its entirety. (For an illustration, see Figure 2.) Such a model, though, will typically fail severely when making predictions. 
The potential for overfitting depends not only on the number of parameters and data but also the conformability of the model structure with the data shape, and the magnitude of model error compared to the expected level of noise or error in the data. Even when the fitted model does not have an excessive number of parameters, it is to be expected that the fitted relationship will appear to perform less well on a new data set than on the data set used for fitting (a phenomenon sometimes known as shrinkage). In particular, the value of the coefficient of determination will shrink relative to the original data.
To lessen the chance or amount of overfitting, several techniques are available (e.g., model comparison, cross-validation, regularization, early stopping, pruning, Bayesian priors, or dropout). The basis of some techniques is either (1) to explicitly penalize overly complex models or (2) to test the model's ability to generalize by evaluating its performance on a set of data not used for training, which is assumed to approximate the typical unseen data that a model will encounter.

",2
Technology,Anomaly Detection at Multiple Scales,"Anomaly Detection at Multiple Scales, or ADAMS, is a $35 million DARPA project designed to identify patterns and anomalies in very large data sets. It is under DARPA's Information Innovation office and began in 2011.The project is intended to detect and prevent insider threats such as ""a soldier in good mental health becoming homicidal or
suicidal"", an ""innocent insider becoming malicious"", or ""a government employee [who] abuses access privileges to share classified information"". Specific cases mentioned are Nidal Malik Hasan and WikiLeaks source Chelsea Manning. Commercial applications may include finance. The intended recipients of the system output are operators in the counterintelligence agencies.The Proactive Discovery of Insider Threats Using Graph Analysis and Learning is part of the ADAMS project. The Georgia Tech team includes noted high-performance computing researcher David A. Bader.",2
Technology,Kernel density estimation,"In statistics, kernel density estimation (KDE) is a non-parametric way to estimate the probability density function of a random variable.  Kernel density estimation is a fundamental data smoothing problem where inferences about the population are made, based on a finite data sample. In some fields such as signal processing and econometrics it is also termed the Parzen–Rosenblatt window method,  after Emanuel Parzen and Murray Rosenblatt, who are usually credited with independently creating it in its current form. One of the famous applications of kernel density estimation is in estimating the class-conditional marginal densities of data when using a naive Bayes classifier, which can improve its prediction accuracy.",2
Technology,Anderson's rule (computer science),"In the field of computer security, Anderson's rule refers to a principle formulated by Ross J. Anderson: systems that handle sensitive personal information involve a trilemma of security, functionality and scale, of which you can choose any two. A system that has information on many data subjects and to which many people require access is hard to secure unless its functionality is severely restricted. If it has rich functionality, you may have to restrict the number of people with access, or accept that some information will leak.",2
Technology,Flow-based generative model,"A flow-based generative model is a generative model used in machine learning that explicitly models a probability distribution by leveraging normalizing flow, which is a statistical method using the change-of-variable law of probabilities to transform a simple distribution into a complex one.
The direct modeling of likelihood provides many advantages. For example, the negative log-likelihood can be directly computed and minimized as the loss function. Additionally, novel samples can be generated by sampling from the initial distribution, and applying the flow transformation.
In contrast, many alternative generative modeling methods such as variational autoencoder (VAE) and generative adversarial network do not explicitly represent the likelihood function.",2
Technology,Outline of computer security,"The following outline is provided as an overview of and topical guide to computer security:
Computer security is commonly known as security applied to computing devices such as computers and smartphones, as well as computer networks such as private and public networks, including the whole Internet.  The field covers all the processes and mechanisms by which digital equipment, information and services are protected from unintended or unauthorized access, change or destruction, and is of growing importance in line with the increasing reliance on computer systems of most societies worldwide. Computer security includes measures taken to ensure the integrity of files stored on a computer or server as well as measures taken to prevent unauthorized access to stored data, by securing the physical perimeter of the computer equipment, authentication of users or computer accounts accessing the data, and providing a secure method of data transmission.",2
Technology,List of datasets for machine-learning research,"These datasets are applied for machine learning research and have been cited in peer-reviewed academic journals. Datasets are an integral part of the field of machine learning. Major advances in this field can result from advances in learning algorithms (such as deep learning), computer hardware, and, less-intuitively, the availability of high-quality training datasets. High-quality labeled training datasets for supervised and semi-supervised machine learning algorithms are usually difficult and expensive to produce because of the large amount of time needed to label the data. Although they do not need to be labeled, high-quality datasets for unsupervised learning can also be difficult and costly to produce.

",2
Technology,Federal Desktop Core Configuration,"The Federal Desktop Core Configuration is a list of security settings recommended by the National Institute of Standards and Technology for general-purpose microcomputers that are connected directly to the network of a United States government agency.
The FDCC is a list of agreed upon Microsoft Windows operating system common core system functions, applications, files, and services that are changed in their configuration around which a framework for a more secure, and security-reliable MS Windows operating system was created. The standards were then made mandatory for every federal government computer effective Feb 1, 2008. If you wanted to connect to a federal office computer network your system had to meet or exceed the FDCC standard or you were denied access.
FDCC applied only to Windows XP and Vista desktop and laptop computers and was replaced by the United States Government Configuration Baseline (USGCB), which included settings for Windows 7 and Red Hat Enterprise Linux 5.
For Windows 7, the NIST changed the naming convention to the US Government Computer Baseline (USGCB ver 2.0). In addition to un-classifying a general Windows settings guide, the NIST also publishes guides specifically for Windows Firewall, Internet Explorer, and a guide (Vista-Energy, for example) created to capture settings that adhere to energy conservation policies.",2
Technology,Solomonoff's theory of inductive inference,"Solomonoff's theory of inductive inference is a mathematical proof that if a universe is generated by an algorithm, then observations of that universe, encoded as a dataset, are best predicted by the smallest executable archive of that dataset.  This formalization of Occam's razor  for induction was introduced by Ray Solomonoff, based on probability theory and theoretical computer science. In essence, Solomonoff's induction derives the posterior probability of any computable theory, given a sequence of observed data. This posterior probability is derived from Bayes rule and some universal prior, that is, a prior that assigns a positive probability to any computable theory.

",2
Technology,Genetic algorithm,"In computer science and operations research, a genetic algorithm (GA) is a metaheuristic inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms (EA). Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection. Some examples of GA applications include optimizing decision trees for better performance, solving sudoku puzzles, hyperparameter optimization, etc.",2
Technology,Evolutionary programming,"Evolutionary programming is one of the four major evolutionary algorithm paradigms.  It is similar to genetic programming, but the structure of the program to be optimized is fixed, while its numerical parameters are allowed to evolve.
It was first used by Lawrence J. Fogel in the US in 1960 in order to use simulated evolution as a learning process aiming to generate artificial intelligence. Fogel used finite-state machines as predictors and evolved them.
Currently evolutionary programming is a wide evolutionary computing dialect with no fixed structure or (representation), in contrast with some of the other dialects. It has become harder to distinguish from evolutionary strategies.
Its main variation operator is mutation; members of the population are viewed as part of a specific species rather than members of the same species therefore each parent generates an offspring, using a (μ + μ) survivor selection.",2
Life Science,Genome mining,"Genome mining describes the exploitation of genomic information for the discovery of biosynthetic pathways of natural products and their possible interactions. It depends on computational technology and bioinformatics tools. The mining process relies on a huge amount of data (represented by DNA sequences and annotations) accessible in genomic databases. By applying data mining algorithms,  the data can be used to generate new knowledge in several areas of medicinal chemistry, such as discovering novel natural products.

",1
Life Science,Optoelectrowetting,"Optoelectrowetting (OEW) is a method of liquid droplet manipulation used in microfluidics applications. This technique builds on the principle of electrowetting, which has proven useful in liquid actuation due to fast switching response times and low power consumption. Where traditional electrowetting runs into challenges, however, such as in the simultaneous manipulation of multiple droplets, OEW presents a lucrative alternative that is both simpler and cheaper to produce. OEW surfaces are easy to fabricate, since they require no lithography, and have real-time, reconfigurable, large-scale manipulation control, due to its reaction to light intensity.",1
Life Science,Diploidization,Diploidization is the process of converting a polyploid genome back into a diploid one. Polyploidy is a product of whole genome duplication (WGD) and is followed by diploidization as a result of genome shock. The plant kingdom has undergone multiple events of polyploidization followed by diploidization in both ancient and recent lineages. It has also been hypothesized that vertebrate genomes have gone through two rounds of paleopolyploidy. The mechanisms of diploidization are poorly understood but patterns of chromosomal loss and evolution of novel genes are observed in the process.,1
Life Science,Bacteriophage,"A bacteriophage (), also known informally as a phage (), is a virus that infects and replicates within bacteria and archaea. The term was derived from ""bacteria"" and the Greek φαγεῖν (phagein), meaning ""to devour"". Bacteriophages are composed of proteins that encapsulate a DNA or RNA genome, and may have structures that are either simple or elaborate. Their genomes may encode as few as four genes (e.g. MS2) and as many as hundreds of genes. Phages replicate within the bacterium following the injection of their genome into its cytoplasm.
Bacteriophages are among the most common and diverse entities in the biosphere. Bacteriophages are ubiquitous viruses, found wherever bacteria exist. It is estimated there are more than 1031 bacteriophages on the planet, more than every other organism on Earth, including bacteria, combined. Viruses are the most abundant biological entity in the water column of the world's oceans, and the second largest component of biomass after prokaryotes, where up to 9x108 virions per millilitre have been found in microbial mats at the surface, and up to 70% of marine bacteria may be infected by phages.Phages have been used since the late 20th century as an alternative to antibiotics in the former Soviet Union and Central Europe, as well as in France. They are seen as a possible therapy against multi-drug-resistant strains of many bacteria (see phage therapy).
Phages are known to interact with the immune system both indirectly via bacterial expression of phage-encoded proteins and directly by influencing innate immunity and bacterial clearance.",1
Life Science,Pursuit predation,"Pursuit predation is a form of predation in which predators actively give chase to their prey, either solitarily or as a group.  It is an alternate predation strategy to ambush predation — pursuit predators rely on superior speed, endurance and/or teamwork to seize the prey, while ambush predators use stealth, luring, the use of surroundings and the element of surprise to capture the prey.  While the two patterns of predation are not mutually exclusive, morphological differences in an organism's body plan can create an evolutionary bias favoring either type of predation.
Pursuit predation is typically observed in carnivorous species within the kingdom Animalia, such as cheetahs, lions, wolves and early Homo species.  The chase can be initiated either by the predator, or by the prey if it is alerted to a predator's presence and attempt to flee before the predator gets close.  The chase ends either when the predator successfully catches up and tackles the prey, or when the predator abandons the attempt after the prey outruns it and escapes.
One particular form of pursuit predation is persistence hunting, where the predator stalks the prey slowly but persistently to wear it down physically with fatigue or overheating; some animals are examples of both types of pursuit.",1
Life Science,Phytogeomorphology,"Phytogeomorphology is the study of how terrain features affect plant growth. It was the subject of a treatise by Howard and Mitchell in 1985, who were considering the growth and varietal temporal and spatial variability found in forests, but recognized that their work also had application to farming, and the relatively new science (at that time) of precision agriculture.  The premise of Howard and Mitchell is that landforms, or features of the land's 3D topography significantly affect how and where plants (or trees in their case) grow.  Since that time, the ability to map and classify landform shapes and features has increased greatly.  The advent of GPS has made it possible to map almost any variable one might wish to measure.  Thus, a very increased awareness of the spatial variability of the environment that plants grow in has arisen.  The development of technology like airborne LiDAR has enabled the detailed measurement of landform features to better than sub-meter, and when combined with RTK-GPS (accuracies to 1mm) enables the creation of very accurate maps of where these features are.  Comparison of these landform maps with mapping of variables related to crop or plant growth show a strong correlation (see below for examples and references for precision agriculture).",1
Life Science,Biosemiotics,"Biosemiotics (from the Greek βίος bios, ""life"" and σημειωτικός sēmeiōtikos, ""observant of signs"") is a field of semiotics and biology that studies the prelinguistic meaning-making, or production and interpretation of signs and codes and their communication in the biological realm.Biosemiotics integrates the findings of biology and semiotics and proposes a paradigmatic shift in the scientific view of life, in which semiosis (sign process, including meaning and interpretation) is one of its immanent and intrinsic features. The term biosemiotic was first used by Friedrich S. Rothschild in 1962, but Thomas Sebeok and Thure von Uexküll have implemented the term and field. The field, which challenges normative views of biology, is generally divided between theoretical and applied biosemiotics.
Insights from biosemiotics have also been adopted in the humanities and social sciences, including human-animal studies and human-plant studies.",1
Life Science,Biomanufacturing,"Biomanufacturing is a type of manufacturing or biotechnology that utilizes biological systems to produce commercially important biomaterials and biomolecules for use in medicines, food and beverage processing, and industrial applications.  Biomanufacturing products are recovered from natural sources, such as blood, or from cultures of microbes, animal cells, or plant cells grown in specialized equipment.  The cells used during the production may have been naturally occurring or derived using genetic engineering techniques.

",1
Life Science,Biology,"Geology (from Ancient Greek  γῆ (gê) 'earth', and  -λoγία (-logía) 'study of, discourse') is a branch of natural science concerned with Earth and other astronomical objects, the features or rocks of which it is composed, and the processes by which they change over time. Modern geology significantly overlaps all other Earth sciences, including hydrology and the atmospheric sciences, and so is treated as one major aspect of integrated Earth system science and planetary science.
Geology describes the structure of the Earth on and beneath its surface, and the processes that have shaped that structure. It also provides tools to determine the relative and absolute ages of rocks found in a given location, and also to describe the histories of those rocks. By combining these tools, geologists are able to chronicle the geological history of the Earth as a whole, and also to demonstrate the age of the Earth. Geology provides the primary evidence for plate tectonics, the evolutionary history of life, and the Earth's past climates.
Geologists use a wide variety of methods to understand the Earth's structure and evolution, including field work, rock description, geophysical techniques, chemical analysis, physical experiments, and numerical modelling. In practical terms, geology is important for mineral and hydrocarbon exploration and exploitation, evaluating water resources, understanding of natural hazards, the remediation of environmental problems, and providing insights into past climate change. Geology is a major academic discipline, and it is central to geological engineering and plays an important role in geotechnical engineering.

",1
Life Science,Trace metal,"Trace metals are the metals subset of trace elements; that is, metals normally present in small but measurable amounts in animal and plant cells and tissues and that are a necessary part of nutrition and physiology. Many biometals are trace metals. Ingestion of, or exposure to, excessive quantities can be toxic. However, insufficient plasma or tissue levels of certain trace metals can cause pathology, as is the case with iron.
Trace metals within the human body include iron, lithium, zinc, copper, chromium, nickel, cobalt, vanadium, molybdenum, manganese and others.Trace metals are metals needed by living organisms to function properly and are depleted through the expenditure of energy by various metabolic processes of living organisms. They are replenished in animals through diet as well as environmental exposure, and in plants through the uptake of nutrients from the soil in which the plant grows. Human vitamin pills and plant fertilizers can be a source of trace metals.
Trace metals are sometimes referred to as trace elements, although the latter includes minerals and is a broader category. See also Dietary mineral. Trace elements are required by the body for specific functions. Things such as vitamins, sports drinks, fresh fruits and vegetables are sources. Taken in excessive amounts, trace elements can cause problems. For example fluorine is required for the formation of bones and enamel on teeth. However, when taken in an excessive amount can cause a disease called ""Fluorosis', in which bone deformations and yellowing of teeth are seen. Fluorine can occur naturally in some areas in ground water.
Trace metals include iron that can help to prevent anemia, and zinc that is a cofactor in over 100 enzyme reactions.",1
Life Science,Potassium spatial buffering,"Potassium spatial buffering is a mechanism for the regulation of extracellular potassium concentration by astrocytes. Other mechanisms for astrocytic potassium clearance are carrier-operated or channel-operated potassium chloride uptake.
The repolarization of neurons tends to raise potassium concentration in the extracellular fluid.  If a significant rise occurs, it will interfere with neuronal signaling by depolarizing neurons. Astrocytes have large numbers of potassium ion channels facilitating removal of potassium ions from the extracellular fluid. They are taken up at one region of the astrocyte and then distributed throughout the cytoplasm of the cell, and further to its neighbors via gap junctions. This keeps extracellular potassium at levels that prevent interference with normal propagation of an action potential.

",1
Life Science,Surfactant,"Surfactants are compounds that lower the surface tension (or interfacial tension) between two liquids, between a gas and a liquid, or between a liquid and a solid. Surfactants may act as detergents, wetting agents, emulsifiers, foaming agents, or dispersants.
The word ""surfactant"" is a blend of surface-active agent,
coined c.  1950.Agents that increase surface tension are ""surface active"" in the literal sense but are not called surfactants as their effect is opposite to the common meaning. A common example of surface tension increase is salting out: by adding an inorganic salt to an aqueous solution of a weakly polar substance, the substance will precipitate. The substance may itself be a surfactant – this is one  of the reasons why many surfactants are ineffective in sea water.",1
Life Science,Substantial equivalence,"In food safety, the concept of substantial equivalence holds that the safety of a new food, particularly one that has been genetically modified (GM), may be assessed by comparing it with a similar traditional food that has proven safe in normal use over time. It was first formulated as a food safety policy in 1993, by the Organisation for Economic Co-operation and Development (OECD).As part of a food safety testing process, substantial equivalence is the initial step, establishing toxicological and nutritional differences in the new food compared to a conventional counterpart—differences are analyzed and evaluated, and further testing may be conducted, leading to a final safety assessment.Substantial equivalence is the underlying principle in GM food safety assessment for a number of national and international agencies, including the Canadian Food Inspection Agency (CFIA), Japan's Ministry of Health, Labour and Welfare (MHLW), the US Food and Drug Administration (FDA), and the United Nations' Food and Agriculture Organization (FAO) and  World Health Organization.",1
Life Science,Intestine-on-a-chip,"Intestines-on-a-chip (gut-on-a-chip, mini-intestine) are microfluidic bioengineered 3D-models of the real organ, which better mimic physiological features than conventional 3D intestinal organoid culture... A variety of different intestine-on-a-chip models systems have been developed and refined, all holding their individual strengths and weaknesses and collectively holding great promise to the ultimate goal of establishing these systems as reliable high-throughput platforms for drug testing and personalised medicine. The intestine is a highly complex organ system performing a diverse set of vital tasks, from nutrient digestion and absorption, hormone secretion, and immunological processes to neuronal activity, which makes it particularly challenging to model in vitro.",1
Life Science,Fermentek,"Fermentek Ltd. is a biotechnological company in the Atarot industrial zone of Jerusalem, Israel. It specializes in the research, development and manufacture of biologically active, natural products isolated from microorganisms as well as from other natural sources such as plants and algae.
The main microorganisms used are nonpathogenic actinomycetes, Nocardia and Streptomycetes. The fungi used are: Penicillium, Aspergillus, Fusarium and the like. None of these is a human pathogen.
Fermentek does not sell to individuals. Most of its products are marketed through major international distributors specializing in chemicals, under their own brand names. Nevertheless, Fermentek has specific impact on the biochemical market, especially in the field of mycotoxins.
Mycotoxins are toxic compounds produced by molds in human food and farm animal feeds, thus being economically important factors. Fermentek manufactures an extensive line of pure mycotoxins used as standards in food analysis. In some cases, such as Aflatoxin M2, Fermentek supplies the entire world's requirements.In 2009, Fermentek announced a product family of highly standardized calibrant solutions of main mycotoxins. These are marketed under the brand name FermaSol. In 2010, it obtained ISO 13485 accreditation in connection with the production of starting materials for experimental drug production, and with manufacturing of reference standards of food contaminants.
None of Fermentek's products have been invented by it. Fermentek's aim is to make known compounds affordable to the scientific community.
Fermentek was founded by Dr. Yosef Behrend in 1994. It moved in 2004 to its new building, quadrupling its working space and greatly enlarging its manufacturing capacities.

",1
Life Science,Cell therapy,"Cell therapy (also called cellular therapy, cell transplantation, or cytotherapy) is a therapy in which viable cells are injected, grafted or implanted into a patient in order to effectuate a medicinal effect, for example, by transplanting T-cells capable of fighting cancer cells via cell-mediated immunity in the course of immunotherapy, or grafting stem cells to regenerate diseased tissues.
Cell therapy originated in the nineteenth century when scientists experimented by injecting animal material in an attempt to prevent and treat illness. Although such attempts produced no positive benefit, further research found in the mid twentieth century that human cells could be used to help prevent the human body rejecting transplanted organs, leading in time to successful bone marrow transplantation as has become common practice in treatment for patients that have compromised bone marrow after disease, infection, radiation or chemotherapy. In recent decades, however, stem cell and cell transplantation has gained significant interest by researchers as a potential new therapeutic strategy for a wide range of diseases, in particular for degenerative and immunogenic pathologies.",1
Life Science,Molecular-weight size marker,"A molecular-weight size marker, also referred to as a protein ladder, DNA ladder, or RNA ladder, is a set of standards that are used to identify the approximate size of a molecule run on a gel during electrophoresis, using the principle that molecular weight is inversely proportional to migration rate through a gel matrix. Therefore, when used in gel electrophoresis, markers effectively provide a logarithmic scale by which to estimate the size of the other fragments (providing the fragment sizes of the marker are known).
Protein, DNA, and RNA markers with pre-determined fragment sizes and concentrations are commercially available. These can be run in either agarose or polyacrylamide gels. The markers are loaded in lanes adjacent to sample lanes before the commencement of the run.

",1
Life Science,C1orf122,"C1orf122 (Chromosome 1 open reading frame 122) is a gene in the human genome that encodes the cytosolic protein ALAESM.. ALAESM is present in all tissue cells and highly up-regulated in the brain, spinal cord, adrenal gland and kidney. This gene can be expressed up to 2.5 times the average gene in its highly expressed tissues. Although the function of C1orf122 is unknown, it is predicted to be used for mitochondria localization.",1
Life Science,Xenobiology,"Xenobiology (XB) is a subfield of synthetic biology, the study of synthesizing and manipulating biological devices and systems. The name ""xenobiology"" derives from the Greek word xenos, which means ""stranger, alien"". Xenobiology is a form of biology that is not (yet) familiar to science and is not found in nature. In practice, it describes novel biological systems and biochemistries that differ from the canonical DNA–RNA-20 amino acid system (see central dogma of molecular biology). For example, instead of DNA or RNA, XB explores nucleic acid analogues, termed xeno nucleic acid (XNA) as information carriers. It also focuses on an expanded genetic code and the incorporation of non-proteinogenic amino acids into proteins.",1
Life Science,Aspergillus niger,"Aspergillus niger is a fungus and one of the most common species of the genus Aspergillus.
It causes a disease called ""black mold"" on certain fruits and vegetables such as grapes, apricots, onions, and peanuts, and is a common contaminant of food. It is ubiquitous in soil and is commonly reported from indoor environments, where its black colonies can be confused with those of Stachybotrys (species of which have also been called ""black mold"").Some strains of A. niger have been reported to produce potent mycotoxins called ochratoxins; other sources disagree, claiming this report is based upon misidentification of the fungal species. Recent evidence suggests some true A. niger strains do produce ochratoxin A. It also produces the isoflavone orobol.

",1
Life Science,High throughput biology,"High throughput cell biology is the use of automation equipment with classical cell biology techniques to address biological questions that are  otherwise unattainable using conventional methods. It may incorporate techniques from optics, chemistry, biology or image analysis to permit rapid, highly parallel research into how cells function, interact with each other and how pathogens exploit them in disease.High throughput cell biology has many definitions, but is most commonly defined by the search for active compounds in natural materials like in medicinal plants. This is also known as high throughput screening (HTS) and is how most drug discoveries are made today, many cancer drugs, antibiotics, or viral antagonists have been discovered using HTS. The process of HTS also tests substances for potentially harmful chemicals that could be potential human health risks. HTS generally involves hundreds of samples of cells with the model disease and hundreds of different compounds being tested from a specific source. Most often a computer is used to determine when a compound of interest has a desired or interesting effect on the cell samples.
Using this method has contributed to the discovery of the drug Sorafenib (Nexavar). Sorafenib is used as medication to treat multiple types of cancers, including renal cell carcinoma (RCC, cancer in the kidneys), hepatocellular carcinoma (liver cancer), and thyroid cancer. It helps stop cancer cells from reproducing by blocking the abnormal proteins present. In 1994, high throughput screening for this particular drug was completed. It was initially discovered by Bayer Pharmaceuticals in 2001. By using a RAF kinase biochemical assay, 200,000 compounds were screened from medicinal chemistry directed synthesis or combinatorial libraries to identify active molecules against activeRAF kinase. Following three trials of testing, it was found to have anti-angiogenic effects on the cancers, which stops the process of creating new blood vessels in the body.Another discovery made using HTS is Maraviroc. It is an HIV entry inhibitor, and slows the process and prevents HIV from being able to enter human cells. It is used to treat a variety of cancers as well, reducing or blocking the metastasis of cancer cells, which is when cancer cells spread to a completely different part of the body from where it started. High throughput screening for Maraviroc was completed in 1997, and finalized in 2005 by Pfizer global research and development team.
High-throughput biology serves as one facet of what has also been called ""omics research"" - the interface between large scale biology (genome, proteome, transcriptome), technology and researchers. High throughput cell biology has a definite focus on the cell, and methods accessing the cell such as imaging, gene expression microarrays, or genome wide screening. The basic idea is to take methods normally performed on their own and do a very large number of them without impacting their quality High throughput research can be defined as the automation of experiments such that large scale repetition becomes feasible. This is important because many of the questions faced by life science researchers now involve large numbers. For example, the Human Genome contains at least 21,000 genes, all of which can potentially contribute to cell function, or disease. To be able to capture an idea of how these genes interact with one another, which genes are involved in and where they are, methods that encompass from the cell to the genome are of interest.",1
Life Science,Molecular diagnostics,"Molecular diagnostics is a collection of techniques used to analyze biological markers in the genome and proteome, and how their cells express their genes as proteins, applying molecular biology to medical testing. In medicine the technique is used to diagnose and monitor disease, detect risk, and decide which therapies will work best for individual patients,: foreword  and in agricultural biosecurity similarly to monitor crop- and livestock disease, estimate risk, and decide what quarantine measures must be taken.By analysing the specifics of the patient and their disease, molecular diagnostics offers the prospect of personalised medicine.
These tests are useful in a range of medical specialties, including infectious disease, oncology, human leucocyte antigen typing (which investigates and predicts immune function), coagulation, and pharmacogenomics—the genetic prediction of which drugs will work best.: v-vii  They overlap with clinical chemistry (medical tests on bodily fluids).",1
Life Science,BamHI,"BamHI (pronounced ""Bam H one"") (from Bacillus amyloliquefaciens) is a type II restriction endonuclease, having the capacity for recognizing short sequences (6 bp) of DNA and specifically cleaving them at a target site. This exhibit focuses on the structure-function relations of BamHI as described by Newman, et al. (1995). BamHI binds at the recognition sequence 5'-GGATCC-3', and cleaves these sequences just after the 5'-guanine on each strand. This cleavage results in sticky ends which are 4 bp long. In its unbound form, BamHI displays a central b sheet, which resides in between α-helices. 
BamHI undergoes a series of unconventional conformational changes upon DNA recognition. This allows the DNA to maintain its normal B-DNA conformation without distorting to facilitate enzyme binding. BamHI is a symmetric dimer. DNA is bound in a large cleft that is formed between dimers; the enzyme binds in a ""crossover"" manner. Each BamHI subunit makes the majority of its backbone contacts with the phosphates of a DNA half site but base pair contacts are made between each BamHI subunit and nitrogenous bases in the major groove of the opposite DNA half site. The protein binds the bases through either direct hydrogen bonds or water-mediated H-bonds between the protein and every H-bond donor/acceptor group in the major groove. Major groove contacts are formed by atoms residing on the amino-terminus of a parallel 4 helix bundle. This bundle marks the BamHI dimer interface, and it is thought that the dipole moments of the NH2-terminal atoms on this bundle may contribute to electrostatic stabilization.",1
Life Science,Genetically encoded voltage indicator,"Genetically encoded voltage indicator (or GEVI) is a protein that can sense membrane potential in a cell and relate the change in voltage to a form of output, often fluorescent level. It is a promising optogenetic recording tool that enables exporting electrophysiological signals from cultured cells, live animals, and ultimately human brain. Examples of notable GEVIs include ArcLight, ASAP1, ASAP3, Archons, SomArchon, and Ace2N-mNeon.",1
Life Science,Informative site,"In phylogenetics, informative site is a term used when maximum parsimony is the optimality criterion for construction of a phylogenetic tree. It refers to a characteristic for which the number of character-state evolutionary changes of at this site depends on the topology of the tree. The charactetistics can take on multiple types of data, including morphological (such as the presence of wings, tentacles, etc.) or molecular information such as sequences of DNA or proteins.
The informative site is a position in the relevant set of aligned sequences at which there are at least two different character states and each of those states occurs in at least two of the sequences. In other words, it cannot be a fully conserved (invariable) site nor can it be a (singleton) site with a difference in only one sequence. In both cases, the number of character-state changes is the same regardless of the topology of the tree, equal to 0 and 1 respectively.",1
Life Science,Electromethanogenesis,"Electromethanogenesis is a form of electrofuel production where methane is produced by direct biological conversion of electrical current and carbon dioxide.Methane producing technologies garnered interest from the scientific community prior to 2000, but electromethanogenesis did not become a significant area of interest until 2008. Publications concerning catalytic methanation have increased from 44 to over 130 since 2008. Electromethanogenesis has drawn more research due to its proposed applications. The production of methane from electrical current may provide an approach to renewable energy storage. Electrical current produced from renewable energy sources may, through electromethanogenesis, be converted into methane which may then be used as a biofuel. It may also be a useful method for the capture of carbon dioxide which may be used for air purification.In nature, methane formation occurs biotically and abiotically. Abiogenic methane is produced on a smaller scale and the required chemical reactions do not necessitate organic materials. Biogenic methane is produced in anaerobic natural environments where methane forms as the result of the breakdown of organic materials by microbes—or microorganisms. Researchers have found that the biogenic methane production process can be replicated in a laboratory environment through electromethanogenesis. The reduction of CO2 in electromethanogenesis is facilitated by an electrical current at a biocathode in a microbial electrolysis cell (MEC) and with the help of microbes and electrons (Equation 1) or abiotically produced hydrogen (Equation 2).(1) CO2 + 8H+ + 8e− ↔ CH4 + 2H2O
(2) CO2 + 4H2 ↔ CH4 + 2H2O

",1
Life Science,Fenestra,"The skull is a bone structure that forms the head in vertebrates. It supports the structures of the face and provides a protective cavity for the brain. The skull is composed of two parts: the cranium and the mandible. In humans, these two parts are the neurocranium and the viscerocranium (facial skeleton) that includes the mandible as its largest bone. The skull forms the anterior-most portion of the skeleton and is a product of cephalisation—housing the brain, and several sensory structures such as the eyes, ears, nose, and mouth. In humans these sensory structures are part of the facial skeleton.
Functions of the skull include protection of the brain, fixing the distance between the eyes to allow stereoscopic vision, and fixing the position of the ears to enable sound localisation of the direction and distance of sounds. In some animals, such as horned ungulates (mammals with hooves), the skull also has a defensive function by providing the mount (on the frontal bone) for the horns.
The English word skull is probably derived from Old Norse skulle, while the Latin word cranium comes from the Greek root κρανίον (kranion). The human skull fully develops two years after birth.The junctions of the skull bones are joined together by structures called sutures.
The skull is made up of a number of fused flat bones, and contains many foramina, fossae, processes, and several cavities or sinuses. In zoology there are openings in the skull called fenestrae.

",1
Life Science,Recombinase polymerase amplification,"Recombinase polymerase amplification (RPA) is a single tube, isothermal alternative to the polymerase chain reaction (PCR). By adding a reverse transcriptase enzyme to an RPA reaction it can detect RNA as well as DNA, without the need for a separate step to produce cDNA,. Because it is isothermal, RPA can use much simpler equipment than PCR, which requires a thermal cycler. Operating best at temperatures of 37–42 °C and still working, albeit more slowly, at room temperature means RPA reactions can in theory be run quickly simply by holding a tube. This makes RPA an excellent candidate for developing low-cost, rapid, point-of-care molecular tests. An international quality assessment of molecular detection of Rift Valley fever virus performed as well as the best RT-PCR tests, detecting less concentrated samples missed by some PCR tests and an RT-LAMP test.
RPA was developed and launched by TwistDx Ltd. (formerly known as ASM Scientific Ltd), a biotechnology company based in Cambridge, UK.",1
Life Science,Ti plasmid,"A tumour inducing (Ti) plasmid is a plasmid found in pathogenic species of Agrobacterium, including A. tumefaciens, A. rhizogenes, A. rubi and A. vitis.
Evolutionarily, the Ti plasmid is part of a family of plasmids carried by many species of Alphaproteobacteria. Members of this plasmid family are defined by the presence of a conserved DNA region known as the repABC gene cassette, which mediates the replication of the plasmid, the partitioning of the plasmid into daughter cells during cell division as well as the maintenance of the plasmid at low copy numbers in a cell. The Ti plasmids themselves are sorted into different categories based on the type of molecule, or opine, they allow the bacteria to break down as an energy source.The presence of this Ti plasmid is essential for the bacteria to cause crown gall disease in plants. This is facilitated via certain crucial regions in the Ti plasmid, including the vir region, which encodes for virulence genes, and the transfer DNA (T-DNA) region, which is a section of the Ti plasmid that is transferred via conjugation into host plant cells after an injury site is sensed by the bacteria. These regions have features that allow the delivery of T-DNA into host plant cells, and can modify the host plant cell to cause the synthesis of molecules like plant hormones (e.g. auxins, cytokinins) and opines and the formation of crown gall tumours.Because the T-DNA region of the Ti plasmid can be transferred from bacteria to plant cells, it represented an exciting avenue for the transfer of DNA between kingdoms and spurred large amounts of research on the Ti plasmid and its possible uses in bioengineering.

",1
Life Science,List of restriction enzyme cutting sites: E–F,"This article contains a list of restriction enzymes whose names start with A and have a clearly defined cutting site.
The following information is given for each enzyme:

Name of Restriction Enzyme: Accepted name of the molecule, according to the internationally adopted nomenclature, and bibliographical references. Note: When alphabetizing, enzymes are first ordered alphabetically by the acronyms (everything before the roman numeral); then enzymes of a given acronym are ordered alphabetically by the roman numeral, treating the numeral as a number and not a string of letters. This helps keep the entries ordered hierarchically while also alphabetic.(Further reading: see the section ""Nomenclature"" in the article ""Restriction enzyme"".)
PDB code: Code used to identify the structure of a protein in the PDB database of protein structures. The 3D atomic structure of a protein provides highly valuable information to understand the intimate details of its mechanism of action.
REBASE Number: Number used to identify restriction enzymes in the REBASE restriction enzyme database. This database includes important information about the enzyme such as Recognition sequence, source, and Isoschizomers, as well as other data, such as the commercial suppliers of the enzyme.
Source: Organism that naturally produces the enzyme.
Recognition sequence: Sequence of DNA recognized by the enzyme and to which it specifically binds.
Cut: Displays the cut site and pattern and products of the cut. The recognition sequence and the cut site usually match, but sometimes the cut site can be dozens of nucleotides away from the recognition site.
Isoschizomers and neoschizomers: An isoschizomer is a restriction enzyme that recognizes the same sequence as another. A neoschizomer is a special type of isoschizomer that recognizes the same sequence as another, but cuts in a different manner. A maximum number of 8–10 most common isoschizomers are indicated for every enzyme but there may be many more. Neoschizomers are shown in bold and green color font (e.g.: BamHI). When ""None as of [date]"" is indicated, that means that there were no registered isoschizomers in the databases on that date with a clearly defined cutting site. Isoschizomers indicated in white font and grey background correspond to enzymes not listed in the current lists, as in this not listed enzyme:   Abc123I",1
Life Science,Cyborg,"The Borg are an alien group that appear as recurring antagonists in the Star Trek fictional universe. The Borg are cybernetic organisms (cyborgs) linked in a hive mind called ""the Collective"". The Borg co-opt the technology and knowledge of other alien species to the Collective through the process of ""assimilation"": forcibly transforming individual beings into ""drones"" by injecting nanoprobes into their bodies and surgically augmenting them with cybernetic components. The Borg's ultimate goal is ""achieving perfection"".Aside from being recurring antagonists in the Next Generation television series, they are depicted as the main threat in the film Star Trek: First Contact. In addition, they played major roles in the Voyager series.
The Borg have become a symbol in popular culture for any juggernaut against which ""resistance is futile"", a common phrase uttered by the Borg.",1
Life Science,Electrohydrogenesis,"Electrohydrogenesis or biocatalyzed electrolysis is the name given to a process for generating hydrogen gas from organic matter being decomposed by bacteria.  This process uses a modified fuel cell to contain the organic matter and water.  A small amount, 0.2–0.8 V of electricity is used, the original article reports an overall energy efficiency of 288% can be achieved (this is computed relative to the amount of electricity used, waste heat lowers the overall efficiency).  This work was reported by Cheng and Logan.",1
Life Science,Biomedical sciences,"Biomedical sciences are a set of sciences applying portions of natural science or formal science, or both, to develop knowledge, interventions, or technology that are of use in healthcare or public health.  Such disciplines as medical microbiology, clinical virology, clinical epidemiology, genetic epidemiology, and biomedical engineering are medical sciences.  In explaining physiological mechanisms operating in pathological processes, however, pathophysiology can be regarded as basic science.
Biomedical Sciences, as defined by the UK Quality Assurance Agency for Higher Education Benchmark Statement in 2015, includes those science disciplines whose primary focus is the biology of human health and disease and ranges from the generic study of biomedical sciences and human biology to more specialised subject areas such as pharmacology, human physiology and human nutrition. It is underpinned by relevant basic sciences including anatomy and physiology, cell biology, biochemistry, microbiology, genetics and molecular biology, immunology, mathematics and statistics, and bioinformatics. As such the biomedical sciences have a much wider range of academic and research activities and economic significance than that defined by hospital laboratory sciences. Biomedical Sciences are the major focus of bioscience research and funding in the 21st century.https://www.hitech-ly.com/autoclave/autoclave-common-problems/==Roles within biomedical science==
A sub-set of biomedical sciences is the science of clinical laboratory diagnosis. This is commonly referred to in the UK as 'biomedical science' or 'healthcare science'. There are at least 45 different specialisms within healthcare science, which are traditionally grouped into three main divisions:
specialisms involving life sciences
specialisms involving physiological science
specialisms involving medical physics or bioengineering

",1
Life Science,Genetic engineering,"Genetic engineering, also called genetic modification or genetic manipulation, is the direct manipulation of an organism's genes using biotechnology. It is a set of technologies used to change the genetic makeup of cells, including the transfer of genes within and across species boundaries to produce improved or novel organisms. New DNA is obtained by either isolating and copying the genetic material of interest using recombinant DNA methods or by artificially synthesising the DNA. A construct is usually created and used to insert this DNA into the host organism. The first recombinant DNA molecule was made by Paul Berg in 1972 by combining DNA from the monkey virus SV40 with the lambda virus. As well as inserting genes, the process can be used to remove, or ""knock out"", genes. The new DNA can be inserted randomly, or targeted to a specific part of the genome.An organism that is generated through genetic engineering is considered to be genetically modified (GM) and the resulting entity is a genetically modified organism (GMO). The first GMO was a bacterium generated by Herbert Boyer and Stanley Cohen in 1973. Rudolf Jaenisch created the first GM animal when he inserted foreign DNA into a mouse in 1974. The first company to focus on genetic engineering, Genentech, was founded in 1976 and started the production of human proteins. Genetically engineered human insulin was produced in 1978 and insulin-producing bacteria were commercialised in 1982. Genetically modified food has been sold since 1994, with the release of the Flavr Savr tomato. The Flavr Savr was engineered to have a longer shelf life, but most current GM crops are modified to increase resistance to insects and herbicides. GloFish, the first GMO designed as a pet, was sold in the United States in December 2003. In 2016 salmon modified with a growth hormone were sold.
Genetic engineering has been applied in numerous fields including research, medicine, industrial biotechnology and agriculture. In research GMOs are used to study gene function and expression through loss of function, gain of function, tracking and expression experiments. By knocking out genes responsible for certain conditions it is possible to create animal model organisms of human diseases. As well as producing hormones, vaccines and other drugs, genetic engineering has the potential to cure genetic diseases through gene therapy. The same techniques that are used to produce drugs can also have industrial applications such as producing enzymes for laundry detergent, cheeses and other products.
The rise of commercialised genetically modified crops has provided economic benefit to farmers in many different countries, but has also been the source of most of the controversy surrounding the technology. This has been present since its early use; the first field trials were destroyed by anti-GM activists. Although there is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, GM food safety is a leading concern with critics. Gene flow, impact on non-target organisms, control of the food supply and intellectual property rights have also been raised as potential issues. These concerns have led to the development of a regulatory framework, which started in 1975. It has led to an international treaty, the Cartagena Protocol on Biosafety, that was adopted in 2000. Individual countries have developed their own regulatory systems regarding GMOs, with the most marked differences occurring between the US and Europe.",1
Life Science,Phytotechnology,"Phytotechnology (from Ancient Greek  φυτο (phyto) 'plant', and  τεχνολογία (technología); from  τέχνη (téchnē) 'art, skill, craft', and  -λογία (-logía) 'study of-') implements solutions to scientific and engineering problems in the form of plants. It is distinct from ecotechnology and biotechnology as these fields encompass the use and study of ecosystems and living beings, respectively. Current study of this field has mostly been directed into contaminate removal (phytoremediation), storage (phytosequestration) and accumulation (see hyperaccumulators). Plant-based technologies have become alternatives to traditional cleanup procedures because of their low capital costs, high success rates, low maintenance requirements, end-use value, and aesthetic nature.",1
Life Science,Eftilagimod alpha,"Eftilagimod alpha (INN; development code IMP321 or efti) is a large-molecule cancer drug being developed by the clinical-stage biotechnology company Immutep. Efti is a soluble version of the immune checkpoint molecule LAG-3. It is an APC Activator used to increase an immune response to tumors, and is administered by subcutaneous injection. Efti has three intended clinical settings:

as adjuvant to cancer vaccines (in a low, effective dose of ~250 µg)
as first-line 'chemo-immunotherapy,' that is, combined with standard chemotherapy (e.g. paclitaxel)
in combination immunotherapy with PD-1 treatments (e.g. pembrolizumab)Eftilagimod alpha is in Phase II clinical testing. Currently, the main indications for the drug are metastatic breast cancer, non-small cell lung cancer (NSCLC), and head and neck squamous cell carcinoma (HNSCC).",1
Life Science,I-cell,"A pulmonary alveolus (plural: alveoli, from Latin alveolus, ""little cavity""), also known as an air sac or air space, is one of millions of hollow, distensible cup-shaped cavities in the lungs where oxygen is exchanged for carbon dioxide. Alveoli make up the functional tissue of the lungs known as the lung parenchyma, which takes up 90 percent of the total lung volume.Alveoli are first located in the respiratory bronchioles that mark the beginning of the  respiratory zone. They are located sparsely in these bronchioles, line the walls of the alveolar ducts, and are more numerous in the blind-ended alveolar sacs. The acini are the basic units of respiration, with gas exchange taking place in all the alveoli present. The alveolar membrane is the gas exchange surface, surrounded by a network of capillaries. Across the membrane oxygen is diffused into the capillaries and carbon dioxide released from the capillaries into the alveoli to be breathed out.Alveoli are particular to mammalian lungs. Different structures are involved in gas exchange in other vertebrates.

",1
Life Science,Antisense therapy,"Antisense therapy is a form of treatment that uses antisense oligonucleotides (ASOs) to target messenger RNA (mRNA). ASOs are capable of altering mRNA expression through a variety of mechanisms, including ribonuclease H mediated decay of the pre-mRNA, direct steric blockage, and exon content modulation through splicing site binding on pre-mRNA. Several ASOs have been approved in the United States, the European Union, and elsewhere.",1
Life Science,Peptidoglycolipid addressing protein,"The Peptidoglycolipid Addressing Protein (GAP) Family is a member of the Lysine Exporter (LysE) Superfamily. It is listed as item 2.A.116 in the Transporter Classification Database. The mechanism of its action is not known, but this family has been shown to be a member of the LsyE superfamily. Therefore, these proteins are most likely secondary carriers.
The proposed generalized reaction catalyzed by members of the GAP family is:
PGL (in) → PGL (outer membrane).",1
Life Science,Economic importance of bacteria,"Bacteria are economically important as these microorganisms are used by humans for many purposes. The beneficial uses of bacteria include the production of traditional foods such as fudge, yogurt, cheese, and vinegar. Microbes are also important in agriculture for the compost and fertilizer production. Bacteria are used in genetic engineering and genetic changes.

",1
Life Science,Modes of toxic action,"A mode of toxic action is a common set of physiological and behavioral signs that characterize a type of adverse biological response. A mode of action should not be confused with mechanism of action, which refer to the biochemical processes underlying a given mode of action. Modes of toxic action are important, widely used tools in ecotoxicology and aquatic toxicology because they classify toxicants or pollutants according to their type of toxic action. There are two major types of modes of toxic action: non-specific acting toxicants and specific acting toxicants. Non-specific acting toxicants are those that produce narcosis, while specific acting toxicants are those that are non-narcotic and that produce a specific action at a specific target site.",1
Life Science,Contract research organization,"In the life sciences, a contract research organization (CRO) is a company that provides support to the  pharmaceutical, biotechnology, and medical device industries in the form of research services outsourced on a contract basis.  A CRO may provide such services as biopharmaceutical development, biologic assay development, commercialization, clinical development, clinical trials management, pharmacovigilance, outcomes research, and Real world evidence. CROs are designed to reduce costs for companies developing new medicines and drugs in niche markets. They aim to simplify entry into drug markets, and simplify development, as the need for large pharmaceutical companies to do everything ‘in house’ is now redundant. CROs also support foundations, research institutions, and universities, in addition to governmental organizations (such as the NIH, EMA, etc.).Many CROs specifically provide clinical-study and clinical-trial support for drugs and/or medical devices. CROs range from large, international full-service organizations to small, niche specialty groups. CROs that specialize in clinical-trials services can offer their clients the expertise of moving a new drug or device from its conception to FDA/EMA marketing approval, without the drug sponsor having to maintain a staff for these services.

",1
Life Science,Microbial electrosynthesis,"Microbial electrosynthesis (MES) is a form of microbial electrocatalysis in which electrons are supplied to living microorganisms via a cathode in an electrochemical cell by applying an electric current. The electrons are then used by the microorganisms to reduce carbon dioxide to yield industrially relevant products. The electric current would ideally be produced by a renewable source of power. This process is the opposite to that employed in a microbial fuel cell, in which microorganisms transfer electrons from the oxidation of compounds to an anode to generate an electric current.

",1
Life Science,Master of Bioscience Enterprise,"A Master of Bioscience Enterprise (abbreviated MBE or MBioEnt) is a specialised degree taught at The University of Auckland, New Zealand, Karolinska Institute, Sweden and The University of Cambridge, United Kingdom. The MBE is an interdisciplinary programme incorporating multiple faculties and includes significant industry involvement.
The degree is primarily focused on the commercialisation of biotechnology. Both universities have developed the MBE programme to provide specialist business and legal skills relevant to employment in the bio-economy. The context in which both programmes were developed are significantly different. These differences are reflected in internship placements, thesis topics and postgraduate employment opportunities.",1
Life Science,Homing endonuclease,"The homing endonucleases are a collection of endonucleases encoded either as freestanding genes within introns, as fusions with host proteins, or as self-splicing inteins. They catalyze the hydrolysis of genomic DNA within the cells that synthesize them, but do so at very few, or even singular, locations. Repair of the hydrolyzed DNA by the host cell frequently results in the gene encoding the homing endonuclease having been copied into the cleavage site, hence the term 'homing' to describe the movement of these genes. Homing endonucleases can thereby transmit their genes horizontally within a host population, increasing their allele frequency at greater than Mendelian rates.

",1
Life Science,List of restriction enzyme cutting sites: S,"This article contains a list of the most studied restriction enzymes whose names start with S.  It contains approximately 130 enzymes.
The following information is given:

Enzyme: Accepted name of the molecule, according to the internationally adopted nomenclature, and bibliographical references. (Further reading: see the section ""Nomenclature"" in the article ""Restriction enzyme"".)
PDB code: Code used to identify the structure of a protein in the PDB database of protein structures. The 3D atomic structure of a protein provides highly valuable information to understand the intimate details of its mechanism of action.
Source: Organism that naturally produces the enzyme.
Recognition sequence: Sequence of DNA recognized by the enzyme and to which it specifically binds.
Cut: Cutting site and DNA products of the cut. The recognition sequence and the cutting site usually match, but sometimes the cutting site can be dozens of nucleotides away from the recognition site.
Isoschizomers and neoschizomers: An isoschizomer is an enzyme that recognizes the same sequence as another. A neoschizomer is a special type of isoschizomer that recognizes the same sequence as another, but cuts in a different manner. A maximum number of 8-10 most common isoschizomers are indicated for every enzyme but there may be many more. Neoschizomers are shown in bold and green color font (e.g.: BamHI). When ""None on date"" is indicated, that means that there were no registered isoschizomers in the databases on that date with a clearly defined cutting site. Isoschizomers indicated in white font and grey background correspond to enzymes not listed in the current lists:",1
Life Science,Organ-on-a-chip,"An organ-on-a-chip (OOC) is a multi-channel 3-D microfluidic cell culture, integrated circuit (chip) that simulates the activities, mechanics and physiological response of an entire organ or an organ system, a type of artificial organ.  It constitutes the subject matter of significant biomedical engineering research, more precisely in bio-MEMS. The convergence of labs-on-chips (LOCs) and cell biology has permitted the study of human physiology in an organ-specific context, introducing a novel model of in vitro multicellular human organisms. One day, they will perhaps abolish the need for animals in drug development and toxin testing.
Although multiple publications claim to have translated organ functions onto this interface, the movement towards this microfluidic application is still in its infancy. Organs-on-chips will vary in design and approach between different researchers. As such, validation and optimization of these systems will likely be a long process. Organs that have been simulated by microfluidic devices include brain, lung, heart, kidney, liver, prostate, vessel(artery), skin, bone, cartilage and more.
Nevertheless, building valid artificial organs requires not only a precise cellular manipulation, but a detailed understanding of the human body's fundamental intricate response to any event.  A common concern with organs-on-chips lies in the isolation of organs during testing. The body is a complex network of physiological processes, making it challenging to simulate a single organ. Microfabrication, microelectronics and microfluidics offer the prospect of modeling sophisticated in vitro physiological responses under accurately simulated conditions.The development of organ chips has enabled the study of the complex pathophysiology of human viral infections. An example is the liver chip platform that has enabled studies of viral hepatitis.",1
Life Science,Site-specific recombination,"Site-specific recombination, also known as conservative site-specific recombination, is a type of genetic recombination in which DNA strand exchange takes place between segments possessing at least a certain degree of sequence homology. Enzymes known as site-specific recombinases (SSRs) perform rearrangements of DNA segments by recognizing and binding to short, specific DNA sequences (sites), at which they cleave the DNA backbone, exchange the two DNA helices involved, and rejoin the DNA strands. In some cases the presence of a recombinase enzyme and the recombination sites is sufficient for the reaction to proceed; in other systems a number of accessory proteins and/or accessory sites are required. Many different genome modification strategies, among these recombinase-mediated cassette exchange (RMCE), an advanced approach for the targeted introduction of transcription units into predetermined genomic loci, rely on SSRs.
Site-specific recombination systems are highly specific, fast, and efficient, even when faced with complex eukaryotic genomes. They are employed naturally in a variety of cellular processes, including bacterial genome replication, differentiation and pathogenesis, and movement of mobile genetic elements. For the same reasons, they present a potential basis for the development of genetic engineering tools.Recombination sites are typically between 30 and 200 nucleotides in length and consist of two motifs with a partial inverted-repeat symmetry, to which the recombinase binds, and which flank a central crossover sequence at which the recombination takes place. The pairs of sites between which the recombination occurs are usually identical, but there are exceptions (e.g. attP and attB of λ integrase).",1
Life Science,Bacterial conjugation,"Bacterial conjugation is the transfer of genetic material between bacterial cells by direct cell-to-cell contact or by a bridge-like connection between two cells. This takes place through a pilus. It is a parasexual mode of reproduction in bacteria.
It is a mechanism of horizontal gene transfer as are transformation and transduction although these two other mechanisms do not involve cell-to-cell contact.Classical E. coli bacterial conjugation is often regarded as the bacterial equivalent of sexual reproduction or mating since it involves the exchange of genetic material. However, it is not sexual reproduction, since no exchange of gamete occurs, and indeed no generation of a new organism: instead an existing organism is transformed. During classical E. coli conjugation the donor cell provides a conjugative or mobilizable genetic element that is most often a plasmid or transposon. Most conjugative plasmids have systems ensuring that the recipient cell does not already contain a similar element.
The genetic information transferred is often beneficial to the recipient. Benefits may include antibiotic resistance, xenobiotic tolerance or the ability to use new metabolites. Other elements can be detrimental and may be viewed as bacterial parasites.
Conjugation in Escherichia coli by spontaneous zygogenesis and in Mycobacterium smegmatis by distributive conjugal transfer differ from the better studied classical E. coli conjugation in that these cases involve substantial blending of the parental genomes.

",1
Life Science,List of restriction enzyme cutting sites: O–R,"This article contains a list of the most studied restriction enzymes whose names start with O to R inclusive.  It contains approximately 130 enzymes.
The following information is given:

Enzyme: Accepted name of the molecule, according to the internationally adopted nomenclature, and bibliographical references. (Further reading: see the section ""Nomenclature"" in the article ""Restriction enzyme"".)
PDB code: Code used to identify the structure of a protein in the PDB database of protein structures. The 3D atomic structure of a protein provides highly valuable information to understand the intimate details of its mechanism of action.
Source: Organism that naturally produces the enzyme.
Recognition sequence: Sequence of DNA recognized by the enzyme and to which it specifically binds.
Cut: Cutting site and DNA products of the cut. The recognition sequence and the cutting site usually match, but sometimes the cutting site can be dozens of nucleotides away from the recognition site.
Isoschizomers and neoschizomers: An isoschizomer is an enzyme that recognizes the same sequence as another. A neoschizomer is a special type of isoschizomer that recognizes the same sequence as another, but cuts in a different manner. A maximum number of 8-10 most common isoschizomers are indicated for every enzyme but there may be many more. Neoschizomers are shown in bold and green color font (e.g.: BamHI). When ""None on date"" is indicated, that means that there were no registered isoschizomers in the databases on that date with a clearly defined cutting site. Isoschizomers indicated in white font and grey background correspond to enzymes not listed in the current lists:

",1
Life Science,Expression vector,"An expression vector, otherwise known as an expression construct, is usually a plasmid or virus designed for gene expression in cells. The vector is used to introduce a specific gene into a target cell, and can commandeer the cell's mechanism for protein synthesis to produce the protein encoded by the gene.  Expression vectors are the basic tools in biotechnology for the production of proteins.
The vector is engineered to contain regulatory sequences that act as enhancer and promoter regions and lead to efficient transcription of the gene carried on the expression vector. The goal of a well-designed expression vector is the efficient production of protein, and this may be achieved by the production of significant amount of stable messenger RNA, which can then be translated into protein. The expression of a protein may be tightly controlled, and the protein is only produced in significant quantity when necessary through the use of an inducer, in some systems however the protein may be expressed constitutively. Escherichia coli is commonly used as the host for protein production, but other cell types may also be used. An example of the use of expression vector is the production of insulin, which is used for medical treatments of diabetes.

",1
Life Science,Axenic,"In biology, axenic (, ) describes the state of a culture in which only a single species, variety, or strain of organism is present and entirely free of all other contaminating organisms. The earliest axenic cultures were  of  bacteria or unicellular eukaryotes, but axenic cultures of many multicellular organisms are also possible. Axenic culture is an important tool for the study of symbiotic and parasitic organisms in a controlled environment.",1
Life Science,Mitochondrial fusion,"Mitochondria are dynamic organelles with the ability to fuse and divide (fission), forming constantly changing tubular networks in most eukaryotic cells. These mitochondrial dynamics, first observed over a hundred years ago are important for the health of the cell, and defects in dynamics lead to genetic disorders. Through fusion, mitochondria can overcome the dangerous consequences of genetic malfunction. The process of mitochondrial fusion involves a variety of proteins that assist the cell throughout the series of events that form this process.

",1
Life Science,Complex systems biology,"Complex systems biology (CSB) is a branch or subfield of mathematical and theoretical biology invented by Robert Rosen concerned with complexity of both structure and function in biological organisms, as well as the emergence and evolution of organisms and species, with emphasis being placed on the interconnectivity of, and within, biological network inference, and on  modelling the fundamental relations inherent to life.According to Baianu et al.  CSB is a field that has only a partial overlap with the more conventional concepts of complex systems theory and systems biology, because CSB is concerned with philosophy and human consciousness. Moreover, mathematics can model a wide range of complex systems, but this is claimed not to be relevant.",1
Life Science,Allometric engineering,"Allometry is the study of the relationship of body size to shape, anatomy, physiology and finally behaviour, first outlined by Otto Snell in 1892, by D'Arcy Thompson in 1917 in On Growth and Form and by Julian Huxley in 1932.",1
Life Science,National Institute of Biotechnology,National Institute of Biotechnology (NIB)(Bengali: ন্যাশনাল ইনস্টিটিউট অব বায়োটেকনোলজি) is a governmental institute in Bangladesh under the Ministry of Science and Technology.,1
Life Science,Lateral flow test,"A lateral flow test (LFT), is an Assay also known as a lateral flow device (LFD), lateral flow immunochromatographic assay, or rapid test, is a simple device intended to detect the presence of a target substance in a liquid sample without the need for specialized and costly equipment.  LFTs are widely used in medical diagnostics in the home, at the point of care, and in the laboratory. For instance, the home pregnancy test is an LFT that detects a specific hormone. These tests are simple and economical and generally show results in around five to thirty minutes. Many lab-based applications increase the sensitivity of simple LFTs by employing additional dedicated equipment. Because the target substance is often a biological antigen, many lateral flow tests are rapid antigen tests (RAT or ART). 
LFTs operate on the same principles of affinity chromatography as the enzyme-linked immunosorbent assays (ELISA). In essence, these tests run the liquid sample along the surface of a pad with reactive molecules that show a visual positive or negative result.   The pads are based on a series of capillary beds, such as pieces of porous paper, microstructured polymer, or sintered polymer. Each of these pads has the capacity to transport fluid (e.g., urine, blood, saliva) spontaneously.The sample pad acts as a sponge and holds an excess of sample fluid. Once soaked, the fluid flows to the second conjugate pad in which the manufacturer has stored freeze dried bio-active particles called conjugates (see below) in a salt–sugar matrix. The conjugate pad contains all the reagents required for an optimized chemical reaction between the target molecule (e.g., an antigen) and its chemical partner (e.g., antibody) that has been immobilized on the particle's surface. This marks target particles as they pass through the pad and continue across to the test and control lines. The test line shows a signal, often a color as in pregnancy tests. The control line contains affinity ligands which show whether the sample has flowed through and the bio-molecules in the conjugate pad are active. After passing these reaction zones, the fluid enters the final porous material, the wick, that simply acts as a waste container.
LFTs can operate as either competitive or sandwich assays.",1
Life Science,Progenitor cell,"A progenitor cell is a biological cell that can differentiate into a specific cell type. Stem cells and progenitor cells have this ability in common. However, stem cells are less specified than progenitor cells. Progenitor cells can only differentiate into their ""target"" cell type. The most important difference between stem cells and progenitor cells is that stem cells can replicate indefinitely, whereas progenitor cells can divide only a limited number of times.  Controversy about the exact definition remains and the concept is still evolving.The terms ""progenitor cell"" and ""stem cell"" are sometimes equated.",1
Life Science,Antibody-oligonucleotide conjugate,"Antibody-drug conjugates or ADCs are a class of biopharmaceutical drugs designed as a targeted therapy for treating cancer. Unlike chemotherapy, ADCs are intended to target and kill tumor cells while sparing healthy cells. As of 2019, some 56 pharmaceutical companies were developing ADCs.ADCs are complex molecules composed of an antibody linked to a biologically active cytotoxic (anticancer) payload or drug. Antibody-drug conjugates are examples of bioconjugates and immunoconjugates.
ADCs combine the targeting capabilities of monoclonal antibodies with the cancer-killing ability of cytotoxic drugs. They can be designed to discriminate between healthy and diseased tissue.",1
Life Science,Strep-tag,"The Strep-tag system is a method which allows the purification and detection of proteins by affinity chromatography. The Strep-tag II is a synthetic peptide consisting of eight amino acids (Trp-Ser-His-Pro-Gln-Phe-Glu-Lys). This peptide sequence exhibits intrinsic affinity towards Strep-Tactin, a specifically engineered streptavidin, and can be N- or C- terminally fused to recombinant proteins. By exploiting the highly specific interaction, Strep-tagged proteins can be isolated in one step from crude cell lysates. Because the Strep-tag elutes under gentle, physiological conditions it is especially suited for generation of functional proteins.",1
Life Science,PTC Therapeutics,"PTC Therapeutics is a US pharmaceutical company focused on the development of orally administered small molecule drugs and gene therapy which regulate gene expression by targeting post-transcriptional control (PTC) mechanisms in orphan diseases.In September 2009, PTC entered into an agreement with Roche for the development of orally bioavailable small molecules for central nervous system diseases. In 2020, PTC announced the FDA approval of Evrysdi™ (risdiplam) for the treatment of spinal muscular atrophy (SMA) in adults and children 2 months and older, in partnership with the SMA Foundation and Roche.
PTC acquired the Bio-e platform in 2019. The Bio-e platform utilizes expertise in electron-transfer chemistry to modulate key biological processes beyond the reach of current drug development approaches. The lead compounds from the Bio-e platform, PTC743 and PTC857, target the enzyme 15-lipoxygenase – a key enzymatic hub that regulates the inflammation and oxidative stress that underpin mitochondrial disease and CNS pathology. Two pivotal studies will investigate the safety and efficacy of PTC743: a Phase 2/3 trial in refractory mitochondrial epilepsy and a Phase 3 trial in Friedreich’s ataxia.

",1
Life Science,Certolizumab pegol,"Certolizumab pegol, sold under the brand name Cimzia, is a biologic medication for the treatment of Crohn's disease, rheumatoid arthritis, psoriatic arthritis and ankylosing spondylitis. It is a fragment of a monoclonal antibody specific to tumor necrosis factor alpha (TNF-α) and is manufactured by UCB.It is on the World Health Organization's List of Essential Medicines.",1
Life Science,Genotyping by sequencing,"In the field of genetic sequencing, genotyping by sequencing, also called GBS, is a method to discover single nucleotide polymorphisms (SNP) in order to perform genotyping studies, such as genome-wide association studies (GWAS). GBS uses restriction enzymes to reduce genome complexity and genotype multiple DNA samples. After digestion, PCR is performed to increase fragments pool and then GBS libraries are sequenced using next generation sequencing technologies, usually resulting in about 100bp single-end reads. It is relatively inexpensive and has been used in plant breeding. Although GBS presents an approach similar to restriction-site-associated DNA sequencing (RAD-seq) method, they differ in some substantial ways.

",1
Life Science,Discovery District,"The Discovery District is one of the commercial districts in Downtown Toronto, Ontario, Canada. It has a high concentration of hospitals and research institutions, particularly those related to biotechnology. The district is roughly bounded by Bloor Street on the north, Bay Street on the east, Dundas Street on the south, and Spadina Avenue on the west.

",1
Life Science,Lung-on-a-chip,"The lung-on-a-chip is a complex, three-dimensional model of a living, breathing human lung on a microchip. The device is made using human lung and blood vessel cells and it can predict absorption of airborne nanoparticles and mimic the inflammatory response triggered by microbial pathogens. It can be used to test the effects of environmental toxins, absorption of aerosolized therapeutics, and the safety and efficacy of new drugs. It is expected to become an alternative to animal testing.
The lung-on-a-chip places two layers of living tissues—the lining of the lung's air sacs and the blood vessels that surround them—across a porous, flexible boundary. Air is delivered to the lung lining cells, a rich culture medium flows in the capillary channel to mimic blood, and cyclic mechanical stretching is generated by a vacuum applied to the chambers adjacent to the cell culture channels to mimic breathing.
The research findings for lung-on-a-chip were published in the June 25, 2010, issue of Science, the academic journal of the American Association for the Advancement of Science.  The research was funded by the National Institutes of Health, the American Heart Association, and the Wyss Institute for Biologically Inspired Engineering at Harvard University.",1
Life Science,Biomimetics,"Biomimetics or biomimicry is the emulation of the models, systems, and elements of nature for the purpose of solving complex human problems. The terms ""biomimetics"" and ""biomimicry"" are derived from Ancient Greek: βίος (bios), life, and μίμησις (mīmēsis), imitation, from μιμεῖσθαι (mīmeisthai), to imitate, from μῖμος (mimos), actor. A closely related field is bionics.Living organisms have evolved well-adapted structures and materials over geological time through natural selection. Biomimetics has given rise to new technologies inspired by biological solutions at macro and nanoscales. Humans have looked at nature for answers to problems throughout their existence. Nature has solved engineering problems such as self-healing abilities, environmental exposure tolerance and resistance, hydrophobicity, self-assembly, and harnessing solar energy.",1
Life Science,Protein arginine phosphatase,"Protein Arginine Phosphatase (PAPs), also known as Phosphoarginine Phosphatase, is an enzyme that catalyzes the dephosphorylation of phosphoarginine residues in proteins. Protein phosphatases (PPs) are ""obligatory heteromers"" made up of two maximum catalytic subunits attached to a non-catalytic subunit. Arginine modification is a post-translational protein modification in gram-positive bacteria. McsB and YwIE were recently identified as phosphorylating enzymes in Bacillus Subtilis (B.Subtilis). YwIE was thought to be a protein-tyrosine-phosphatase, and McsB a tyrosine-kinase, however in 2012 Elsholz et al. showed that McsB is a protein-arginine-kinase (PAK) and YwlE is a phosphatase-arginine-phosphatase (PAP).
Many proteins rely on protein phosphatase activity for regulating their stability, localization, and interaction with other proteins. Arginine modification is a post-translational protein modification in gram-positive bacteria, and protein arginine phosphorylation regulates transcription factors, in addition to tagging rogue proteins for degradation in gram-positive bacteria. Like phosphorylation, dephosphorylation is a reversible post-translational event. It is reversible through the action of kinases (enzymes that adds a phosphate group to a protein via phosphorylation), and this antagonist activity of phosphorylation and dephosphorylation of proteins controls all aspect of prokaryotic and eukaryotic life. In general, protein phosphatases play a crucial role in cell signaling regulation in both eukaryotes and prokaryotes. They act by removing a phosphate group from proteins, and their activity counteracts that of protein kinases.",1
Life Science,Biorefining,"Biorefining is the process of ""building"" multiple products from biomass as a feedstock or raw material much like a petroleum refinery that is currently in use. A biorefinery is a facility like a petroleum refinery that comprises the various process steps or unit operations and related equipment to produce various bioproducts including fuels, power, materials and chemicals from biomass. Industrial biorefineries have been identified as the most promising route to the creation of a new domestic biobased industry producing entire spectrum of bioproducts or bio-based products.
Biomass has various components such as lignin, cellulose, hemicellulose, extractives, etc. Biorefinery can take advantage of the unique properties of each of biomass components enabling the production of various products. The various bioproducts can include fiber, fuels, chemicals, plastics etc.",1
Life Science,Registry of Standard Biological Parts,"The Registry of Standard Biological Parts is a collection of genetic parts that are used in the assembly of systems and devices in synthetic biology. The registry was founded in 2003 at the Massachusetts Institute of Technology. The registry, as of 2018, contains over 20,000 parts. Recipients of the genetic parts include academic labs, established scientists, and student teams participating in the iGEM Foundation's annual synthetic biology competition.The Registry of Standard Biological Parts conforms to the BioBrick standard, a standard for interchangeable genetic parts. BioBrick was developed by a nonprofit composed of researchers from MIT, Harvard, and UCSF. The registry offers genetic parts with the expectation that recipients will contribute data and new parts to improve the resource. The registry records and indexes biological parts and offers services including the synthesis and assembly of biological parts, systems, and devices.
The registry offers many types of biological parts, including DNA, plasmids, plasmid backbones, primers, promoters, protein coding sequences, protein domains, ribosomal binding sites, terminators, translational units, riboregulators, and composite parts. It also includes devices such as protein generators, reporters, inverters, receptors, senders, and measurement devices. A key idea that motivated the development of the Registry was to develop an abstraction hierarchy implemented through the parts categorization system.The registry has previously received external funding through grants from the National Science Foundation, the Defense Advanced Research Projects Agency, and the National Institutes of Health.",1
Life Science,Heterologous expression,"Heterologous expression refers to the expression of a gene or part of a gene in a host organism which does not naturally have this gene or gene fragment. Insertion of the gene in the heterologous host is performed by recombinant DNA technology. After being inserted in the host, the gene may be integrated into the host DNA, causing permanent expression, or not integrated, causing transient expression. Heterologous expression can be done in many type of host organisms. The host organism can be a bacterium, yeast, mammalian cell, or plant cell. This host is called the ""expression system"".
Homologous expression, on the other hand, refers to the overexpression of a gene in a system from where it originates.
Genes are subjected to heterologous expression often to study specific protein interactions. E. coli, yeast (S. cerevisiae, P. pastoris), immortalized mammalian cells, and amphibian oocytes (i.e. unfertilized eggs) are commonly for studies that require heterologous expression.",1
Life Science,Oncolytic herpes virus,"An oncolytic virus is a virus that preferentially infects and kills cancer cells. As the infected cancer cells are destroyed by oncolysis, they release new infectious virus particles or virions to help destroy the remaining tumour. Oncolytic viruses are thought not only to cause direct destruction of the tumour cells, but also to stimulate host anti-tumour immune system responses. Oncolytic viruses also have the ability to affect the tumor micro-environment in multiples ways.The potential of viruses as anti-cancer agents was first realised in the early twentieth century, although coordinated research efforts did not begin until the 1960s. A number of viruses including adenovirus, reovirus, measles, herpes simplex, Newcastle disease virus, and vaccinia have been clinically tested as oncolytic agents. Most current oncolytic viruses are engineered for tumour selectivity, although there are naturally occurring examples such as reovirus and the senecavirus, resulting in clinical trials.The first oncolytic virus to be approved by a national regulatory agency was genetically unmodified ECHO-7 strain enterovirus RIGVIR, which was approved in Latvia in 2004 for the treatment of skin melanoma; the approval was withdrawn in 2019. An oncolytic adenovirus, a genetically modified adenovirus named H101, was approved in China in 2005 for the treatment of head and neck cancer. In 2015, talimogene laherparepvec (OncoVex, T-VEC), an oncolytic herpes virus which is a modified herpes simplex virus, became the first oncolytic virus to be approved for use in the U.S. and European Union, for the treatment of advanced inoperable melanoma.",1
Life Science,List of restriction enzyme cutting sites,"A restriction enzyme or restriction endonuclease is a special type of biological macromolecule that functions as part of the ""immune system"" in bacteria. One special kind of restriction enzymes is the class of ""homing endonucleases"", these being present in all three domains of life, although their function seems to be very different from one domain to another.
The classical restriction enzymes cut up, and hence render harmless, any unknown (non-cellular) DNA that enters a bacterial cell as a result of a viral infection. They recognize a specific DNA sequence, usually short (3 to 8 bp), and cut it, producing either blunt or overhung ends, either at or nearby the recognition site.
Restriction enzymes are quite variable in the short DNA sequences they recognize. An organism often has several different enzymes, each specific to a distinct short DNA sequence.
See the main article on restriction enzyme.
Further reading: Homing endonuclease.

",1
Life Science,Biological hydrogen production (algae),"Biohydrogen is H2 that is produced biologically.  Interest is high in this technology because H2 is a clean fuel and can be readily produced from certain kinds of biomass.Many challenges characterize this technology, including those intrinsic to H2, such as storage and transportation of a noncondensible gas.  Hydrogen producing organisms are poisoned by O2.  Yields of H2 are often low.",1
Life Science,Intron-encoded endonuclease I-SceI,Intron-encoded endonuclease I-Sce I is a homing endonuclease. The enzyme is used in biotechnology as a meganuclease. It recognises an 18-base pair sequence TAGGGATAACAGGGTAAT and leaves a 4 base pair 3' hydroxyl overhang. It is a rare cutting endonuclease. Statistically an 18-bp sequence will occur once in every 6.9*1010 base pairs (a frequency of 1 in 418). This sequence does not normally occur in a human or mouse genome.,1
Life Science,List of restriction enzyme cutting sites: Bsa–Bso,"A restriction enzyme or restriction endonuclease is a special type of biological macromolecule that functions as part of the ""immune system"" in bacteria. One special kind of restriction enzymes is the class of ""homing endonucleases"", these being present in all three domains of life, although their function seems to be very different from one domain to another.
The classical restriction enzymes cut up, and hence render harmless, any unknown (non-cellular) DNA that enters a bacterial cell as a result of a viral infection. They recognize a specific DNA sequence, usually short (3 to 8 bp), and cut it, producing either blunt or overhung ends, either at or nearby the recognition site.
Restriction enzymes are quite variable in the short DNA sequences they recognize. An organism often has several different enzymes, each specific to a distinct short DNA sequence.
See the main article on restriction enzyme.
Further reading: Homing endonuclease.

",1
Life Science,Protein–DNA interaction,"DNA-binding proteins are proteins that have DNA-binding domains and thus have a specific or general affinity for single- or double-stranded DNA. Sequence-specific DNA-binding proteins generally interact with the major groove of B-DNA, because it exposes more functional groups that identify a base pair. However, there are some known minor groove DNA-binding ligands such as netropsin, distamycin, Hoechst 33258, pentamidine, DAPI and others.",1
Life Science,Chem-seq,"Chem-seq is a technique that is used to map genome-wide interactions between small molecules and their protein targets in the chromatin of eukaryotic cell nuclei. The method employs chemical affinity capture coupled with massively parallel DNA sequencing to identify genomic sites where small molecules interact with their target proteins or DNA.  It was first described by Lars Anders et al. in the January, 2014 issue of ""Nature Biotechnology"".",1
Life Science,AlgaePARC,"Wageningen UR (University & Research centre) has constructed AlgaePARC (Algae Production And Research Centre) at the Wageningen Campus. The goal of AlgaePARC is to fill the gap between fundamental research on algae and full-scale algae production facilities. This will be done by setting up flexible pilot scale facilities to perform applied research and obtain direct practical experience. It is a joined initiative of BioProcess Engineering and Food & Biobased Research of the Wageningen University.
AlgaePARC facility
AlgaePARC uses four different photobioreactors comprising 24 m2 ground surface: an open pond, two types of tubular reactors and a plastic film bioreactor, and a number of smaller systems for the testing of new technologies. This facility is unique, because it is the first facility in which the productivity of four different production systems can be compared during the year under identical conditions. At the same time, knowledge is gained for the development of new photobioreactors and the design of systems on a production scale.
For the construction of the facility 2.25 M€  has been made available by the Ministry of Agriculture, Nature and Food Quality (1.5 M€) and the Provincie Gelderland (0.75 M€).
Microalgae
Microalgae are currently seen by some persons as a promising source of biodiesel and chemical building blocks, which can be used in paint and plastics. Biomass from algae offers a sustainable alternative to products and fuels from the petrochemical industry. When fully developed this contributes to a biobased economy as algae help to reduce the emissions of carbon dioxide (CO2) and make the economy less dependent on fossil fuels.
AlgaePARC research
The costs of biomass produced from algae for biofuels are still ten times too high to be able to compete with today’s other fuels. Within the business community, the question being asked is how it could be produced more cheaply, making it economically viable. Companies within the energy, food, oil and chemical sectors, the Ministry of Agriculture, Nature & Food Quality, the Provincial Government of Gelderland, Oost NV and Wageningen UR are all working together in or contributing to the algae research centre AlgaePARC in order to answer that question.

",1
Life Science,Nb.BbvCI,Nb.BbvCI is a nicking endonuclease used to cut one strand of double-stranded DNA. It has been successfully used to incorporate fluorochrome-labeled nucleotides into specific spots of a DNA sequence via nick translation.,1
Life Science,Electroporation,"Electroporation, or electropermeabilization, is a microbiology technique in which an electrical field is applied to cells in order to increase the permeability of the cell membrane, allowing chemicals, drugs, electrode arrays or DNA to be introduced into the cell (also called electrotransfer). In microbiology, the process of electroporation is often used to transform bacteria, yeast, or plant protoplasts by introducing new coding DNA. If bacteria and plasmids are mixed together, the plasmids can be transferred into the bacteria after electroporation, though depending on what is being transferred, cell-penetrating peptides or CellSqueeze could also be used. Electroporation works by passing thousands of volts (~8 kV/cm) across suspended cells in an electroporation cuvette. Afterwards, the cells have to be handled carefully until they have had a chance to divide, producing new cells that contain reproduced plasmids. This process is approximately ten times more effective in increasing cell membrane's permeability than chemical transformation.Electroporation is also highly efficient for the introduction of foreign genes into tissue culture cells, especially mammalian cells. For example, it is used in the process of producing knockout mice, as well as in tumor treatment, gene therapy, and cell-based therapy.  The process of introducing foreign DNA into eukaryotic cells is known as transfection.  Electroporation is highly effective for transfecting cells in suspension using electroporation cuvettes. Electroporation has proven efficient for use on tissues in vivo, for in utero applications as well as in ovo transfection.  Adherent cells can also be transfected using electroporation, providing researchers with an alternative to trypsinizing their cells prior to transfection. One downside to electroporation, however, is that after the process the gene expression of over 7,000 genes can be affected. This can cause problems in studies where gene expression has to be controlled to ensure accurate and precise results.
Although bulk electroporation has many benefits over physical delivery methods such as microinjections and gene guns, it still has limitations, including low cell viability. Miniaturization of electroporation has been studied, leading to microelectroporation and nanotransfection of tissue utilizing electroporation-based techniques via nanochannels to minimally invasively deliver cargo to the cells.Electroporation has also been used as a mechanism to trigger cell fusion. Artificially induced cell fusion can be used to investigate and treat different diseases, like diabetes, regenerate axons of the central nerve system, and produce cells with desired properties, such as in cell vaccines for cancer immunotherapy. However, the first and most known application of cell fusion is production of monoclonal antibodies in hybridoma technology, where hybrid cell lines (hybridomas) are formed by fusing specific antibody-producing B lymphocytes with a myeloma (B lymphocyte cancer) cell line.",1
Life Science,DEPT (medicine),"Directed enzyme prodrug therapy (DEPT) uses enzymes artificially introduced into the body to  convert prodrugs, which have no or poor biologically activity, to the active form in the desired location within the body. Many chemotherapy drugs for cancer lack tumour specificity and the doses required to reach therapeutic levels in the tumour are often toxic to other tissues. DEPT strategies are an experimental method of reducing the systemic toxicity of a drug, by achieving high levels of the active drug only at the desired site. This article describes the variations of DEPT technology.

",1
Life Science,Animal efficacy rule,"The FDA animal efficacy rule (also known as animal rule) applies to development and testing of drugs and biologicals to reduce or prevent serious or life-threatening conditions caused by exposure to lethal or permanently disabling toxic agents (chemical, biological, radiological, or nuclear substances), where human efficacy trials are not feasible or ethical. The animal efficacy rule was finalized by the FDA and authorized by the United States Congress in 2002, following the September 11 attacks and concerns regarding bioterrorism.",1
Life Science,FlowFET,"A flowFET is a microfluidic component which allows the rate of flow of liquid in a microfluidic channel to be modulated by the electrical potential applied to it. In this way, it behaves as a microfluidic analogue to  the field effect transistor, except that in the flowFET the flow of liquid takes the place of the flow of electric current. Indeed, the name of the flowFET is derived from the naming convention of electronic FETs (e.g. MOSFET, FINFET etc.).",1
Life Science,Immune Therapy Holdings,"Immune Therapy Holdings AB or ITH is a Swedish biotechnology R&D holding company headquartered at the Karolinska Institutet and Karolinska University Hospital in Stockholm.
ITH's research is primarily focused on its Tailored Leukapheresis  (TLA) treatment for immune mediated inflammatory diseases (IMIDs).

",1
Life Science,Compartmentalized ciliogenesis,Compartmentalized ciliogenesis is the most common type of ciliogenesis where the cilium axoneme is formed separated from the cytoplasm by the ciliary membrane and a ciliary gate known as the transition zone.,1
Life Science,High-performance Integrated Virtual Environment,"The High-performance Integrated Virtual Environment (HIVE) is a distributed computing environment used for healthcare-IT and biological research, including analysis of Next Generation Sequencing (NGS) data, preclinical, clinical and post market data, adverse events, metagenomic data, etc.  Currently it is supported and continuously developed by US Food and Drug Administration (government domain), George Washington University (academic domain), and by DNA-HIVE, WHISE-Global and Embleema (commercial domain). HIVE currently operates fully functionally within the US FDA supporting wide variety (+60) of regulatory research and regulatory review projects as well as for supporting MDEpiNet medical device postmarket registries. Academic deployments of HIVE are used for research activities and publications in NGS analytics, cancer research, microbiome research and in educational programs for students at GWU. Commercial enterprises use HIVE for oncology, microbiology, vaccine manufacturing, gene editing,  healthcare-IT, harmonization of real-world data, in preclinical research and clinical studies.

",1
Life Science,Folate targeting,"Folate targeting is a method utilized in biotechnology for drug delivery purposes.  This Trojan Horse process, which was created by Drs. Christopher P. Leamon and Philip S. Low, involves the attachment of the vitamin, folate (folic acid), to a molecule/drug to form a ""folate conjugate"".  Based on the natural high affinity of folate for the folate receptor protein (FR), which is commonly expressed on the surface of many human cancers, folate-drug conjugates also bind tightly to the FR and trigger cellular uptake via endocytosis.  Molecules as diverse as small radiodiagnostic imaging agents to large DNA plasmid formulations have successfully been delivered inside FR-positive cells and tissues.",1
Life Science,Artificially Expanded Genetic Information System,"Artificially Expanded Genetic Information System (AEGIS) is a synthetic DNA analog experiment that uses some unnatural base pairs from the laboratories of the Foundation for Applied Molecular Evolution in Gainesville, Florida. AEGIS is a NASA-funded project to try to understand how extraterrestrial life may have developed.The system uses twelve different nucleobases in its genetic code. These include the four canonical nucleobases found in DNA (adenine, cytosine, guanine and thymine) plus eight synthetic nucleobases). AEGIS includes S:B, Z:P, V:J and K:X base pairs.",1
Life Science,Infradian rhythm,"In chronobiology, an infradian rhythm is a rhythm with a period longer than the period of a circadian rhythm, i.e., with a frequency of less than one cycle in 24 hours. Some examples of infradian rhythms in mammals include menstruation, breeding, migration, hibernation, molting and fur or hair growth, and tidal or seasonal rhythms. In contrast, ultradian rhythms have periods shorter than the period of a circadian rhythm. Several infradian rhythms are known to be caused by hormone stimulation or exogenous factors. For example, seasonal depression, an example of an infradian rhythm occurring once a year, can be caused by the systematic lowering of light levels during the winter.",1
Life Science,Combinatorial biology,"In biotechnology, combinatorial biology is the creation of a large number of compounds (usually proteins or peptides) through technologies such as phage display. Similar to combinatorial chemistry, compounds are produced by biosynthesis rather than organic chemistry. This process was developed independently by Richard A. Houghten and H. Mario Geysen in the 1980s.  Combinatorial biology allows the generation and selection of the large number of ligands for high-throughput screening.Combinatorial biology techniques generally begin with large numbers of peptides, which are generated and screened by physically linking a gene encoding a protein and a copy of said protein. This could involve the protein being fused to the M13 minor coat protein pIII, with the gene encoding this protein being held within the phage particle. Large libraries of phages with different proteins on their surfaces can then be screened through automated selection and amplification for a protein that binds tightly to a particular target.",1
Life Science,Human HGF plasmid DNA therapy,"Human HGF plasmid DNA therapy of cardiomyocytes is being examined as a potential treatment for coronary artery disease (a major cause of myocardial infarction (MI)), as well as treatment for the damage that occurs to the heart after MI.  After MI, the myocardium suffers from reperfusion injury which leads to death of cardiomyocytes and detrimental remodelling of the heart, consequently reducing proper cardiac function. Transfection of cardiac myocytes with human HGF reduces ischemic reperfusion injury after MI. The benefits of HGF therapy include preventing improper remodelling of the heart and ameliorating heart dysfunction post-MI.",1
Life Science,Protein–protein interaction,"Protein–protein interactions (PPIs) are physical contacts of high specificity established between two or more protein molecules as a result of biochemical events steered by interactions that include electrostatic forces, hydrogen bonding and the hydrophobic effect. Many are physical contacts with molecular associations between chains that occur in a cell or in a living organism in a specific biomolecular context.
Proteins rarely act alone as their functions tend to be regulated. Many molecular processes within a cell are carried out by molecular machines that are built from numerous protein components organized by their PPIs. These physiological interactions make up the so-called interactomics of the organism, while aberrant PPIs are the basis of multiple aggregation-related diseases, such as Creutzfeldt–Jakob and Alzheimer's diseases.
PPIs have been studied with many methods and from different perspectives: biochemistry, quantum chemistry, molecular dynamics, signal transduction, among others. All this information enables the creation of large protein interaction networks – similar to metabolic or genetic/epigenetic networks – that empower the current knowledge on biochemical cascades and molecular etiology of disease, as well as the discovery of putative protein targets of therapeutic interest.",1
Life Science,Human Medicines Regulations 2012,"The Human Medicines Regulations 2012  in the United Kingdom were created, under statutory authority of the European Communities Act 1972 and the Medicines Act 1968 in 2012. The body responsible for their upkeep is the Medicines and Healthcare products Regulatory Agency. The regulations partially repealed the Medicines Act 1968 in line with EU legislation.",1
Life Science,3D cell culturing by magnetic levitation,"3D cell culture by the magnetic levitation method (MLM) is the application of growing 3D tissue by inducing cells treated with magnetic nanoparticle assemblies in spatially varying magnetic fields using neodymium magnetic drivers and promoting cell to cell interactions by levitating the cells up to the air/liquid interface of a standard petri dish. The magnetic nanoparticle assemblies consist of magnetic iron oxide nanoparticles, gold nanoparticles, and the polymer polylysine. 3D cell culturing is scalable, with the capability for culturing 500 cells to millions of cells or from single dish to high-throughput low volume systems. Once magnetized cultures are generated, they can also be used as the building block material, or the ""ink"", for the magnetic 3D bioprinting process.",1
Life Science,DNA ligase,"DNA ligase is a specific type of enzyme, a ligase, (EC 6.5.1.1) that facilitates the joining of DNA strands together by catalyzing the formation of a phosphodiester bond. It plays a role in repairing single-strand breaks in duplex DNA in living organisms, but some forms (such as DNA ligase IV) may specifically repair double-strand breaks (i.e. a break in both complementary strands of DNA). Single-strand breaks are repaired by DNA ligase using the complementary strand of the double helix as a template, with DNA ligase creating the final phosphodiester bond to fully repair the DNA.
DNA ligase is used in both DNA repair and DNA replication (see Mammalian ligases).  In addition, DNA ligase has extensive use in molecular biology laboratories for recombinant DNA experiments (see Research applications). Purified DNA ligase is used in gene cloning to join DNA molecules together to form recombinant DNA.",1
Life Science,Biomaterial surface modifications,"Biomaterials exhibit various degrees of compatibility with the harsh environment within a living organism. They need to be nonreactive chemically and physically with the body, as well as integrate when deposited into tissue. The extent of compatibility varies based on the application and material required. Often modifications to the surface of a biomaterial system are required to maximize performance. The surface can be modified in many ways, including plasma modification and applying coatings to the substrate. Surface modifications can be used to affect surface energy, adhesion, biocompatibility, chemical inertness, lubricity, sterility, asepsis, thrombogenicity, susceptibility to corrosion, degradation, and hydrophilicity.",1
Life Science,Trichoderma hamatum,"Trichoderma hamatum is a species of fungus in the family Hypocreaceae. It has been used a biological control of certain plant diseases.

",1
Life Science,Human cloning,"Human cloning is the creation of a genetically identical copy (or clone) of a human. The term is generally used to refer to artificial human cloning, which is the reproduction of human cells and tissue. It does not refer to the natural conception and delivery of identical twins. The possibility of human cloning has raised controversies. These ethical concerns have prompted several nations to pass laws regarding human cloning.
Two commonly discussed types of human cloning are therapeutic cloning and reproductive cloning.
Therapeutic cloning would involve cloning cells from a human for use in medicine and transplants. It is an active area of research, but is not in medical practice anywhere in the world, as of 2022. Two common methods of therapeutic cloning that are being researched are somatic-cell nuclear transfer and (more recently) pluripotent stem cell induction.
Reproductive cloning would involve making an entire cloned human, instead of just specific cells or tissues.",1
Life Science,Genome Project-Write,"The Genome Project - Write (also known as GP-Write) is a large-scale collaborative research project (an extension of Genome Projects, aimed at reading genomes since 1984) that focuses on the development of technologies for the synthesis and testing of genomes of many different species of microbes, plants, and animals, including the human genome in a sub-project known as Human Genome Project-Write (HGP-Write). Formally announced on 2 June 2016, the project leverages two decades of work on synthetic biology and artificial gene synthesis.
The newly created GP-Write project will be managed by the Center of Excellence for Engineering Biology, an American nonprofit organization. Researchers expect that the ability to artificially synthesize large portions of many genomes will result in many scientific and medical advances.",1
Life Science,TK cell therapy,"TK is an experimental cell therapy which may be used to treat high-risk leukemia.  It is currently undergoing a Phase III clinical trial to determine efficacy and clinical usefulness.TK is currently being investigated in patients suffering from acute leukemia in first or subsequent complete remission and at high risk of relapse or in patients with relapsed disease who are candidates for haploidentical transplantation of hemopoietic stem cells (taken from a partially HLA-compatible family donor).

",1
Life Science,Bioremediation,"Bioremediation broadly refers to any process wherein a biological system (typically bacteria, microalgae, fungi, and plants), living or dead, is employed for removing environmental pollutants from air, water, soil, flue gasses, industrial effluents etc, in natural or artificial settings. The natural ability of organisms to adsorb, accumulate, and degrade common and emerging pollutants has attracted the use of biological resources in treatment of contaminated environment. In comparison to conventional physiochemical treatment methods which suffer serious drawbacks, bioremediation is sustainable, eco-friendly, cheap, and scalable.
Most bioremediation is inadvertent, involving native organisms. Research on bioremediation is heavily focused on stimulating the process by inoculation of a polluted site with organisms or supplying nutrients to promote the growth.  In principle, bioremediation could be used to reduce the impact of byproducts created from anthropogenic activities, such as industrialization and agricultural processes. Bioremediation could prove less expensive and more sustainable than other remediation alternatives.For organic pollutants, which are generally susceptible to biodegradation than heavy metals, bioremediation usually involves oxidations.  Oxidations enhance the water-solubility of organic compounds and their susceptibility to further degradation by oxidation and hydrolysis. Ultimately biodegradation convert hydrocarbons to carbon dioxide and water.  For heavy metals, bioremediation offers few solutions.  Metal containing can be removed or reduced with varying bioremediation techniques. The main challenge to bioremediations is rate: the processes are slow.Bioremediation techniques can be classified as (i) in situ techniques, which treats polluted sites directly, vs (ii) ex situ techniques which are applied to excavated materials. In both these approaches, additional nutrients, vitamins, minerals, and pH buffers are added to enhance the growth and metabolism of the microorganisms. In some cases, specialized microbial cultures are added (biostimulation). Some examples of bioremediation related technologies are phytoremediation, bioventing, bioattenuation, biosparging, composting (biopiles and windrows), and landfarming. Other remediation techniques include thermal desorption, vitrification, air stripping, bioleaching, rhizofiltration, and soil washing. Biological treatment, bioremediation, is a similar approach used to treat wastes including wastewater, industrial waste and solid waste. The end goal of bioremediation is to remove or reduce harmful compounds to improve soil and water quality.

",1
Life Science,Cultural hitchhiking,"Cultural hitchhiking is a hypothesized gene-culture coevolutionary process through which cultural selection, sexual selection based on cultural preference, limits the diversity at genetically neutral loci being transmitted in parallel to selective cultural traits. The process is thought to account for exceptionally low diversity in neutral loci such as control regions of the mitochondrial genome unaccounted for by any other selective forces. Simply put, selection for certain learned social and cultural behaviors can manifest in specific shaping of a population’s genetic makeup. While the notion that culture plays a significant role in shaping community genetics is widely accepted in the context of human populations it had not been considered or documented in non-human organisms until the late 1990s. The term was coined by the cetologist Hal Whitehead who studies the cultures and population genetics of matrilineal whale communities.
Cultural hitchhiking and has been proposed as a cause for reduced genetic diversity at certain loci in prehistoric  Homo sapiens, dolphins, killer whales, and sperm whales.Cultural hitchhiking is a significant hypothesis because it investigates the relationship between population genetics and culture. By understanding how social behavior can shape the genetic makeup of communities scientists are better able to explain why certain communities have genetic traits distinct from the larger population.",1
Life Science,Pyrosequencing,"Pyrosequencing is a method of DNA sequencing (determining the order of nucleotides in DNA) based on the ""sequencing by synthesis"" principle, in which the sequencing is performed by detecting the nucleotide incorporated by a DNA polymerase. Pyrosequencing relies on light detection based on a chain reaction when pyrophosphate is released. Hence, the name pyrosequencing.
The principle of pyrosequencing was first described in 1993 by, Bertil Pettersson, Mathias Uhlen and Pål Nyren by combining the solid phase sequencing method using streptavidin coated magnetic beads with recombinant DNA polymerase lacking 3´to 5´exonuclease activity (proof-reading) and luminescence detection using the firefly luciferase enzyme.  A mixture of three enzymes (DNA polymerase, ATP sulfurylase and firefly luciferase) and a nucleotide (dNTP) are added to single stranded DNA to be sequenced and the incorporation of nucleotide is followed by measuring the light emitted. The intensity of the light determines if 0, 1 or more nucleotides have been incorporated, thus showing how many complementary nucleotides are present on the template strand. The nucleotide mixture is removed before the next nucleotide mixture is added. This process is repeated with each of the four nucleotides until the DNA sequence of the single stranded template is determined.
A second solution-based method for pyrosequencing was described in 1998 by Mostafa Ronaghi, Mathias Uhlen and Pål Nyren. In this alternative method, an additional enzyme apyrase is introduced to remove nucleotides that are not incorporated by the DNA polymerase. This enabled the enzyme mixture including the DNA polymerase, the luciferase and the apyrase to be added at the start and kept throughout the procedure, thus providing a simple set-up suitable for automation. An automated instrument based on this principle was introduced to the market the following year by the company Pyrosequencing.
A third microfluidic variant of the pyrosequencing method was described in 2005 by Jonathan Rothberg and co-workers at the company 454 Life Sciences. This alternative approach for pyrosequencing was based on the original principle of attaching the DNA to be sequenced to a solid support and they showed that sequencing could be performed in a highly parallel manner using a microfabricated microarray. This allowed for high-throughput DNA sequencing and an automated instrument was introduced to the market. This became the first next generation sequencing instrument starting a new era in genomics research, with rapidly falling prices for DNA sequencing allowing whole genome sequencing at affordable prices.

",1
Life Science,Biotechnology industry in Italy,"Biotechnology industry in Italy is a highly innovative and fast-growing sector dedicated to research.
At the end of 2019, there are 696 biotech companies active in Italy.",1
Life Science,Chemical Engineering and Biotechnology Abstracts,"Chemical Engineering and Biotechnology Abstracts (CEABA-VTB) is an abstracting and indexing service that is published by DECHEMA, BASF, and Bayer Technology Services, all based in Germany. This is a bibliographic database that covers multiple disciplines.",1
Life Science,Rational design,"In chemical biology and biomolecular engineering, rational design (RD) is an umbrella term which invites the strategy of creating new molecules with a certain functionality, based upon the ability to predict how the molecule's structure (specifically derived from motifs) will affect its behavior through physical models.  This can be done either from scratch or by making calculated variations on a known structure, and usually complements directed evolution.",1
Life Science,Biostimulation,"Biostimulation involves the modification of the environment to stimulate existing bacteria capable of bioremediation.  This can be done by addition of various forms of rate limiting nutrients and electron acceptors, such as phosphorus, nitrogen, oxygen, or carbon (e.g. in the form of molasses).  Alternatively, remediation of halogenated contaminants in anaerobic environments may be stimulated by adding electron donors (organic substrates), thus allowing indigenous microorganisms to use the halogenated contaminants as electron acceptors. EPA Anaerobic Bioremediation Technologies Additives are usually added to the subsurface through injection wells, although injection well technology for biostimulation purposes is still emerging.  Removal of the contaminated material is also an option, albeit an expensive one.  Biostimulation can be enhanced by bioaugmentation.  This process, overall, is referred to as bioremediation and is an EPA-approved method for reversing the presence of oil or gas spills.  While biostimulation is usually associated with remediation of hydrocarbon or high production volume chemical spills, it is also potentially useful for treatment of less frequently encountered contaminant spills, such as pesticides, particularly herbicides.The primary advantage of biostimulation is that bioremediation will be undertaken by already present native microorganisms that are well-suited to the subsurface environment, and are well distributed spatially within the subsurface.  The primary disadvantage is that the delivery of additives in a manner that allows the additives to be readily available to subsurface microorganisms is based on the local geology of the subsurface.  Tight, impermeable subsurface lithology (tight clays or other fine-grained material) make it difficult to spread additives throughout the affected area.  Fractures in the subsurface create preferential pathways in the subsurface which additives preferentially follow, preventing even distribution of additives.
Recently a number of products have been introduced which allow popular use of bioremediation using biostimulative methods.  They may harness local bacteria using biostimulation by creating a hospitable environment for hydrocarbon-devouring microorganisms, or they may introduce foreign bacteria into the environment as a direct application to the hydrocarbon.  While the jury is out as to whether either is particularly more effective than the other, prima facie consideration suggests the introduction of foreign bacteria to any environment stands a chance of mutating organisms already present and affecting the biome.
Investigations to determine subsurface characteristics (such as natural groundwater velocity during ambient conditions, hydraulic conductivity of the subsurface, and lithology of the subsurface) are important in developing a successful biostimulation system.  In addition, a pilot-scale study of the potential biostimulation system should be undertaken prior to full-scale design and implementation.
However, some biostimulative agents may be used in chaotic surfaces such as open water and sand so long as they are [oleophilic], meaning that they bond exclusively to hydrocarbons, and basically sink in the water column, bonding to oil, where they then float to the water's surface, exposing the hydrocarbon to more abundant sunlight and oxygen where greater micro-organic aerobic activity can be encouraged.  Some consumer-targeted biostimulants bond possess this quality, others do not.",1
Life Science,Merodiploid,"A merodiploid is a partially diploid bacterium, which has its own chromosome complement and a chromosome fragment introduced by conjugation, transformation or transduction. It can also be defined as an essentially haploid organism that carries a second copy of a part of its genome. The term is derived from the Greek, meros = part, and was originally used to describe both unstable partial diploidy, such as that which occurs briefly in recipients after mating with an Hfr strain (1), and the stable state, exemplified by F-prime strains (see Hfr'S And F-Primes). Over time the usage has tended to confine the term to descriptions of stable genetic states. Merodiploidy refers to the partial duplication of chromosomes in a haploid organism.",1
Life Science,Integrated fluidic circuit,Integrated fluidic circuit (IFC) is a type of integrated circuit (IC) using fluids.,1
Life Science,Human genetic enhancement,"Human genetic enhancement or human genetic engineering refers to human enhancement by means of a genetic modification. This could be done in order to cure diseases (gene therapy), prevent the possibility of getting a particular disease (similarly to vaccines),  to improve athlete performance in sporting events (gene doping), or to change physical appearance, metabolism, and even improve physical capabilities and mental faculties such as memory and intelligence.
These genetic enhancements may or may not be done in such a way that the change is heritable (which has raised concerns within the scientific community).

",1
Life Science,Stercomata,"Stercomata (or stercomes) are extracellular pellets of waste material produced by some groups of foraminiferans, including xenophyophoreans and komokiaceans, Gromia, and testate amoebae. The pellets are ovoid (egg-shaped), brownish in color, and on average measure from 10-20 µm in length. Stercomata are composed of small mineral grains and undigested waste products held together by strands of glycosaminoglycans.The term “sterkome” was first used Schaudinn in 1899 to describe the balls of undigested food remains produced by the testate amoeba Trichosphaerium sieboldi, the foraminiferan Saccammina sphaerica, and the gromiid Gromia dujardinii. Schaudinn conducted feeding experiments on live individuals of Trichosphaerium sieboldi kept in culture dishes to confirm that stercomata were accumulations of waste material produced as a byproduct of feeding.

",1
Life Science,Primer dimer,"A primer dimer (PD) is a potential by-product in the polymerase chain reaction (PCR), a common biotechnological method. As its name implies, a PD consists of two primer molecules that have attached (hybridized) to each other because of strings of complementary bases in the primers. As a result, the DNA polymerase amplifies the PD, leading to competition for PCR reagents, thus potentially inhibiting amplification of the DNA sequence targeted for PCR amplification. In quantitative PCR, PDs may interfere with accurate quantification.

",1
Life Science,Polyphosphate-accumulating organisms,"Polyphosphate-accumulating organisms (PAOs) are a group of bacteria that, under certain conditions, facilitate the removal of large amounts of phosphorus from wastewater in a process, called enhanced biological phosphorus removal (EBPR). PAOs accomplish this removal of phosphate by accumulating it within their cells as polyphosphate.
PAOs are by no means the only bacteria that can accumulate polyphosphate within their cells and in fact, the production of polyphosphate is a widespread ability among bacteria.  However, the PAOs have many characteristics that other organisms that accumulate polyphosphate do not have, that make them amenable to use in wastewater treatment.  Specifically, this is the ability to consume simple carbon compounds (energy source) without the presence of an external electron acceptor (such as nitrate or oxygen) by generating energy from internally stored polyphosphate and glycogen.  Most other bacteria cannot consume under these conditions and therefore PAOs gain a selective advantage within the mixed microbial community present in the activated sludge. Therefore, wastewater treatment plants that operate for enhanced biological phosphorus removal have an anaerobic tank (where there is no nitrate or oxygen present as external electron acceptor) prior to the other tanks to give PAOs preferential access to the simple carbon compounds in the wastewater that is influent to the plant.
A PAO related to the Betaproteobacteria has been identified and named Candidatus Accumulibacter Phosphatis.  Accumulibacter has been shown to remove phosphorus from EBPR plants in Australia, Europe and the USA. It can consume a range of carbon compounds, such as acetate and propionate, under anaerobic conditions and store these compounds as polyhydroxyalkanoates (PHA) which it consumes as a carbon and energy source for growth using oxygen or nitrate as electron acceptor.
Recently, another PAO related to the Actinobacteria has been identified in wastewater treatment plants. These organisms appear to be limited to certain amino acids as carbon and energy source.  The storage compound that they use to store the amino acids that these organisms take up under anaerobic conditions has not been identified. These bacteria have been observed in some EBPR plants in Denmark (where they were discovered) but their wider distribution is unknown.",1
Life Science,Pegol,"Certolizumab pegol, sold under the brand name Cimzia, is a biologic medication for the treatment of Crohn's disease, rheumatoid arthritis, psoriatic arthritis and ankylosing spondylitis. It is a fragment of a monoclonal antibody specific to tumor necrosis factor alpha (TNF-α) and is manufactured by UCB.It is on the World Health Organization's List of Essential Medicines.",1
Life Science,Sotio,"SOTIO Biotech is a Czech biotechnology company focused on clinical-stage research and development of innovative medicines for cancer with operations in Europe, North America, and Asia. The company has clinical programs which include a superagonist of the immuno-oncology target IL-15, a new generation of potent and stable antibody-drug conjugates (ADCs), proprietary technology designed to improve on the efficacy of CAR T therapies and a platform to streamline and enhance personalized cell therapies.

",1
Life Science,Somatic embryogenesis,"Somatic embryogenesis is an artificial process in which a plant or embryo is derived from a single somatic cell. Somatic embryos are formed from plant cells that are not normally involved in the development of embryos, i.e. ordinary plant tissue. No endosperm or seed coat is formed around a somatic embryo.
Cells derived from competent source tissue are cultured to form an undifferentiated mass of cells called a callus. Plant growth regulators in the tissue culture medium can be manipulated to induce callus formation and subsequently changed to induce embryos to form the callus. The ratio of different plant growth regulators required to induce callus or embryo formation varies with the type of plant. Somatic embryos are mainly produced in vitro and for laboratory purposes, using either solid or liquid nutrient media which contain plant growth regulators (PGR’s). The main PGRs used are auxins but can contain cytokinin in a smaller amount. Shoots and roots are monopolar while somatic embryos are bipolar, allowing them to form a whole plant without culturing on multiple media types. Somatic embryogenesis has served as a model to understand the physiological and biochemical events that occur during plant developmental processes as well as a component to biotechnological advancement. The first documentation of somatic embryogenesis was by Steward et al. in 1958 and Reinert in 1959 with carrot cell suspension cultures.",1
Life Science,Suppression subtractive hybridization,"Subtractive hybridization is a technology that allows for PCR-based amplification of only cDNA fragments that differ between a control (driver) and experimental transcriptome. cDNA is produced from mRNA.  Differences in relative abundance of transcripts are highlighted, as are genetic differences between species.  The technique relies on the removal of dsDNA formed by hybridization between a control and test sample, thus eliminating cDNAs or gDNAs of similar abundance, and retaining differentially expressed, or variable in sequence, transcripts or genomic sequences.
Suppression subtractive hybridization has also been successfully used to identify strain- or species-specific DNA sequences in a variety of bacteria including Vibrio species (Metagenomics).",1
Life Science,Competitions and prizes in biotechnology,There exist a number of competitions and prizes to reward distinguished contributions and to encourage developments in biotechnology.,1
Life Science,Protein precipitation,"Protein precipitation is widely used in downstream processing of biological products in order to concentrate proteins and purify them from various contaminants. For example, in the biotechnology industry protein precipitation is used to eliminate contaminants commonly contained in blood. The underlying mechanism of precipitation is to alter the solvation potential of the solvent, more specifically, by lowering the solubility of the solute by addition of a reagent.

",1
Life Science,Body capacitance,"Body capacitance is the physical property of the human body that has it act as a capacitor. Like any other electrically-conductive object, a human body can store electric charge if insulated. The actual amount of capacitance varies with the surroundings; it would be low when standing on top of a pole with nothing nearby, but high when leaning against an insulated, but grounded large metal surface, such as a household refrigerator, or a metal wall in a factory.",1
Life Science,Tellurium ion resistance,The Tellurium Ion Resistance (TerC) Family (TC# 2.A.109) is part of the Lysine Exporter (LysE) Superfamily. A representative list of proteins belonging to the TerC family can be found in the Transporter Classification Database.,1
Life Science,Single-nucleotide polymorphism,"In genetics, a single-nucleotide polymorphism (SNP ; plural SNPs ) is a germline substitution of a single nucleotide at a specific position in the genome. Although certain definitions require the substitution to be present in a sufficiently large fraction of the population (e.g. 1% or more), many publications do not apply such a frequency threshold.
For example, at a specific base position in the human genome, the G nucleotide may appear in most individuals, but in a minority of individuals, the position is occupied by an A. This means that there is a SNP at this specific position, and the two possible nucleotide variations – G or A – are said to be the alleles for this specific position.SNPs pinpoint differences in our susceptibility to a wide range of diseases, for example age-related macular degeneration (a common SNP in the CFH gene is associated with increased risk of the disease) or nonalcoholic fatty liver disease (a SNP in the PNPLA3 gene is associated with increased risk of the disease). The severity of illness and the way the body responds to treatments are also manifestations of genetic variations caused by SNPs. For example, the APOE E4 allele that is determined by two common SNPs, rs429358 and rs7412, in the APOE gene is not only associated with increased risk for Alzheimer’s disease but also younger age at onset of the disease.A single-nucleotide variant (SNV) is a general term for single nucleotide change in DNA sequence. So a SNV can be a common SNP or a rare mutation, and can be germline or somatic and can be caused by cancer, but a SNP has to segregate in a species' population of organisms. SNVs also commonly arise in molecular diagnostics such as designing PCR primers to detect viruses, in which the viral RNA or DNA sample may contain SNVs.",1
Life Science,Phosphoproteomics,"Phosphoproteomics is a branch of proteomics that identifies, catalogs, and characterizes proteins containing a phosphate group as a posttranslational modification.  Phosphorylation is a key reversible modification that regulates protein function, subcellular localization, complex formation, degradation of proteins and therefore cell signaling networks.  With all of these modification results, it is estimated that between 30%–65% of all proteins may be phosphorylated, some multiple times. Based on statistical estimates from many datasets, 230,000, 156,000 and 40,000 phosphorylation sites should exist in human, mouse, and yeast, respectively.Compared to expression analysis, phosphoproteomics provides two additional layers of information.  First, it provides clues on what protein or pathway might be activated because a change in phosphorylation status almost always reflects a change in protein activity.  Second, it indicates what proteins might be potential drug targets as exemplified by the kinase inhibitor Gleevec.  While phosphoproteomics will greatly expand knowledge about the numbers and types of phosphoproteins, its greatest promise is the rapid analysis of entire phosphorylation based signalling networks.",1
Life Science,Synchronous coefficient of drag alteration,"Synchronous coefficient of drag alteration (SCODA) is a biotechnology method for purifying, separating and/or concentrating bio-molecules. SCODA has the ability to separate molecules whose mobility (or drag) can be altered in sync with a driving field. This technique has been primarily used for concentrating and purifying DNA, where DNA mobility changes with an applied electrophoretic field. Electrophoretic SCODA has also been demonstrated with RNA and proteins.",1
Life Science,NAIL-MS,"NAIL-MS (short for nucleic acid isotope labeling coupled mass spectrometry) is a technique based on mass spectrometry used for the investigation of nucleic acids and its modifications. It enables a variety of experiment designs to study the underlying mechanism of RNA biology in vivo. For example, the dynamic behaviour of nucleic acids in living cells, especially of RNA modifications, can be followed in more detail.",1
Life Science,Tokogeny,"Tokogeny or tocogeny is the biological relationship between parent and offspring, or more generally between ancestors and descendants.  In contradistinction to phylogeny it applies to individual organisms as opposed to species.
In the tokogentic system shared characteristics are called traits.",1
Business Administration,Disagree and commit,"Disagree and commit is a management principle which states that individuals are allowed to disagree while a decision is being made, but that once a decision has been made, everybody must commit to it. The principle can also be understood as a statement about when it is useful to have conflict and disagreement, with the principle saying disagreement is useful in early states of decision-making while harmful after a decision has been made. Disagree and commit is a method of avoiding the consensus trap, in which the lack of consensus leads to inaction.",0
Business Administration,Power structure,"In political sociology, but also operative within the rest of the animal kingdom, a power structure is a hierarchy of competence or aggression (might) predicated on influence between an individual and other entities in a group. A power structure focuses on the way power and authority is related between people within groups such as a government, nation, institution, organization, or a society. Such structures are of interest to various fields, including sociology, government, economics, and business. A power structure may be formal and intentionally constructed to maximize values like fairness or efficiency, as in a hierarchical organization wherein every entity, except one, is subordinate to a single other entity. Conversely, a power structure may be an informal set of roles, such as those found in a dominance hierarchy in which members of a social group interact, often aggressively, to create a ranking system. A culture that is organised in a dominance hierarchy is a dominator culture, the opposite of an egalitarian culture of partnership. A visible, dominant group or elite that holds power or authority within a power structure is often referred to as being the Establishment. Power structures are fluid, with changes occurring constantly, either slowly or rapidly, evolving or revolutionary, peacefully or violently.",0
Business Administration,Company code of conduct,"A code of conduct is a set of rules outlining the norms, rules, and responsibilities or proper practices of an individual party or an organization.",0
Business Administration,Supervision,"Supervision is an act or instance of directing, managing, or oversight.

",0
Business Administration,Peopleware,"Peopleware is a term used to refer to one of the three core aspects of computer technology, the other two being hardware and software. Peopleware can refer to anything that has to do with the role of people in the development or use of computer software and hardware systems, including such issues as developer productivity, teamwork, group dynamics, the psychology of programming, project management, organizational factors, human interface design, and human–machine interaction.",0
Business Administration,Target culture,"Target culture is a pejorative term used to refer to the perceived negative effects of rigid adherence to performance targets by businesses and organisations. The term is primarily used to refer to this kind of behaviour within the provision of public services in the United Kingdom. Target culture often stems from not being able to accurately measure a broad social good like health, education or crime prevention: instead, specific target like increasing the number of people passing an examination  or the number of arrests made by a police force is used.",0
Business Administration,OSTO System Model,"The OSTO System Model is based on the OSTO System Theory, which comprehends complex systems and organizations as living systems and maps these by means of the OSTO System Model. The model is cybernetic in nature and is deduced from the theory of closed loops. The basics of this theory have been formulated by David P. Hanna in the 1980s and have been published initially in 1988. The model assumes that several central transformation processes take place on the inside of a complex organization. These are deeply influenced by mutual reactions between the inner life of the organization and the outside (environment). In terms of closed loop theory, the OSTO System Model depicts the essential elements of such a living system in its interconnectedness, dependencies, and reciprocal reactions. Thinking in network structures is, thus, a crucial part of the OSTO System Theory.
The acronym “OSTO” stands for open, sociotechnical, economic (German: “oekonomisch”)  aspects of a system. With regard to organizations and economically working companies, the model takes into consideration the openness of systems towards their environments as well as the fact that they are multidimensional, socio-techno-economic structures. Taking into consideration these four aspects, the model displays the complexity of such a system in its numerous dimensions.",0
Business Administration,Incremental profit,"Incremental profit is the profit gain or loss associated with a given managerial decision. Total profit increases so long as incremental profit is positive. When incremental profit is negative, total profit declines. Similarly, incremental profit is positive (and total profit increases) if the incremental revenue associated with a decision exceeds the incremental cost. The incremental concept is so intuitively obvious that it is easy to overlook both its significance in managerial decision making and the potential for difficulty in correctly applying it.
For this reason, the incremental concept is sometimes violated in practice. For example, a firm may refuse to sublet excess warehouse space for $5000 per month because it figures its cost as $7500 per month -a price paid for a long-term lease on the facility. However, if the warehouse space represents excess capacity with no current value to the company, its historical cost of $7500 per month is irrelevant and should be disregarded. The firm would forego $5000 in profits by turning down the offer to sublet the excess warehouse space. Similarly, any firm that adds a standard allocated charge for fixed costs and overhead to the true incremental cost of production runs the risk of turning down profitable business.",0
Business Administration,Palladium International,"Palladium (also known as ""The Palladium Group"", ""Palladium Holdings"" or ""Palladium International"") is an international advisory and management company representing the combination of seven prior companies: GRM International, Futures Group, Palladium, the IDL Group, Development & Training Services, HK Logistics and CARANA Corporation. As of October 2016, Palladium employs over 2,500 persons operating in 90 countries. At the end of 2015, Palladium International was the fourth-largest private sector partner for the UK Government's Department for International Development (DFID). During 2011, Palladium International members Futures Group and Carana were USAID's fourteenth and sixteenth largest private sector partners, respectively. At the end of 2012, GRM International was the third largest private sector partner for AusAID.",0
Business Administration,Registered office,"A registered office is the official address of an incorporated company, association or any other legal entity. Generally it will form part of the public record and is required in most countries where the registered organization or legal entity is incorporated. A registered physical office address is required for incorporated organizations to receive official correspondence and formal notices from government departments, investors, banks, shareholders and the general public.: 209 

",0
Business Administration,Managerialism,"Managerialism involves belief in the value of professional managers and of the concepts and methods they use. Contemporary writers on management such as Thomas Diefenbach associate managerialism with hierarchy. But scholars have also linked managerialism to control,
to accountability
and measurement, and to an ideologically determined belief in the importance of tightly-managed organizations,
as opposed to individuals or to groups that do not resemble an organization.
Following Enteman's 1993 classic on Managerialism: The Emergence of a New Ideology,
American management experts Robert R. Locke and J. C. Spender see managerialism as an expression of a special group – management – that entrenches itself ruthlessly and systemically in an organization.  It deprives owners of decision-making power and workers of their ability to resist managerialism. In fact the rise of managerialism may in itself be a response to people's resistance in society and more specifically to workers' opposition against managerial regimes. Enteman (1993), Locke and Spender (2011) and Klikauer (2013) explain Managerialism in three different ways:

Building on Enteman (1993) and Locke/Spender (2011), Thomas Klikauer in “Managerialism – Critique of an Ideology” (2013) defined managerialism thus:  ""[....] Managerialism combines management knowledge and ideology to establish itself systemically in organisations and society while depriving owners, employees (organisational-economical) and civil society (social-political) of all decision-making powers. Managerialism justifies the application of managerial techniques to all areas of society on the grounds of superior ideology, expert training, and the exclusive possession of managerial knowledge necessary to efficiently run corporations and societies.""As the simpler yet already highly organised management of Henri Fayol (1841-1925) and Frederick Winslow Taylor (1856-1915) mutated into managerialism, managerialism became a full-fledged ideology under the following formula:Management + Ideology + Expansion = Managerialism [1]
Two examples of the extension of management into the non-management domain – the not for profit sphere of human existence – are public schools and universities. [2] In both cases, managerialism occurs when public institutions are run “as if” these were for-profit organization even though they remain government institutions funded through state taxes. In these cases, the term new public management has been used. [3] But the ideology of managerialism can even extend into more distant institutions such as, for example, a college of physicians.[4]
Albert A. Anderson summarized  managerialism as the ideological principle that sees societies as equivalent to the sum of the decisions and transactions made by the managements of organizations.Compare what the historian James Hoopes wrote (2003):

""[...] the main genesis of managerialism lay in the human relations movement that took root at the Harvard Business School in the 1920s and 1930s under the guiding hand of Professor Elton Mayo. Mayo, an immigrant from Australia, saw democracy as divisive and lacking in community spirit. He looked to corporate managers to restore the social harmony that he believed the uprooting experiences of immigration and industrialization had destroyed and that democracy was incapable of repairing.""",0
Business Administration,Halil Umut Meler,"Halil Umut Meler (born 1 August 1986) is a Turkish football referee. He has been FIFA listed since 2017 and a member of the UEFA Elite since 2022. He has officiated in 2017–18 UEFA Europa League, beginning with the match between Vojvodina and Ružomberok on 29 June 2017.",0
Business Administration,Japanese management culture,"Japanese management culture refers to working philosophies or methods in Japan. It included concepts and philosophies such as just in time, kaizen and total quality management.",0
Business Administration,Systel,"Systel, Inc. is a US-based multinational firm dealing in integrated technology and business services, mostly utilizing temporary H-1B visa workers. Headquartered in Alpharetta, its development centers are located in India and the United States. Systel is a certified minority business enterprise.

",0
Business Administration,Dynamic enterprise modeling,"Dynamic enterprise modeling (DEM) is an enterprise modeling approach developed by the Baan company, and used for the Baan enterprise resource planning system which aims ""to align and implement it in the organizational architecture of the end-using company"".According to Koning (2008), Baan introduced dynamic enterprise modelling in 1996 as a ""means for implementing the Baan ERP product. The modelling focused on a Petri net–based technique for business process modelling to which the Baan application units were to be linked. DEM also contains a supply-chain diagram tool for the logistic network of the company and of an enterprise function modelling diagram"".",0
Business Administration,Peopleware: Productive Projects and Teams,"Peopleware: Productive Projects and Teams is a 1987 book on the social side of software development, specifically managing project teams.  It was written by software consultants Tom DeMarco and Tim Lister, from their experience in the world of software development.  This book was revised in 2013.",0
Business Administration,F-Law,"An A-law algorithm is a standard companding algorithm, used in European 8-bit PCM digital communications systems to optimize, i.e. modify, the dynamic range of an analog signal for digitizing. It is one of two versions of the G.711 standard from ITU-T, the other version being the similar μ-law, used in North America and Japan.
For a given input 
  
    
      
        x
      
    
    {\displaystyle x}
  , the equation for A-law encoding is as follows,

where 
  
    
      
        A
      
    
    {\displaystyle A}
   is the compression parameter. In Europe, 
  
    
      
        A
        =
        87.6
      
    
    {\displaystyle A=87.6}
  .
A-law expansion is given by the inverse function,

The reason for this encoding is that the wide dynamic range of speech does not lend itself well to efficient linear digital encoding. A-law encoding effectively reduces the dynamic range of the signal, thereby increasing the coding efficiency and resulting in a signal-to-distortion ratio that is superior to that obtained by linear encoding for a given number of bits.

",0
Business Administration,Empowerment,"Empowerment is the degree of autonomy and self-determination in people and in communities. This enables them to represent their interests in a responsible and self-determined way, acting on their own authority. It is the process of becoming stronger and more confident, especially in controlling one's life and claiming one's rights. Empowerment as action refers both to the process of self-empowerment and to professional support of people, which enables them to overcome their sense of powerlessness and lack of influence, and to recognize and use their resources.
As a term, empowerment originates from American community psychology and is associated with the social scientist Julian Rappaport (1981). However, the roots of empowerment theory extend further into history and are linked to Marxist sociological theory. These sociological ideas have continued to be developed and refined through Neo-Marxist Theory (also known as Critical Theory).In social work, empowerment forms a practical approach of resource-oriented intervention. In the field of citizenship education and democratic education, empowerment is seen as a tool to increase the responsibility of the citizen. Empowerment is a key concept in the discourse on promoting civic engagement. Empowerment as a concept, which is characterized by a move away from a deficit-oriented towards a more strength-oriented perception, can increasingly be found in management concepts, as well as in the areas of continuing education and self-help.",0
Business Administration,Power to the edge,"Power to the edge refers to the ability of an organization to dynamically synchronize its actions; achieve command and control (C2) agility; and increase the speed of command over a robust, networked grid. The term is most commonly used in relation to military organizations, but it can equally be used in a civilian context.
""Power to the edge"" is an information and organization management philosophy first articulated by the U.S. Department of Defense in a publication by Dr. David S. Alberts and Richard E. Hayes in 2003 titled: ""Power to the Edge: Command...Control...in the Information Age."" This book was published by the Command and Control Research Program and can be downloaded from the Program's website.",0
Business Administration,Scaling of innovations,"Scaling of innovations is a process that leads to widespread use of an innovation. It is regarded the last step after the discovery, proof of concept and piloting of an innovation. In business it is often used as maximizing operational scale of the product. This technology, or project-focused scaling takes products and services as the point of departure and wants to see those to go scale. In the public sector, and for example in development aid, the desired impact is the point of departure and whatever leads to more impact is scaled (usually in the form of a range of innovations). However, some authors recognize that the public sector often uses the business way of scaling to reach impact, leading to disillusionment and doing more harm than good. Sometimes, scaling is seen as a process towards sustainable systems change at scale, where sustainability, systems change and responsible scaling are just as important as “reaching many”.",0
Business Administration,Machiavellianism in the workplace,"Machiavellianism in the workplace is a concept studied by many organizational psychologists. Conceptualized originally by Richard Christie and Florence Geis, Machiavellianism refers to a psychological trait concept where individuals behave in a cold and duplicitous manner. It has in recent times been adapted and applied to the context of the workplace and organizations by many writers and academics. 
Oliver James wrote on the effects of Machiavellianism and other dark triad personality traits in the workplace, the others being narcissism and psychopathy.A new model of Machiavellianism based in organizational settings consists of three factors:
maintaining power
harsh management tactics
manipulative behaviors.Examples of what Machiavellianism could look like in the workplace:
Theft (tangible or intangible)
Lying/Deceit
Sabotage
Cheating (passive or active)High Machs can exhibit high levels of charisma, and their leadership can be beneficial in some areas.The presence of Machiavellianism in an organization has been positively correlated with counterproductive workplace behaviour and workplace deviance.The origin of Machiavellianism entering the workplace can be tied to multiple factors, such as distrust towards others, pessimism, survival/self-protection tactics, or even the gender of involved parties.

",0
Business Administration,Hot desking,"Hot desking (sometimes called ""non-reservation-based hoteling"") is an office organization system that involves multiple workers using a single physical work station or surface during different time periods. The ""desk"" in the name refers to a table or other work space being shared by multiple workers on different shifts as opposed to every staff member having their own personal desk. A primary motivation for hot-desking is cost reduction through space savings—up to 30% in some cases. Hot desking is especially valuable in cities where real estate prices are high.",0
Business Administration,Edmund Hillary Fellowship,"The Edmund Hillary Fellowship is a Fellowship programme in New Zealand and community that provides exceptional entrepreneurs, investors and startup teams with a platform to incubate global impact ventures. The idea behind the Fellowship was to bring foreign entrepreneurs and investors to New Zealand to incubate new businesses. The Immigration New Zealand partnered with the Edmund Hillary Fellowship to deliver Global Impact Visa to 400 international applications over four years. It was setup in 2016 and has 532 fellows (400 international and 132 kiwis) as of March 2022.Immigration New Zealand will partner with the Edmund Hillary Fellowship to bring innovation-based ventures to New Zealand, announced Immigration Minister Michael Woodhouse.
Yoseph Ayele is one of the co-founders of the Edmund Hillary Fellowship and was the first CEO as well. Anna Kominik serves as their Board Chair.
Famous fellows of this Fellowship include Naval Ravikant, Deepa Malik, Amitabh Kant, Shay Wright, Tashi and Nungshi Malik, Kunal Kapur  and many more.",0
Business Administration,Managing up and managing down,"Managing Up and Managing Down is a part of management that details how middle managers or supervisors should effectively deal with their managers and subordinates. Promotion to management comes with additional responsibility of managing down. With the additional responsibility for managing their team while remaining accountable to their management teams, managers require additional skills and training to effectively influence up or down. Management levels within large organizations are structured from a hierarchal organization and include senior, middle, and lower management roles..",0
Business Administration,Research report,"A research report is a publication that reports on the findings of a research project or alternatively scientific observations on or about a subject.
Research reports are produced by many sectors including industry, education, government and non-government organizations and may be disseminated internally, or made public (i.e. published) however they are not usually available from booksellers or through standard commercial publishing channels. Research reports are also issued by governmental and international organizations, such as UNESCO.
There are various distribution models for research reports with the main ones being: public distribution for free or open access; limited distribution to clients and customers; or sold commercially. For example market research reports are often produced for sale by specialist market research companies, investment companies may provide research reports to clients while government agencies and civil society organizations such as UNESCO, the World Health Organization and many others often provide free access to organization research reports in the public interest or for a range of organization requirements and objectives.",0
Business Administration,Professional services,"Professional services are occupations in the service sector requiring special training in the arts or sciences. Some professional services, such as architects, accountants, engineers, doctors, lawyers, and teachers, require the practitioner to hold professional degrees or licenses and possess specific skills. Other professional services involve providing specialist business support to businesses of all sizes and in all sectors; this can include tax advice, supporting a company with accounting, IT services, Public Relations services or providing management advice.

",0
Business Administration,Communities of innovation,"Communities that support innovation have been referred to as communities of innovation (CoI), communities for innovation, innovation communities, open innovation communities, and communities of creation.

",0
Business Administration,Completed staff work,"Completed staff work is a principle of management which states that subordinates are responsible for submitting written recommendations to superiors in such a manner that the superior need do nothing further in the process than review the submitted document and indicate approval or disapproval.
In Completed Staff Work, the subordinate is responsible for identifying the problem or issue requiring decision by some higher authority. In written form such as a memorandum, the subordinate documents the research done, the facts gathered, and analysis made of alternative courses of action. The memo concludes with a specific recommendation for action by the superior.
The earliest description of the concept of Completed Staff Work appears in U.S. Army publications. Since its early military origin, it has subsequently found favor in police management texts in the U.S.James Webb, Director of the Bureau of the Budget (1946-1949), attributes the Doctrine of Completed Staff Work to President Harry S. Truman. 
However, a memo written and circulated by Briagadier General George A. Rehm, executive officer for the G-3, Operations section, attributes the policy to General MacArthur's headquarters in the Southwest Pacific Areas during World War II.",0
Business Administration,Corporate governance,"Corporate governance is defined, described or delineated in diverse ways, depending on the writer's purpose. Writers focussed on a disciplinary interest or context (such as accounting, finance, law, or management) often adopt narrow definitions that appear purpose-specific. Writers concerned with regulatory policy in relation to corporate governance practices often use broader structural descriptions. A broad (meta) definition that encompasses many adopted definitions is '“Corporate governance” describes the processes, structures, and mechanisms that influence the control and direction of corporations'.
This meta definition accommodates both the narrow definitions used in specific contexts and the broader descriptions that are often presented as authoritative. The latter include: the structural definition from the Cadbury Report, which identifies corporate governance as 'the system by which companies are directed and controlled' (Cadbury 1992, p. 15); and the relational-structural view adopted by the Organization for Economic Cooperation and Development (OECD) of 'Corporate governance involves a set of relationships between a company's management, its board, its shareholders and other stakeholders. Corporate governance also provides the structure through which the objectives of the company are set, and the means of attaining those objectives and monitoring performance are determined' (OECD 2015, p.9). .",0
Business Administration,MECE principle,"The MECE principle, (mutually exclusive and collectively exhaustive) pronounced by many as ""ME-see"", and pronounced by the author as ""Meese"" like Greece or niece, is a grouping principle for separating a set of items into subsets that are mutually exclusive (ME) and collectively exhaustive (CE). It was developed in the late 1960s by Barbara Minto at McKinsey & Company and underlies her Minto Pyramid Principle, and while she takes credit for MECE, according to her interview with McKinsey, she says the idea for MECE goes back as far as to Aristotle.The MECE principle has been used in the business mapping process wherein the optimum arrangement of information is exhaustive and does not double count at any level of the hierarchy. Examples of MECE arrangements include categorizing people by year of birth (assuming all years are known), apartments by their building number, letters by postmark, and dice rolls. A non-MECE example would be categorization by nationality, because nationalities are neither mutually exclusive (some people have dual nationality) nor collectively exhaustive (some people have none).

",0
Business Administration,Indian Ethos in Management,"Indian Ethos in Management refers to the values and practices that the culture of India (Bharatheeya Sanskriti) can contribute to service, leadership and management. These values and practices are rooted in Sanathana Dharma (the eternal essence), and have been influenced by various strands of Indian philosophy.",0
Business Administration,Likert's management systems,"Likert's management systems are management styles developed by Rensis Likert in the 1960s. He outlined four systems of management to describe the relationship, involvement, and roles of managers and subordinates in industrial settings. He based the systems on studies of highly productive supervisors and their team members of an American Insurance Company. Later, he and Jane G. Likert revised the systems to apply to educational settings. They initially intended to spell out the roles of principals, students, and teachers; eventually others such as superintendents, administrators, and parents were included. The management systems, established by Likert, include ""Exploitative Authoritative (System I), Benevolent Authoritative (System II), Consultative (System III), and Participative (System IV).""",0
Business Administration,Abilene paradox,"In the Abilene paradox, a group of people collectively decide on a course of action that is counter to the preferences of many or all of the individuals in the group. It involves a common breakdown of group communication in which each member mistakenly believes that their own preferences are counter to the group's and, therefore, does not raise objections, or even states support for an outcome they do not want. A common phrase relating to the Abilene paradox is a desire to not ""rock the boat"". This differs from groupthink in that the Abilene paradox is characterized by an inability to manage agreement.

",0
Business Administration,Office administration,"Office administration (shortened as Office Ad and abbreviated as OA) is a set of day-to-day activities that are related to the maintenance of an office building, financial planning, record keeping and billing, personal development, physical distribution and logistics, within an organization. An employee that undertakes these activities is commonly called an office administrator or office manager, and plays a key role in any organization's infrastructure, regardless of the scale. Many administrative positions require the candidate to have an advanced skill set in the software applications Microsoft Word, Excel and Access.

",0
Business Administration,Social work management,"Social work management is the management of organisations or enterprises in the social economy and non-profit sector, e.g., public service providers, charities, youth welfare offices, associations, etc. 
Social work management has been traditionally pursued by social workers, social pedagogues, pedagogues, psychologists without additional management skills and knowledge or legal practitioners and business economists – often without reference to the social economy.
Most scholars and practitioners agree that social work managers need to have a high degree of leadership skills to make considered managerial decisions, to empower social workers, to develop staff within and collaborate with partners outside the social and human service organisation. Social work management as a field of social work education and practice was established in many universities in Europe and North America  since the 1980s. Established qualifications in higher education first included diplomas in social economy. It originally focused on person-centred leadership, motivation and strategic issues. It combines management with social pedagogical, psychological, and sociological knowledge and skills.",0
Business Administration,Core business,"The core business of an organization is an idealized construct intended to express that organization's ""main"" or ""essential"" activity.
Core business process means that a business's success depends not only on how well each department performs its work, but also on how well the company manages to coordinate departmental activities to conduct the core business process, which is;
1. The market-sensing process
Meaning all activities in gathering marketing intelligence and acting on the information.
2. The new-offering realization process
Covering all activities in research, development and launching new quality offerings quickly and within budget.
3. The customer acquisition process
all the activities defining the target market and prospecting for new customers
4. The customer relationship management process
all the activities covering building deeper understanding, relationships and offerings to individual customers.
5. The fulfillment management process
all the activities in receiving and approving orders, shipping out on time and collecting payment.
In business, a core item is defined as an item that is immediately responsible for the revenues and cash flows of that particular business, whereas a non-core item is of a more strategic view, intended to benefit the revenue model and cash flows of the core items.Therefor, the easiest way to identify a core business function is to look at whether the primary cash flows of the business revenue model runs directly through it, or not. Core business functions are always directly involved in the primary cash flows of the revenue model or models of the business, whereas non-core business functions usually are not, meaning that the business can technically operate without non-core business functions without impacting the primary cash flows, whereas the core business functions are essential to the continuance of its primary cash flows.
To be successful, a business needs to look for competitive advantages beyond its own operations. The business needs to look at the competitiveness value chain of suppliers, distributors and customers. Many companies today have partnered with specific suppliers and distributors to create a superior value delivery network.

",0
Business Administration,Diagnostic Enterprise Method,"The diagnostic enterprise method is a management theory whose methods were created based on Frederick Winslow Taylor's principles to develop new ways in which companies can change their internal structure without outside help. Some of the techniques bring the managers the advantage to find opportunity areas in the company to correct them without affecting the enterprise development. This methods can be applied without big costs in money, time and training. This method can be applied to almost any enterprise.",0
Business Administration,Micromanagement,"In business management, micromanagement is a management style whereby a manager closely observes and/or controls and/or reminds the work of their subordinates or employees.
Micromanagement is generally considered to have a negative connotation, mainly because it shows a lack of freedom and trust in the workplace.

",0
Business Administration,Business workflow analysis,"Business Workflow Analysis (BWA), aka Business management systems p2p, is a management tool that streamlines, automates and improves the efficiency of business procedures.",0
Business Administration,Mushroom management,"Mushroom management is the management of a company where the communication channels between the managers and the employees do not work effectively, and where employees are 'kept in the dark' by management in regards to business decisions that affect their work and employment. The term 'mushroom management' alludes to the stereotypical (and somewhat inaccurate) view of mushroom cultivation: kept in the dark and fed bullshit.

",0
Business Administration,Integrated Management Concept,"The Integrated Management Concept, or IMC is an approach to structure management challenges by applying a ""system-theoretical perspective that sees organisations as complex systems consisting of sub-systems, interrelations, and functions"".  The most characteristic aspect of the IMC is its distinction between three particular management dimensions: normative, strategic, and operational management, which are held together by different integration mechanisms.  The normative management dimension determines the general aim of the organization, the strategic dimension directs the plans, basic structures, systems, and the problem-solving behaviour of the staff for achieving it, and the operative level translates the normative missions and strategic programs into day-to-day organizational processes. 
The IMC was developed by Knut Bleicher and his colleagues originally as an element of the St. Gallen Management Model, introduced in the 1970s by Hans Ulrich and Walter Krieg at the Swiss University of St. Gallen. Thereafter, the IMC has been revised several times (e.g. with respect to its application within SMEs sectors ) and further developed by research institutions and management scholars, such as Johannes Rüegg-Stürm.",0
Business Administration,Lean thinking,"Lean thinking is a transformational framework that aims to provide a new way to think about how to organize human activities to deliver more benefits to society and value to individuals while eliminating waste. The term “lean thinking” was coined by James P. Womack and Daniel T. Jones to capture the essence of their in-depth study of Toyota's fabled Toyota Production System. Lean thinking is a way of thinking about an activity and seeing the waste inadvertently generated by the way the process is organized. It uses the concepts of:

Value
Value streams
Flow
Pull
PerfectionThe aim of lean thinking is to create a lean culture, one that sustains growth by aligning customer satisfaction with employee satisfaction, and that offers innovative products or services profitably while minimizing unnecessary over-costs to customers, suppliers and the environment. The basic insight of lean thinking is that if you train every person to identify wasted time and effort in their own job and to better work together to improve processes by eliminating such waste, the resulting culture (basic thinking, mindset & assumptions) will deliver more value at less expense while developing every employee's confidence, competence and ability to work with others.
The idea of lean thinking gained popularity in the business world and has evolved in three different directions:

Lean thinking converts who keep seeking to understand how to seek dynamic gains rather than static efficiencies. For this group of thinkers, lean thinking continuously evolves as they seek to better understand the possibilities of the way opened up by Toyota and have grasped the fact that the aim of continuous improvement is continuous improvement. Lean thinking as such is a movement of practitioners and writers who experiment and learn in different industries and conditions, to lean think any new activity.
Lean production adepts who have interpreted the term “lean” as a form of operational excellence and have turned to company programs aimed at taking costs out of processes. Lean activities are used to improve processes without ever challenging the underlying thinking, with powerful low-hanging fruit results but little hope of transforming the enterprise as a whole. This “corporate lean” approach is fundamentally opposed to the ideals of lean thinking, but has been taken up by a great number of large businesses seeking to cut their costs without challenging their fundamental management assumptions.
Lean Services,  as an extent area of application to all the learnings gathered from the industry and adapted to a whole new set of scenarios, such as HR, Accounting,  Retail,  Health,  Education, Product Development, Startup/ Entrepreneurship, Digital... among so many other areas. Lean basic principles can be applied basically to all scopes of action,  disregarding its geography and culture.

",0
Business Administration,Technostructure,"Technostructure is the group of technicians, analysts within an organisation (enterprise, administrative body) with considerable influence and control on its economy. The term was coined by the economist John Kenneth Galbraith in The New Industrial State (1967). It usually refers to managerial capitalism where the managers and other company leading administrators, scientists, or lawyers retain more power and influence than the shareholders in the decisional and directional process.",0
Business Administration,Kiss up kick down,"Kiss up kick down (or suck up kick down) is a neologism used to describe the situation where middle-level employees in an organization are polite and flattering to superiors but abusive to subordinates. The term is believed to have originated in the US, with the first documented use having occurred in 1993. A similar expression (lit. ""lick up, kick down"") was used by Swedish punk band Ebba Grön in one of their songs, on an album released in 1981. The concept can be applied to any social interaction where one person believes they have power over another person and believes that another person has power over them.

",0
Business Administration,Business,"Business is the activity of making one's living or making money by producing or buying and selling products (such as goods and services). It is also ""any activity or enterprise entered into for profit.""Having a business name does not separate the business entity from the owner, which means that the owner of the business is responsible and liable for debts incurred by the business.  If the business acquires debts, the creditors can go after the owner's personal possessions.  A business structure does not allow for corporate tax rates. The proprietor is personally taxed on all income from the business.
The term is also often used colloquially (but not by lawyers or by public officials) to refer to a company. A company, on the other hand, is a separate legal entity and provides for limited liability, as well as corporate tax rates.  A company structure is more complicated and expensive to set up, but offers more protection and benefits for the owner.",0
Business Administration,Theory of the firm,"The theory of Forms or theory of Ideas is a philosophical theory, concept, or world-view, attributed to Plato, that the physical world is not as real or true as timeless, absolute, unchangeable ideas. According to this theory, ideas in this sense, often capitalized and translated as ""Ideas"" or ""Forms"", are the non-physical essences of all things, of which objects and matter in the physical world are merely imitations. Plato speaks of these entities only through the characters (primarily Socrates) of his dialogues who sometimes suggests that these Forms are the only objects of study that can provide knowledge. The theory itself is contested from within Plato's dialogues, and it is a general point of controversy in philosophy.  Nonetheless, the theory is considered to be a classical solution to the problem of universals.The early Greek concept of form precedes attested philosophical usage and is represented by a number of words mainly having to do with vision, sight, and appearance. Plato uses these aspects of sight and appearance from the early Greek concept of the form in his dialogues to explain the Forms and the Good.",0
Business Administration,Steuerberater,"Steuerberater (StB) is the professional license for tax advisors in Germany.The provision of tax advisory services is restricted and basically permissible for Steuerberater, Rechtsanwälte (attorneys-at-law) and Wirtschaftsprüfer (certified public accountants) only according to German law. In order to obtain this qualification, an individual must pass the Steuerberaterprüfung, a special uniform nationwide state examination. Merely being qualified as an attorney at law is not sufficient. Individuals may hold several of the aforementioned qualifications at the same time, e.g. be dual qualified and licensed as Rechtsanwalt (attorney-at-law) and Steuerberater (licensed tax advisor) at the same time. 
A similar license exists in Austria and Switzerland.

",0
Business Administration,Association of Consulting Engineers New Zealand,"The Association of Consulting Engineers New Zealand (ACENZ) is New Zealand's main business association representing engineers providing consultancy services in a wide range of disciplines. It was founded in 1959 as the consulting division of IPENZ, though it has been a separate entity since 1970.It has 176 corporate members with a total of around 8,500 staff (2007 data), up from about 5,800 in 2001.Apart from its functions as a representative of the interests of its member companies, it annually judges engineering awards for the most innovative and exceptional engineering projects of New Zealand.",0
Business Administration,Chemonics,"Chemonics International, Inc. is a private international development firm based in Washington, D.C. It was established in 1975 by Thurston F. (Tony) Teele as a subsidiary of Erly Industries. The employee-owned company offers a variety of services globally and with more than $1.5 billion in USAID contracts in 2019 is the largest for-profit recipient of U.S. government foreign aid. As of 2019 the company has approximately 5,000 employees in 100 countries.

",0
Business Administration,Foresight (psychology),"Foresight is the ability to predict, or the action of predicting, what will happen or what is needed in the future. Studies suggest that much of human daily thought is directed towards potential future events. Because of this and its role in human control on the planet, the nature and evolution of foresight is an important topic in psychology.  Thinking about the future is also studied under the label prospection. Recent neuroscientific, developmental, and cognitive studies have identified many commonalities to the human ability to recall past episodes. Science magazine selected new evidence for such commonalities one of the top ten scientific breakthroughs of 2007. However, there are fundamental differences between mentally travelling through time into the future (i.e., foresight) versus mentally travelling through time into the past (i.e., episodic memory).

",0
Business Administration,List of university statistical consulting centers,This list of university statistical consulting centers (or centres)  is a simple list of universities in which there is a specifically designated team providing statistical consultancy services. Often this service will be available only to enquirers from within the same university.,0
Business Administration,Activity management,"Project management is the process of leading the work of a team to achieve all project goals within the given constraints. This information is usually described in project documentation, created at the beginning of the development process. The primary constraints are scope, time, and budget. The secondary challenge is to optimize the allocation of necessary inputs and apply them to meet pre-defined objectives.
The objective of project management is to produce a complete project which complies with the client's objectives. In many cases, the objective of project management is also to shape or reform the client's brief to feasibly address the client's objectives. Once the client's objectives are clearly established they should influence all decisions made by other people involved in the project – for example, project managers, designers, contractors, and sub-contractors. Ill-defined or too tightly prescribed project management objectives are detrimental to decision making.
A project is a temporary and unique endeavor designed to produce a product, service, or result with a defined beginning and end (usually time-constrained, and often constrained by funding or staffing) undertaken to meet unique goals and objectives, typically to bring about beneficial change or added value.  The temporary nature of projects stands in contrast with business as usual (or operations), which are repetitive, permanent, or semi-permanent functional activities to produce products or services. In practice, the management of such distinct production approaches requires the development of distinct technical skills and management strategies.",0
Business Administration,Administrative assistant,A person responsible for providing various kinds of administrative assistance is called an administrative assistant (admin assistant) or sometimes an administrative support specialist.,0
Business Administration,Information Control Company,"g2o, formerly Information Control Company (ICC), formerly Information Control Corporation, is headquartered in Columbus, Ohio, United States. It is the largest Ohio-owned digital experience and technology consulting company.The company employs more than 500 analysts, designers, developers, system and data engineers, researchers, and strategists.
Their client list includes financial institutions, health care organizations, government agencies, insurance companies, retailers, and educators.",0
Business Administration,Action item,"In management, an action item is a documented event, task, activity, or action that needs to take place. Action items are discrete units that can be handled by a single person.

",0
Business Administration,Magang Constitution,"The Magang Constitution (simplified Chinese: 马钢宪法; traditional Chinese: 馬鋼憲法; pinyin: Mǎ gāng xiànfǎ), also known as Ma-steel Constitution, was a set of enterprise management system that was gradually formed in the Former Soviet Union in the 1950s and 1960s after decades of socialist industrial construction and development. Nowadays, it has been abandoned.
It is worth noting that ""Magang Constitution"" is a vivid metaphor, it is not really a constitution in the true sense of the term (like China's ""Angang Constitution"").  It is a complete set of rules and regulations for factory management, even rising to the height of the law.Magang Constitution is not the fundamental law of the FSU, nor the most basic law of the country. In addition, the name ""Magang Constitution"" was not named by the Soviets, but by the Chinese.",0
Business Administration,Hoteling,"Hoteling (also hotelling or office hoteling) is a method of office management in which workers dynamically schedule their use of workspaces such as desks, cubicles, and offices. It is an alternative approach to the more traditional method of permanently assigned seating. Hoteling is reservation-based unassigned seating; employees reserve a workspace before they come to work in an office. An alternate method of handling unassigned seating is hot desking, which does not involve reservations; with hot-desking, a worker chooses a workspace upon arrival, rather than reserving it in advance. The use of the term has declined in recent years.
With hoteling, workers are not assigned their own desks; instead, they reserve a desk for their temporary use for just the days they expect to work in the office. The benefits of hoteling over a more traditional, one-desk-per-employee scenario include saving costs on commercial real estate, as well as creating opportunities for staff to mingle and collaborate more.The practice of hoteling has resulted from increased worker mobility, enabled by advances in mobile technology. Organizations whose workers travel frequently, or with growing remote or mobile workforces, are best suited to hoteling. A Washington Post article cites the rising use of hoteling as reflecting a shift from the office being a ""home base"" to being a ""hospitality hub.""Companies started implementing hoteling in the 1990s, with consulting and accounting firms among the early adopters.",0
Business Administration,Cognitive inertia,"Cognitive inertia is the tendency for a particular orientation in how an individual thinks about an issue, belief or strategy to resist change. In clinical and neuroscientific literature it is often defined as a lack of motivation to generate distinct cognitive processes needed to attend to a problem or issue. The physics term inertia is to emphasize the rigidity and resistance to change in the method of cognitive processing that has been in use for a significant amount of time. Commonly confused with belief perseverance, cognitive inertia is the perseverance of how one interprets information, not the perseverance of the belief itself.
Cognitive inertia has been causally implicated in disregard of impending threat to one's health or environment, enduring political values and deficits in task switching. Interest in the phenomenon was largely taken up by economic and industrial psychologists to explain resistance to change in brand loyalty, group brainstorming and business strategies. In the clinical setting cognitive inertia has been used as a diagnostic tool for neurodegenerative diseases, depression and anxiety. Critics have stated that the term oversimplifies resistant thought processes and suggest a more integrative approach that involves motivation, emotion and developmental factors.",0
Business Administration,Ramapati Singhania,"Ramapati Singhania was born on May 8, 1956 to Gopal Krishna Singhania and Sulochana Devi of the Singhania family. He is the grandson of Sir Padampat Singhania who was knighted in the 1943 Honours list. He is an entrepreneur and author.Ramapati Singhania acquired his MBA from the University of Virginia in 1981. He is an alumnus of the Darden School of Business. He completed his BS in Electrical Engineering from Carnegie Mellon, Pennsylvania (USA).
He held the position of full time Director of JK Synthetics Ltd and Director of JK Bombay Ltd.Other companies he held crucial positions include:

JayKay Tech Ltd
Keventer Agro Ltd
JK Jute Mills.He contributed to promoting the Quality Circle Forum of India. He was president of the Employers Association, Rajasthan and the National Institute of Quality and Reliability. He was an instructor at the Search Engine Academy, UAE.Presently, Ramapati Singhania is the Managing Director of Varal Consultancy DMCC, Dubai (UAE).",0
Business Administration,Management buyout,"A management buyout (MBO) is a form of acquisition in which a company's existing managers acquire a large part, or all, of the company, whether from a parent company or non-artificial person(s). Management-, and/or leveraged buyout  became noted phenomena of 1980s business economics. These so-called MBOs originated in the US, spreading first to the UK and then throughout the rest of Europe. The venture capital industry has played a crucial role in the development of buyouts in Europe, especially in smaller deals in the UK, the Netherlands, and France.",0
Business Administration,Feedforward (management),"Feed forward in  management theory is an application of the cybernetic concept of feedforward first articulated by I. A. Richards in 1951. It reflects the impact of Management cybernetics in the general area of management studies.
It refers to the practice of giving a control impact in a downlink to a subordinate to a person or an organization from which you are expecting an output. A feed forward is not just a pre-feedback, as a feedback is always based on measuring an output and sending respective feedback. A pre-feedback given without measurement of output may be understood as a confirmation or just an acknowledgment of control command.
However, a feed forward is generally imposed before any willful change in output may occur. All other changes of output determined with feedback may for example result from distortion, noise or attenuation. It usually involves giving a document for review and giving an ex post information on that document which you have not already given.
However, social feedback is the response of the supreme hierarch to the subordinate as an acknowledgement of a subordinate's report on output, hence the subordinate's feedback to the supreme.",0
Business Administration,Dynamic capabilities,"In organizational theory, dynamic capability is the capability of an organization to purposefully adapt an organization's resource base. The concept was defined by David Teece, Gary Pisano and Amy Shuen, in their 1997 paper Dynamic Capabilities and Strategic Management, as ""the firm’s ability to integrate, build, and reconfigure internal and external competences to address rapidly changing environments"".The term is often used in the plural form, dynamic capabilities, emphasizing that the ability to react adequately and timely to external changes requires a combination of multiple capabilities.

",0
Business Administration,Management,"Management (or managing) is the administration of an organization, whether it is a business, a non-profit organization, or a government body. It is the art and science of managing resources of the business. 
Management includes the activities of setting the strategy of an organization and coordinating the efforts of its employees (or of volunteers) to accomplish its objectives through the application of available resources, such as financial, natural, technological, and human resources. ""Run the business"" and ""Change the business"" are two concepts that are used in management to differentiate between the continued delivery of goods or services and adapting of goods or services to meet the changing needs of customers - see trend. The term ""management"" may also refer to those people who manage an organization—managers. 
Some people study management at colleges or universities; major degrees in management includes the Bachelor of Commerce (B.Com.), Bachelor of Business Administration (BBA.), Master of Business Administration (MBA.), Master in Management (MSM or MIM) and, for the public sector, the Master of Public Administration (MPA) degree. Individuals who aim to become management specialists or experts, management researchers, or professors may complete the Doctor of Management (DM), the Doctor of Business Administration (DBA), or the Ph.D. in Business Administration or Management. In the past few decades, there has been a movement for evidence-based management.Larger organizations generally have three hierarchical levels of managers, in a pyramid structure:

Senior managers such as members of a board of directors and a chief executive officer (CEO) or a president of an organization sets the strategic goals of the organization and make decisions on how the overall organization will operate. Senior managers are generally executive-level professionals who provide direction to middle management, and directly or indirectly report to them.
Middle managers such as branch managers, regional managers, department managers, and section managers, who provide direction to the front-line managers. They communicate the strategic goals of senior management to the front-line managers.
Line managers such as supervisors and front-line team leaders, oversee the work of regular employees (or volunteers, in some voluntary organizations) and provide direction on their work. Line managers often perform the traditional functions of management. They are usually considered part of the workforce and not a proper part of the organization's management.In smaller organizations, a manager may have a much wider scope and may perform several roles or even all of the roles commonly observed in a large organization.
Social scientists study management as an academic discipline, investigating areas such as social organization, organizational adaptation, and organizational leadership.",0
Business Administration,Organizational conflict,"Organizational conflict, or workplace conflict, is a state of discord caused by the actual or perceived opposition of needs, values and interests between people working together. Conflict takes many forms in organizations. There is the inevitable clash between formal authority and power and those individuals and groups affected. There are disputes over how revenues should be divided, how the work should be done, and how long and hard people should work. There are jurisdictional disagreements among individuals, departments, and between unions and management. There are subtler forms of conflict involving rivalries, jealousies, personality clashes, role definitions, and struggles for power and favor. There is also conflict within individuals – between competing needs and demands – to which individuals respond in different ways.

",0
Business Administration,Performance consulting,"Performance consulting is a practice that became popular in the  early 2000s. Performance consulting is a practice that evolved from the instructional design discipline. It is performed by performance consultants who use more of a systems-thinking approach to resolving workplace performance problems. Performance consulting acknowledges that there are other environmental factors that affect one's performance. While instructional design and the development of training or learning solutions helps to build knowledge and skills, performance consulting takes a more systems-thinking approach to investigate and identify other environmental factors that may degrade one's performance.",0
Business Administration,Exit criteria,"Exit criteria are the criteria or requirements which must be met to complete a specific task or process as used in some fields of business or science, such as software engineering.",0
Business Administration,Association management company,"An association management company, or AMC, provides management and specialized administrative services to non-profit trade associations and professional associations using a for-profit approach. Many AMCs serve as an organization's headquarters, managing day-to-day operations and becoming the public face of the organization.Services may include executive, administrative and financial management; strategic planning; membership development; public affairs and lobbying; education and professional development; statistical research; meetings management; and marketing and communication services. Orienting board members is common; AMCs lay out expectations for fiduciary oversight and point out conflicts of interest.Fernley & Fernley, Inc., based in Philadelphia and founded in 1886, was the first association management company in the United States. More than 600 AMCs worldwide now collectively manage associations ranging in budget size from $50,000 to $16 million and representing more than 3 million members. AMCs can be found in most major U.S. cities.The Alexandria, Va.-based AMC Institute accredits AMCs under the guidance of the American National Standards Institute. Current employees of AMCs are eligible to apply to become a Certified Association Executive.Chicago-based SmithBucklin is the world's largest AMC, although Geneva, Switzerland-based MCI Group, a professional conference organiser that offers AMC services, has more employees: 1,900 as of 2016.

",0
Business Administration,Oliver Wyman,"Oliver Wyman is an American management consulting firm. Founded in New York City in 1984 by former Booz Allen Hamilton partners Alex Oliver and Bill Wyman, the firm has more than 60 offices in Europe, North America, the Middle East, and Asia-Pacific, employing over 5,000 professionals. The firm is part of the Oliver Wyman Group, a business unit of Marsh McLennan.",0
Business Administration,Stewardship theory,"Stewardship theory is a theory that managers, left on their own, will act as responsible stewards of the assets they control.Stewardship theorists assume that given a choice between self-serving behavior and pro-organizational behavior, a steward will place higher value on cooperation than defection. Stewards are assumed to be collectivists, pro-organizational, and trustworthy.In American politics, an example of the stewardship theory is where a president practices a governing style based on belief, they have the duty to do whatever is necessary in national interest, unless prohibited by the Constitution.  The Stewardship approach is often associated with Theodore Roosevelt, who viewed the Presidency as a ""Bully pulpit"" of moral and political leadership.",0
Business Administration,Dynaxity,"Dynaxity is a compound word of dynamics and complexity. The term describes the combination of dynamics and complexity. It was invented in the late 1980s and was initially published and used by Rieckmann. The term was used by many authors, i.a. by Henning and Tiltmann.The term was developed from practical experiences in managing complex systems in companies and organizations and describes the simultaneous increase of complexity and dynamics as well as the implications for the perception, diagnosis and management of such.
In general, four different zones can be distinguished: static, dynamic, turbulent and chaotic. These four zones correspond to the different degrees of Dynaxity.",0
Business Administration,Instruction creep,"Instruction creep or rule creep occurs when instructions or rules accumulate over time until they are unmanageable or inappropriate.  It is a type of scope creep.  The accumulation of bureaucratic requirements results in overly complex procedures that are often misunderstood, irritating, time-wasting, or ignored. 
Instruction creep is common in complex organizations, where rules and guidelines are created by changing groups of people over extended periods of time.  The constant state of flux in such groups often leads them to add or modify instructions, rather than simplifying, consolidating, or generalizing existing ones.  This can result in a loss of clarity, efficiency, and communication, or even of consistency.  Alternatives to instruction creep include applying the KISS principle, articulating general principles rather than specific rules, and trusting people to use their best judgment.
The fundamental fallacy of instruction creep is believing that people read instructions with the same level of attention and comprehension, regardless of the volume or complexity of those instructions. A byproduct is the advent of many new rules having the deliberate intent to control others via fiat, without considering consensus or collaboration. This tends to antagonize others, even when it appears to the instigators that they are acting with proper intent.

",0
Business Administration,Full Range Leadership Model,"The Full Range of Leadership Model (FRLM) is a general leadership theory focusing on the behavior of leaders towards the workforce in different work situations. The FRLM relates transactional and transformational leadership styles with laissez-faire leadership style.The concepts of three distinct leadership styles — transactional, transformational, and laissez-faire — were introduced in 1991 by Bruce Avolio and Bernard Bass

",0
Business Administration,11 Honoré,"11 Honoré is a Los Angeles-based luxury plus-sized contemporary fashion e-retailer that works directly with high-end designers and brands, including Zac Posen, Prabal Gurung, Jason Wu, Christian Siriano and more. Founded in 2017 by Patrick Herning, the company began with investments from Forerunner, Nordstrom, Upfront, Greycroft and Canvas. Over time, the company would expand from its initial 15 brands at launch to almost 90 within two years of its launch.In 2019, 11 Honoré received significant press coverage for its event at New York Fashion Week featuring a size-inclusive runway featuring multiple designers, headlined by actress Laverne Cox and plus-sized models including Candice Huffine, Marquita Pring, Precious Lee, Stella Duval and Tara Lynn.In 2020 the company launched its own private label, initially featuring 24 pieces.In October 2021, 11 Honoré announced a partnership with Nordstrom where the company's clothing will be accessible in Nordstrom stores as well as on the retailer's website.",0
Business Administration,Portfolio career,"A portfolio career comprises a variety of roles rather than one job at a single organisation. It can be a career that combines multiple paid and/or voluntary roles.
The philosopher and organisational behaviourist Charles Handy popularised the ""portfolio"" concept
in works like his 1994 book The Empty Raincoat.
Handy's recognition of the portfolio career-path came about when he realised that individuals would be required to develop portable skillsets to meet the needs of a fast-moving future workplace. His prediction foresaw what is now known as the gig economy.Portfolio careers are often found in the creative industries where freelancing is the norm.
Economic conditions mean many are now actively choosing to pursue portfolio careers to make the most of their earning potential.",0
Business Administration,Delaying tactic,"A delaying tactic or delay tactic is a strategic device sometimes used during business, diplomatic or interpersonal negotiations, in which one party to the negotiation seeks to gain an advantage by postponing a decision.  Someone uses a delaying tactic when they expect to have a stronger negotiating position at a later time. They may also use a delaying tactic when they prefer the status quo to any of the potential resolutions, or to impose costs on the other party to compel them to accept a settlement or compromise. Delay tactics are also sometimes used as a form of indirect refusal wherein one party postpones a decision indefinitely rather than refusing a negotiation outright. To use a delaying tactic, the delaying party must have some form of control over the decision-making process.",0
Business Administration,Workers' control,"Workers' control is participation in the management of factories and other commercial enterprises by the people who work there.  It has been variously advocated by anarchists, socialists, communists, social democrats, distributists and Christian democrats, and has been combined with various socialist and mixed economy systems.
Workers' councils are a form of workers' control. Council communism, such as in the early Soviet Union, advocates workers' control through workers' councils and factory committees. Syndicalism advocates workers' control through trade unions. Guild socialism advocates workers' control through a revival of the guild system. Participatory economics represents a recent variation on the idea of workers' control.
Workers' control can be contrasted to control of the economy via the state, such as nationalization and central planning (see state socialism) versus control of the means of production by owners, which workers can achieve through employer provided stock purchases, direct stock purchases, etc., as found in capitalism.",0
Business Administration,Management entrenchment,"Management is a type of labor with a special role of coordinating the activities of inputs and carrying out the contracts agreed among inputs, all of which can be characterized as ""decision making"". Managers usually face disciplinary forces by making themselves irreplaceable in a way that the company would lose without them. A manager has an incentive to invest the firm's resources in assets whose value is higher under him than under the best alternative manager, even when such investments are not value-maximizing.",0
Business Administration,Business sector,"In economics, the business sector or corporate sector - sometimes popularly called simply ""business"" - is ""the part of the economy made up by companies"". It is a subset of the domestic economy, excluding the economic activities of general government, of private households, and of non-profit organizations serving individuals. The business sector is part of the private sector, but it differs in that the private sector includes all non-government activity, including non-profit organizations, while the business sector only includes business that operate for profit.
In the United States the business sector accounted for about 78 percent of the value of gross domestic product (GDP) as of 2000. Kuwait and Tuvalu each had business sectors accounting for less than 40% of GDP as of 2015.In systems of state capitalism, much of the business sector forms part of the public sector.
In  mixed economies, state-owned enterprises may straddle any divide between public and business sectors, allowing analysts to use the concept of a ""state-owned enterprise sector"".The Oxford English Dictionary records the phrase ""business sector"" in the general sense from 1934.
Word usage suggests that the concept of a ""business sector"" came into wider use after 1940.
Related terms in previous times included ""merchant class"" and ""merchant caste"".",0
Business Administration,Macromanagement,"Macromanagement is a management theory with two different approaches to the definition that both share a common idea; management from afar. 
Contrary to micromanagement where managers closely observe and control the works of their employees, macromanagement is a more independent style of organizational management. Managers step back and give employees the freedom to do their job how they think it is best done, so long as the desired result is reached. This is the most commonly applied understanding of macromanagement. 
Both styles of management are viewed as a negative when taken to an extreme, so it is important for organizations to develop a balance of micro- and macromanagement practices and understand when to apply which. 
The second interpretation of macromanagement is when an organization views itself as a social institution, orienting its goals and purpose toward serving society. To do this, they align the organization’s values, norms, ethics with those of the society they are immersed in. In 1971, Alan Wells defined a social institution as “patterns of rules, customs, norms, beliefs and roles that are instrumentally related to the needs and purposes of society.” Other examples of social institutions in this respect include government and religious organizations, some more in-line with serving society that others.  
This interpretation of macromanagement is less about managing employees, but rather managing the organization from a broader perspective that is oriented toward the future. An organization that practices macromanagement greatly considers the future of the organization, the future of society, and their impact on one another.

",0
Business Administration,Managing by wire,"Managing by wire is a management strategy in which managers rely on their company's ""information representation"" generated by computers such as databases and software instead of on detailed commands.
It was presented by Stephan H. Haeckel and Richard L. Nolan in a 1993 Harvard Business Review article. The authors chose the term ""managing by wire"" as an analogue to the fly-by-wire concept for jets. SAP SE, Aetna, Mrs. Fields Cookies, and Brooklyn Union Gas have done ""managing by wire"".",0
Business Administration,Managerial hubris,"Managerial hubris is the unrealistic belief held by managers in bidding firms that they can manage the assets of a target firm more efficiently than the target firm's current management. 
Managerial hubris is one reason a manager may choose to invest in a merger that on average generates no profits.

",0
Business Administration,Maria Ramberger,"Maria Ramberger is a 2-time Olympic Snowboarder and Engagement Manager at McKinsey & Company where she served a broad range of tech clients across Hardware, Software and Tech Services. Born in Vienna, Austria she initially joined as part of the German office in 2017 and later transferred to the United States in early 2019. Before joining McKinsey she was a member of the Austrian National Snowboard Team. Maria also holds a PhD in law and served in the Austrian Armed Forces (2007 - 2012).",0
Business Administration,Plan,"A plan is typically any diagram or list of steps with details of timing and resources, used to achieve an objective to do something. It is commonly understood as a temporal set of intended actions through which one expects to achieve a goal.
For spatial or planar topologic or topographic sets see map.
Plans can be formal or informal:

Structured and formal plans, used by multiple people, are more likely to occur in projects, diplomacy, careers, economic development, military campaigns, combat, sports, games, or in the conduct of other business. In most cases, the absence of a well-laid plan can have adverse effects: for example, a non-robust project plan can cost the organization time and money.
Informal or ad hoc plans are created by individuals in all of their pursuits.The most popular ways to describe plans are by their breadth, time frame, and specificity; however, these planning classifications are not independent of one another. For instance, there is a close relationship between the short- and long-term categories and the strategic and operational categories.
It is common for less formal plans to be created as abstract ideas, and remain in that form as they are maintained and put to use. More formal plans as used for business and military purposes, while initially created with and as an abstract thought, are likely to be written down, drawn up or otherwise stored in a form that is accessible to multiple people across time and space. This allows more reliable collaboration in the execution of the plan.",0
Business Administration,Decentralized decision-making,"Decentralized decision-making is any process where the decision-making authority is distributed throughout a larger group. It also connotes a higher authority given to lower level functionaries, executives, and workers. This can be in any organization of any size, from a governmental authority to a corporation. However, the context in which the term is used is generally that of larger organizations. This distribution of power, in effect, has far-reaching implications for the fields of management, organizational behavior, and government.
The decisions arising from a process of decentralized decision-making are the functional result of group intelligence and crowd wisdom. Decentralized decision-making also contributes to the core knowledge of group intelligence and crowd wisdom, often in a subconscious way a la Carl Jung's collective unconscious.
Decision theory is a method of deductive reasoning based on formal probability and deductive reasoning models. It is also studied in a specialized field of mathematics wherein models are used to help make decisions in all human activities including the sciences and engineering. (See also Game theory, Uncertainty, Expectation maximization principle.)",0
Business Administration,Upper echelons theory,"The upper echelons theory is a management theory published by Donald C. Hambrick and P. Mason in 1984.
It states that organizational outcomes are partially predicted by managerial background characteristics of the top level management team.

",0
Business Administration,Business interaction networks,"Business interaction networks are networks that allow businesses and their communities of interest to collaborate and do business online securely via the Internet.Mary Johnston Turner first discussed the concept in a Network World opinion piece in August 1995 and attributed the first advocacy for the concept to the now-defunct BBN Planet, the ISP division of BBN Technologies.",0
Business Administration,Organizing (management),"Organizating or organising is the establishment of effective authority relationships among selected works, persons and work places in order for the group to work together efficiently, or the  process of dividing work into sections and departments.",0
Business Administration,Fayolism,"Henri Fayol (29 July 1841 – 19 November 1925) was a French mining engineer, mining executive, author and director of mines who developed a general theory of business administration that is often called Fayolism. He and his colleagues developed this theory independently of scientific management but roughly contemporaneously. Like his contemporary Frederick Winslow Taylor, he is widely acknowledged as a founder of modern management methods.

",0
Business Administration,Feminine style of management,"The feminine style of management is a management style generally characterized by more feminine quality soft skills and behaviors such as empathy, effective communication, and a generally more democratic or team-styled work environment. The style is a growing trend within businesses and is characterized by a form of transformational leadership style. The feminine style of management, although characterized by traits commonly labeled as feminine, it is not a style of management that is only used by females; it is also a style which has been found beneficial for particular types of businesses and organizations.",0
Business Administration,Chartered Administrator,"A Chartered Administrator (French: Administrateur agréé) is a member of the Ordre des Administrateurs Agréés du Québec who may use the abbreviation ""Adm.A."" in French or ""C.Adm."" in English.
The title Adm.A. or C.Adm. turns out to be a reserved regulated profession; it has no reserved activities. These management professionals are supervised by the Quebec professional system.
In Canada (outside Quebec), there is no equivalent professional title in the management sciences.",0
Business Administration,Design leadership,"Design leadership is a concept complementary to design management. In practice, design managers within companies often operate in the field of design leadership and design leaders in the field of design management. However, the two terms are not interchangeable; they are interdependent. In essence, design leadership aims to define future strategies, and design management is responsible for implementation. Both are critically important to business, government, and society, and both are necessary in order to maximize value from design activity and investment.
Design leadership can be described as leadership that generates innovative design solutions. Turner defines design leadership by adding three additional aspects for design leadership:
the difference in leading through design,
the sustaining design leadership over time
the gaining of acknowledgment for achievements through design.Turner separates the core responsibilities of design leadership into the following six activities:
envisioning of the future
manifesting strategic intent
directing design investment
managing corporate reputation
creating and nurturing an environment of innovation
training for design leadership

",0
Business Administration,Interdepartmental communication,"Interdepartmental communication is largely a formal affair between different departments of an organization. Interdepartmental communication is effective when it is supported by good infrastructural facilities. There are various documents used in inter departmental communication, they are:
A memorandum is a note or record for future use. It is convenient and useful for informal communication. Most interdepartmental communication is done over phone, but when the information has to be communicated in writing then memorandums are used. Memos are also issued in the cases of disciplinary actions to be taken against employees. The format of a memo is almost the same.
Office circulars are used to convey the information to a large number of employees. It is used for internal communication, so it is brief and formal.
The format of office orders is similar to memorandum but the purpose for which it is issued will differ. It is usually issued in matters affecting rights and privileges of employees. Office orders carry a number since they will be in force until revoked.
Suggestions are given by employees. Sometimes they given by one department to another. It helps in developing new ideas and policies. But its effectiveness depends on the attitude of the management.
Complaints are a part of office routine. As the size of the organization increases, the number of complaints also increases. In many cases complaints may relate to lack of proper infrastructure, non-observance of rules, etc.",0
Business Administration,Outline of business management,"The following outline is provided as an overview of and topical guide to management:
Business management – management of a business. Business management rule #1 is delegation, assign the best qualified people to each position and trust your staff to do the work instead of trying to do everything yourself. It includes all aspects of overseeing and supervising business operations. Management is the act of allocating resources to accomplish desired goals and objectives efficiently and effectively; it comprises planning, organizing, staffing, leading or directing, and controlling an organization (a group of one or more people or entities) or effort for the purpose of accomplishing a goal.",0
Business Administration,Success,"Success is the state or condition of meeting a defined range of expectations. It may be viewed as the opposite of failure. The criteria for success depend on context, and may be relative to a particular observer or belief system. One person might consider a success what another person considers a failure, particularly in cases of direct competition or a zero-sum game. Similarly, the degree of success or failure in a situation may be differently viewed by distinct observers or participants, such that a situation that one considers to be a success, another might consider to be a failure, a qualified success or a neutral situation. For example, a film that is a commercial failure or even a box-office bomb can go on to receive a cult following, with the initial lack of commercial success even lending a cachet of subcultural coolness.It may also be difficult or impossible to ascertain whether a situation meets criteria for success or failure due to ambiguous or ill-defined definition of those criteria. Finding useful and effective criteria, or heuristics, to judge the failure or success of a situation may itself be a significant task.",0
Business Administration,Body shopping,"Body shopping is the practice of consultancy firms recruiting workers (generally in the information technology sector) in order to contract their services out on a tactical short- to mid-term basis. IT services companies that practice body shopping assert that they provide real services (such as software development) rather than the ""sham"" of merely farming out professionals to overseas companies.",0
Business Administration,Office,"An office is a space where an organization's employees perform administrative work in order to support and realize objects and goals of the organization. The word ""office"" may also denote a position within an organization with specific duties attached to it (see officer, office-holder, official); the latter is in fact an earlier usage, office as place originally referring to the location of one's duty. When used as an adjective, the term ""office"" may refer to business-related tasks. In law, a company or organization has offices in any place where it has an official presence, even if that presence consists of (for example) a storage silo rather than an establishment with desk-and-chair. An office is also an architectural and design phenomenon: ranging from a small office such as a bench in the corner of a small business of extremely small size (see small office/home office), through entire floors of buildings, up to and including massive buildings dedicated entirely to one company. In modern terms an office is usually the location where white-collar workers carry out their functions. According to James Stephenson, ""Office is that part of business enterprise which is devoted to the direction and co-ordination of its various activities.""
Offices in classical antiquity were often part of a palace complex or of a large temple. The High Middle Ages (1000–1300) saw the rise of the medieval chancery, which was usually the place where most government letters were written and where laws were copied in the administration of a kingdom. With the growth of large, complex organizations in the 18th century, the first purpose-built office spaces were constructed. As the Industrial Revolution intensified in the 18th and 19th centuries, the industries of banking, rail, insurance, retail, petroleum, and telegraphy grew dramatically, requiring many clerks, and as a result more office space was assigned to house their activities. The time-and-motion study, pioneered in manufacturing by F. W. Taylor (1856-1915) led to the ""Modern Efficiency Desk"" of 1915 with a flat top and drawers below, designed to allow managers an easy view of the workers.
However, by the middle of the 20th century, it became apparent that an efficient office required discretion in the control of privacy, and gradually the cubicle system evolved.The main purpose of an office environment is to support its occupants in performing their jobs. Work spaces in an office are typically used for conventional office activities such as reading, writing and computer work. There are nine generic types of work space, each supporting different activities. In addition to individual cubicles, one can find meeting rooms, lounges, and spaces for support activities, such as photocopying and filing. Some offices also have a kitchen area where workers can make their lunches. There are many different ways of arranging the space in an office and whilst these vary according to function, managerial fashions and the culture of specific companies can be even more important.
While offices can be built in almost any location and in almost any building, some modern requirements for offices make this more difficult, such as requirements for light, networking, and security. The major purpose of an office building is to provide a workplace and working environment - primarily for administrative and managerial workers. These workers usually occupy set areas within the office building, and usually are provided with desks, PCs and other equipment they may need within these areas. The chief operating officer (COO) is responsible for handling administration and maintenance of an office building.",0
Business Administration,Religion and business,"Religion and business have throughout history interacted in ways that relate to and affected one another, as well as influenced sociocultural evolution, political geographies, and labour laws. As businesses expand globally they seek new markets which leads to expanding their corporation's norms and rules to encompass the new locations norms which most often involve religious rules and terms.",0
Business Administration,Community of practice,"A community of practice (CoP) is a group of people who ""share a concern or a passion for something they do and learn how to do it better as they interact regularly"". The concept was first proposed by cognitive anthropologist Jean Lave and educational theorist Etienne Wenger in their 1991 book Situated Learning (Lave & Wenger 1991). Wenger then significantly expanded on the concept in his 1998 book Communities of Practice (Wenger 1998).
A CoP can evolve naturally because of the members' common interest in a particular domain or area, or it can be created deliberately with the goal of gaining knowledge related to a specific field. It is through the process of sharing information and experiences with the group that members learn from each other, and have an opportunity to develop personally and professionally (Lave & Wenger 1991).
CoPs can exist in physical settings, for example, a lunchroom at work, a field setting, a factory floor, or elsewhere in the environment, but members of CoPs do not have to be co-located. They form a ""virtual community of practice"" (VCoP) (Dubé, Bourhis & Jacob 2005) when they collaborate online, such as within discussion boards, newsgroups, or the various chats on social media, such as #musochat centered on contemporary classical music performance (Sheridan 2015). A ""mobile community of practice"" (MCoP) (Kietzmann et al. 2013) is when members communicate with one another via mobile phones and participate in community work on the go.
Communities of practice are not new phenomena: this type of learning has existed for as long as people have been learning and sharing their experiences through storytelling. The idea is rooted in American pragmatism, especially C. S. Peirce's concept of the ""community of inquiry"" (Shields 2003), but also John Dewey's principle of learning through occupation (Wallace 2007).

",0
Business Administration,Management process,"Management process is a process of setting goals, planning and/or controlling the organising and leading the execution of any type of activity, such as: 

a project (project management process) or
a process (process management process, sometimes referred to as the process performance measurement and management system).An organization's senior management is responsible for carrying out its management process. However, this is not always the case for all management processes, for example, sometimes it is the responsibility of the project manager to carry out a project management process.

",0
Business Administration,Turnaround management,"Turnaround management is a process dedicated to corporate renewal. It uses analysis and planning to save troubled companies and return them to solvency, and to identify the reasons for failing performance in the market, and rectify them. Turnaround management involves management review, root failure causes analysis, and SWOT analysis to determine why the company is failing. Once analysis is completed, a long term strategic plan and restructuring plan are created. These plans may or may not involve a bankruptcy filing. Once approved, turnaround professionals begin to implement the plan, continually reviewing its progress and make changes to the plan as needed to ensure the company returns to solvency.",0
Business Administration,Court of assistants,"A court of assistants is a council of members belonging to professional, trade, craft or livery companies.
The term originated among the London livery companies, as 'certain senior members who manage the affairs of the City of London Companies', but may also be used by other trade associations. A court of assistants usually comprises the governing body of such organisations and may include the officials, as in the case of the Worshipful Company of Clockmakers founded in 1631: ""The governing body of the Company is the Court of Assistants, comprising the Master, three Wardens and not less than ten Assistants.""Another example is the Honourable Artillery Company, which has an annual General Court open to all members: it meets in March to elect 20 Assistants. The company is governed in its civil and financial affairs by the Court of Assistants, which was first established in 1633.",0
Business Administration,Public consultation,"Public consultation (Commonwealth countries and European Union), public comment (US),  or simply consultation, is a regulatory process by which the public's input on matters affecting them is sought. Its main goals are in improving the efficiency, transparency and public involvement in large-scale projects or laws and policies. It usually involves notification (to publicise the matter to be consulted on), consultation (a two-way flow of information and opinion exchange) as well as participation (involving interest groups in the drafting of policy or legislation). A frequently used tool for understanding different levels of community participation in consultation is known as Arnstein's ladder, although some academics contest that Arnstein's ladder is contextually specific and was not intended to be a universal tool. Ineffective consultations are considered to be cosmetic consultations that were done due to obligation or show and not true participatory decision making.
Public comment (or ""vox populi"") is a public meeting of government bodies which set aside time for public comments, usually upon documents. Such documents may either be reports such as Draft Environmental Impact Reports (DEIR's) or new regulations. There is typically a notice which is posted on the web and mailed to lists of interested parties known to the government agencies. If there is to be a change of regulations, there will be a formal notice of proposed rulemaking.
The basis for public comment is found in general political theory of constitutional democracy as originated during and after the Enlightenment, particularly by Rousseau. This basis was elaborated in the American Revolution, and various thinkers such as Benjamin Franklin, Thomas Jefferson and Thomas Paine are associated with the rejection of tyrannical, closed government decision making in favor of open government. The tradition of the New England Town Hall is believed to be rooted in this early American movement, and the distillation of formal public comment in official proceedings in the United States is a direct application of this format in the workings of public administration itself.",0
Business Administration,Cultural intelligence,"Cultural intelligence or cultural quotient (CQ) is the capability to relate and work effectively across cultures, bearing similarity to the term cultural agility. The term has been used in business, education, government and academic research contexts. Originally, the term cultural intelligence and the abbreviation ""CQ"" was developed by the research done by Christopher Earley (2002) and Earley and Soon Ang (2003). During the same period, researchers David Thomas and Kerr Inkson worked on a complementary framework of CQ as well. A few years later, Ang Soon and Linn Van Dyne worked on a scale development of the CQ construct as a researched-based way of measuring and predicting intercultural performance.
The term is relatively recent: early definitions and studies of the concepts were given by P. Christopher Earley and Soon Ang in the book Cultural Intelligence: Individual Interactions Across Cultures (2003) and more fully developed later by David Livermore in the book, Leading with Cultural Intelligence. The concept is related to that of cross-cultural competence. but goes beyond that to actually look at intercultural capabilities as a form of intelligence that can be measured and developed. According to Earley, Ang, and Van Dyne, cultural intelligence can be defined as ""a person's capability to adapt as s/he interacts with others from different cultural
regions"", and has behavioral, motivational, and metacognitive aspects. Without cultural intelligence, both business and military actors seeking to engage foreigners are susceptible to mirror imaging.Cultural intelligence or CQ is measured on a scale, similar to that used to measure an individual's intelligence quotient. People with higher CQs are regarded as better able to successfully blend into any environment, using more effective business practices, than those with a lower CQ. CQ is assessed using the academically validated assessment created by Linn Van Dyne and Soon Ang. Both self-assessments and multi-rater assessments are available through the Cultural Intelligence Center in East Lansing, Michigan and the Center makes the CQ Scale available to other academic researchers at no charge. Research demonstrates that CQ is a consistent predictor of performance in multicultural settings.  Cultural intelligence research has been cited and peer-reviewed in more than seventy academic journals. The research and application of cultural intelligence is being driven by the Cultural Intelligence Center in the U.S. and Nanyang Business School in Singapore. Additional research and application of cultural intelligence has been conducted by Liliana Gil Valletta, who holds the trademark for the term since 2013. Defined as the ability to be aware of, understand and apply cultural competence into everyday business decisions, Gil Valletta has expanded the definition of cultural intelligence into a capability that yields a commercial advantage by turning cultural trends into profits and P&L impact. Since 2010, the firm CIEN+ and data science platform Culturintel is the first using artificial intelligence and big data tools to report measures of cultural intelligence and enable corporations to embed inclusion for business growth.

",0
Business Administration,Smiling curve,"In business management theory, the smiling curve is a graphical depiction of how value added varies across the different stages of bringing a product on to the market in an IT-related manufacturing industry. The concept was first proposed around 1992 by Stan Shih, the founder of Acer Inc., an IT company headquartered in Taiwan. According to Shih's observation, in the personal computer industry, the two ends of the value chain – conception and marketing – command higher values added to the product than the middle part of the value chain – manufacturing. If this phenomenon is presented in a graph with a Y-axis for value-added and an X-axis for value chain (stage of production), the resulting curve appears like a ""smile"".
Based on this model, the Acer company adopted a business strategy to reorient itself from manufacturing into global marketing of brand-name PC-related products and services. Acer accordingly invested heavily in R&D to develop innovative technology. The concept later became widely cited to describe the distribution of value-adding potentials in other types of industry to justify business strategies aimed at higher value-adding activities.",0
Business Administration,Research ethics consultation,"Analogous to clinical ethics consultation, Research Ethics Consultation (REC) describes a formal way for researchers to solicit and receive expert ethical guidance related to biomedical research. The first REC service was established at the National Institutes of Health (NIH) Clinical Center in 1997. Today, most REC services are found at academic institutions, and the majority of current services were originally launched in response to the 2006 NIH Clinical and Translational Science Award program, as applicants to that program were required to have procedures in place to address ethical concerns raised by their research.While still a young discipline with no explicit standards, individuals serving as research ethics consultants are expected to be familiar with research ethics and ethical analysis; knowledgeable about the applicable regulations, laws, and policies; and ideally also have some biomedical research experience and scientific expertise.REC is distinct from related services, such as those of Institutional Review Boards, in that it is typically available at any point during a study (planning, conducting, interpreting, or disseminating results), and can relate to any ethical question. While little is known about the range and distribution of topics put forth for REC, such services may be particularly important and useful for studies of known regulatory and ethical uncertainty (e.g. assessment of minimal risk in pediatric studies) and frontier research for which there is little if any regulation or expert consensus. The recommendations that result from the consultation are non-binding, meaning that the researcher may choose to follow the recommendation, or to pursue a different approach.",0
Business Administration,Engineering consulting,"Engineering consulting is the practice of performing engineering as a consulting engineer. It assists public and private companies with process management, idea organization, product design, fabrication, MRO (Maintenance, Repair and Operations), servicing, tech advice, tech specifications, tech estimating, costing, budgeting, valuation, branding, and marketing.Engineering consulting firms may involve Civil, Structural, Mechanical, Electrical, Environmental, Chemical, Industrial, and Agricultural, Electronics and Telecom, Computer and Network, Instrumentation and Control, IT, Manufacturing and Production, Aerospace, Marine, Fire and Safety, etc. Consulting engineers may also assist in marketing.",0
Business Administration,Managerial psychology,"Managerial psychology is a sub-discipline of industrial and organizational psychology that focuses on the effectiveness of individuals and groups in the workplace, using behavioral science.
The purpose of managerial psychology is to aid managers in gaining a better managerial and personal understanding of the psychological patterns common among these individuals and groups.

Managers can use managerial psychology to predict and prevent harmful psychological patterns within the workplace and to control psychological patterns to benefit the organisation long term.
Managerial psychologists help managers, through research in theory, practice, methods and tools, to achieve better decision-making, leadership practices and development, problem solving and improve overall human relations.

",0
Business Administration,Fish! Philosophy,"The Fish! Philosophy (styled FISH! Philosophy), modeled after the Pike Place Fish Market, is a business technique that is aimed at creating happy individuals in the workplace. John Christensen created this philosophy in 1998 to improve organizational culture. The central four ideas are: ""choose your attitude"", ""play"", ""make their day"" and the ""present moment"".",0
Business Administration,Managerial finance,"Managerial finance is the branch of finance that concerns itself with the managerial application of finance techniques and theory, 

emphasizing the financial aspects of managerial decisions.
The techniques addressed are drawn in the main from managerial accounting and corporate finance; 
the former allow management to better understand, and hence act on, financial information relating to profitability and performance; the latter are about optimizing the overall financial-structure.
The discipline is somewhat academic in nature, and ""is concerned more with the assessment of financial techniques versus the financial techniques themselves""; 
its emphasis though, is managerial as opposed to technical.
Putting the techniques into practice -  i.e. performing financial management - entails strategic planning, organizing, directing, and controlling of the organization's financial undertakings; see Financial analyst § Corporate and other and Financial management § Role.
Correspondingly, the discipline will assess the various techniques from the perspectives of Planning, Directing, and Controlling.",0
Business Administration,Management buy-in,"A management buy-in (MBI) occurs when a manager or a management team from outside the company raises the necessary finance, buys it, and becomes the company's new management. A management buy-in team often competes with other purchasers in the search for a suitable business. Usually, the team will be led by a manager with significant experience at managing director level.
The difference to a management buy-out is in the position of the purchaser: in the case of a buy-out, they are already working for the company. In the case of a buy-in, however, the manager or management team is from another source.

",0
Business Administration,Agribusiness,"Agribusiness refers to the enterprises, the industry, and the field of study of  value chains in agriculture and in the bio-economy,
in which case it is also called bio-business or bio-enterprise. 
The primary goal of agribusiness is to maximize profit while sustainably satisfying the needs of consumers for products related to natural resources such as biotechnology, farms, food, forestry, fisheries, fuel, and fiber — usually with the exclusion of non-renewable resources such as mining.Studies of business growth and performance in farming have found successful agricultural businesses are cost-efficient internally and operate in favorable economic, political, and physical-organic environments.  They are able to expand and make profits, improve the productivity of land, labor, and capital, and keep their costs down to ensure market price competitiveness.Agribusiness is not limited to farming. It encompasses a broader spectrum through the agribusiness system which includes input supplies, value-addition, marketing, entrepreneurship, microfinancing, agricultural extension, among others.
In some countries like the Philippines, creation and management of agribusiness enterprises require consultation with registered agriculturists if reached a certain level of operations, capitalization, land area, or number of animals in the farm.",0
Business Administration,Client (business),"In business, commerce, and economics, a client is a person who receives advice or services from a professional, such as a lawyer or a health care provider. Clients differ from customers in that customers are thought of as ""one-time buyers"" while clients can be summarized as ""long-term recipients.""",0
Business Administration,Managerial economics,"Managerial economics is a branch of economics involving the application of economic methods in the managerial decision-making process. Economics is the study of the production, distribution and consumption of goods and services. Managerial economics involves the use of economic theories and principles to make decisions regarding the allocation of scarce resources.Managers use economic frameworks in order to optimise profits, resource allocation and the overall output of the firm, whilst improving efficiency and minimising unproductive activities. These frameworks assist organisations to make rational, progressive decisions, by analysing practical problems at both micro and macroeconomic levels. Managerial decisions involve forecasting (making decisions about the future), which involve levels of risk and uncertainty, however, the assistance of managerial economic techniques aid in informing managers in these decisions.The two main purposes of managerial economics are:

To optimize decision making when the firm is faced with problems or obstacles, with the consideration and application of macro and microeconomic theories and principles.
To analyze the possible effects and implications of both short and long-term planning decisions on the revenue and profitability of the Business.The core principles that managerial economist use to achieve the above purposes are; monitoring operations management and performance, target or goal setting and talent management and development.
In order to optimize economic decisions, the use of operations research, mathematical programming, strategic decision making, game theory and other computational methods are often involved. The methods listed above are typically used for making quantitate decisions by data analysis techniques.
The theory of Managerial Economics includes a focus on; incentives, business organization, biases, advertising, innovation, uncertainty, pricing, analytics, and competition. In other words, managerial economics is a combination of economics and managerial theory.  It helps the manager in decision-making and acts as a link between practice and theory.
Furthermore, managerial economics provides the device and techniques for managers to make the best possible decisions for any scenario.
Some examples of the types of problems that the tools provided by managerial economics can answer are:

The price and quantity of a good or service that a business should produce.
Whether to invest in training current staff or to look into the market.
When to purchase or retire fleet equipment.
Decisions regarding understanding the competition between two firms based on the motive of profit maximization.
The impacts of consumer and competitor incentives plan on business decisionsManagerial economics is sometimes referred to as business economics and is a branch of economics that applies microeconomic analysis to decision methods of businesses or other management units to assist managers to make a wide array of multifaceted decisions. The calculation and quantitative analysis draws heavily from techniques such as regression analysis, correlation and calculus.",0
Business Administration,Office management,"Office management is a profession involving the design, implementation, evaluation, and maintenance of the process of work within an office or other organization, in order to sustain and improve efficiency and productivity.
Office management is thus a part of the overall administration of business and since the elements of management are forecasting and planning, organising, command, control and coordination, the office is a part of the total management function.
Office management is the technique of planning, organizing, coordinating and controlling office activities with a view to achieve business objectives and is concerned with efficient and effective performance of the office work. The success of a business depends upon the efficiency of its office. The volume of paper work in offices has increased manifold in these days due to industrialization, population explosion, government control and application of various tax and labour laws to any business enterprise. Efficiency and effectiveness which are key words in management are achieved only through proper planning and control of activities, reduction of office costs and coordination of all activities of business.
In simple words, office management can be defined as “a distinct process of planning, organizing, staffing, directing, coordinating and controlling office in order to facilitate achievement of objectives of any business enterprise’ the definition shows managerial functions of an administrative manager. Following diagram indicates various elements or functions in the process of office management.",0
Business Administration,Commercialista,"A tax advisor or tax consultant is a person with advanced training and knowledge of tax law. The services of a tax advisor are usually retained in order to minimize taxation while remaining compliant with the law in complicated financial situations. Tax Advisors are also retained to represent clients before tax authorities and tax courts to resolve tax issues.

",0
Business Administration,Closure (business),"Closure is the term used to refer to the actions necessary when it is no longer necessary or possible for a business or other organization to continue to operate.  Closure may be the result of a bankruptcy, where the organization lacks sufficient funds to continue operations, as a result of the proprietor of the business dying, as a result of a business being purchased by another organization (or a competitor) and shut down as superfluous, or because it is the non-surviving entity in a corporate merger.  A closure may occur because the purpose for which the organization was created is no longer necessary.
While a closure is typically of a business or a non-profit organization, any entity which is created by human beings can be subject to a closure, from a single church to a whole religion, up to and including an entire country if, for some reason, it ceases to exist.
Closures are of two types, voluntary or involuntary. Voluntary closures of organizations are much rarer than involuntary ones, as, in the absence of some change making operations impossible or unnecessary, most operations will continue until something happens that causes a change requiring this situation.
The most common form of voluntary closure would be when those involved in an organization such as a social club, a band, or other non-profit organization decide to cease operating. Once the organization has paid any outstanding debts and completed any pending operations, closure may simply mean that the organization ceases to exist.
If an organization has debts that cannot be paid, it may be necessary to perform a liquidation of its assets. If there is anything left after the assets are converted to cash, in the case of a for-profit organization, the remainder is distributed to the stockholders; in the case of a non-profit, by law any remaining assets must be distributed to another non-profit.
If an organization has more debts than assets, it may have to declare bankruptcy. If the organization is viable, it may reorganizes itself as a result of the bankruptcy and continue operations. If it is not viable for the business to continue operating, then a closure occurs through a bankruptcy liquidation: its assets are liquidated, the creditors are paid from whatever assets could be liquidated, and the business ceases operations.
Possibly the largest ""closure"" in history (but more closely analogous to a demerger) was the split of the Soviet Union into its constituent countries. In comparison, the end of East Germany can be considered a merger rather than a closure as West Germany assumed all of the assets and liabilities of East Germany. The end of the Soviet Union was the equivalent of a closure through a bankruptcy liquidation, because while Russia assumed most of the assets and responsibilities of the former Soviet Union, it did not assume all of them. There have been issues over who is responsible for unpaid parking tickets accumulated by motor vehicles operated on behalf of diplomatic missions operated by the former Soviet Union in other countries, as Russia claims it is not responsible for them.
Several major business closures include the bankruptcy of the Penn Central railroad, the Enron scandals, and MCI Worldcom's bankruptcy and eventual merger into Verizon.",0
Business Administration,Multidimensional organization,"A multidimensional organization is an organization that pursues its objectives simultaneously through multiple dimensions (product, region, account, market segment).
The multidimensional organization was discussed as early as the 1970s. It required the combination of the fall of costs of information, the development of dynamic multidimensional markets, and a new generation of workers and managers, to create this paradigm shift in organization forms.",0
Business Administration,Stakeholder approach,"In management, a stakeholder approach is the practice that managers formulate and implement processes that satisfy stakeholders' needs to ensure long-term success. According to the degree of participation of the different groups, the company can take advantage of market imperfections to create valuable opportunities. It emphasizes active management of the business environment, relationships and the promotion of shared interests. This approach is based on stakeholder theory, which arises as a counterpart to business practices and management that focus on shareholders satisfaction. The implementation of this approach can reinforce the firm values and create competitive advantage. However, it has been criticized for overvaluing stakeholders and its difficulty to reach consensus.",0
Business Administration,CEO succession,"CEO succession refers to the process by which boards of directors ensure that their organization has the ability to sustain excellence in CEO leadership over time, with transitions from one leader to the next.",0
Business Administration,Developer relations,"Developer Relations, also known as DevRel, is an umbrella term covering the strategies and tactics for building and nurturing a community of mutually beneficial relationships between organizations and developers (e.g., software developers) as the primary users, and often influencers on purchases, of a product.Developer Relations is a form of Platform Evangelism and the activities involved are sometimes referred to as a Developer Program or DevRel Program. A DevRel program may comprise a framework built around some or all of the following aspects:
Developer Marketing: Outreach and engagement activities to create awareness and convert developers to use a product.
Developer Education: Product documentation and education resources to aid learning and build affinity with a product and community.
Developer Experience (DX): Resources like a developer portal, product, and documentation, to activate the developer with the least friction.
Developer Success: Activities to nurture and retain developers as they build and scale with a product.
Community: Nourishes a community to maintain a sustainable program.The impacts and goals of DevRel programs include:
Increased revenue and funding
User growth and retention
product innovation and improvements
Customer satisfaction and support deflection
Strong technical recruiting pipeline
Brand recognition and awarenessOther goals of DevRel initiatives can include:
Product Building: An organization relies on a community of developers to build their technology (e.g., open source).
Product-market Fit: The product's success depends on understanding developers' needs and desires.
Developer Enablement: Supporting developers' use of the product (e.g., by providing education, tools, and infrastructure).
Developer Perception: To overcome developer perceptions that may be preventing success of a product.
Hiring/Recruiting: To attract potential developers for recruitment.

",0
Business Administration,Energy monitoring and targeting,"Energy monitoring and targeting (M&T) is an energy efficiency technique based on the standard management axiom stating that “you cannot manage what you cannot measure”. M&T techniques provide energy managers with feedback on operating practices, results of energy management projects, and guidance on the level of energy use that is expected in a certain period. Importantly, they also give early warning of unexpected excess consumption caused by equipment malfunctions, operator error, unwanted user behaviours, lack of effective maintenance and the like.
The foundation of M&T lies in determining the normal relationships of energy consumptions to relevant driving factors (HVAC equipment, production though puts, weather, occupancy available daylight, etc.) and the goal is to help business managers:

Identify and explain excessive energy use
Detect instances when consumption is unexpectedly higher or lower than would usually have been the case
Visualize energy consumption trends (daily, weekly, seasonal, operational...)
Determine future energy use and costs when planning changes in the business
Diagnose specific areas of wasted energy
Observe how changes to relevant driving factors impact energy efficiency
Develop performance targets for energy management programs
Manage energy consumption, rather than accept it as a fixed costThe ultimate goal is to reduce energy costs through improved energy efficiency and energy management control. Other benefits generally include increased resource efficiency, improved production budgeting and reduction of  greenhouse gas (GHG) emissions.",0
Business Administration,Managerial prerogative,"Managerial prerogatives are also referred to as the functions and rights of management,  is considered as the discretion of the employer or manager on how to manage its business, not bound by collective bargaining. It is a term that easily leads to widespread misunderstanding. Different circles have different interpretations of this term. When it is used in the trade unions circles, is perceived as a user's support for unilateral management power and can cause protests.When used by the management circle, It is considered as exclusive right and control right without interference.  Managerial prerogatives give employers or managers the power to control the direction in which their businesses are heading. Employees basically do not have this power. 

",0
Business Administration,Grade (consulting),"In information technology consulting and management consulting, a grade aims to explicitly recognize a certain professional level, both within the organization and to customer organizations. A grade is separated from a place in the line hierarchy of a company; it underlines the very possibility of recognizing a person (top) level without being necessarily in a management functions.
The most commonly used system of grading consultants is the following:

Junior consultant or associate consultant: In some fields, an associate consultant is at the beginning of their consulting career and will typically do work to support the consultants and senior consultants - data collection and analysis, workshop support, etc. An associate consultant can also refer to a day rate contractor at any level, differentiating them from an employee of the firm (e.g. associate managing consultant). However, in engineering, urban planning. and some environmental consulting fields the term associate consultant is used differently and is typically a higher grade than principal consultant.
Consultant: A consultant is ‘learning the trade' within a specific domain of expertise. A consultant is developing in most competency dimensions and work in different roles on different projects in a specific domain.
Senior consultant: A senior consultant has developed a specialisation within a specific domain of expertise. A senior consultant is capable of working independently as well as in teams. A senior consultant is often responsible for the completion of a part of a project or activities for which he/she leads a small team. A senior consultant is more client oriented and explores sales activities.
Managing consultant: A managing consultant has started to excel in some of the competency dimensions. A managing consultant is known for domain expertise and is capable of generating his or her own work and that of others. As such the managing consultant is often responsible for business volume, through (add-on) sales and delivering a project. A managing consultant can act as a team lead or counsellor for other team members.
Senior managing consultant: A senior managing consultant has developed excellence within some of the competency dimensions. A senior managing consultant is known for domain expertise and is capable of generating his or her own work and that of others. As such the senior managing consultant is often responsible for business volume, through (add-on) sales and delivering a project. A senior managing consultant leads a team or counsellor for other teams.
Principal consultant: A principal consultant has a strong business impact and is often part of the company's leadership. A principal consultant is capable of shaping a piece of business being the leader in a specific domain and in any other domains. A principal consultant develops high-level business relations and high-impact projects. A principal is capable of leading large teams and also generates new business ideas.
Executive Principal consultant: not a real thing.",0
Business Administration,Business acumen,"Business acumen, also known as business savviness, business sense and business understanding, is keenness and quickness in understanding and dealing with a business situation (risks and opportunities) in a manner that is likely to lead to a good outcome. Additionally, business acumen has emerged as a vehicle for improving financial performance and leadership development. Consequently, several different types of strategies have developed around improving business acumen.

",0
Business Administration,Social entrepreneurship,"Social entrepreneurship is an approach by individuals, groups, start-up companies or entrepreneurs, in which they develop, fund and implement solutions to social, cultural, or environmental issues. This concept may be applied to a wide range of organizations, which vary in size, aims, and beliefs. For-profit entrepreneurs typically measure performance using business metrics like profit, revenues and increases in stock prices. Social entrepreneurs, however, are either non-profits, or they blend for-profit goals with generating a positive ""return to society"". Therefore, they use different metrics. Social entrepreneurship typically attempts to further broad social, cultural and environmental goals often associated with the voluntary sector in areas such as poverty alleviation, health care and community development.
At times, profit-making social enterprises may be established to support the social or cultural goals of the organization but not as an end in themselves. For example, an organization that aims to provide housing and employment to the homeless may operate a restaurant, both to raise money and to provide employment for the homeless.
In 2010, social entrepreneurship was facilitated by the use of the Internet, particularly social networking and social media websites. These websites enable social entrepreneurs to reach numerous people who are not geographically close yet who share the same goals and encourage them to collaborate online, learn about the issues, disseminate information about the group's events and activities, and raise funds through crowdfunding.In recent years, researchers are calling for a better understanding of the ecosystem in which social entrepreneurship exists, and social ventures operate. This will help them formulate better strategy and help achieve their double bottom line objective.",0
Business Administration,Abusive supervision,"Abusive supervision is most commonly studied in the context of the workplace, although it can arise in other areas such as in the household and at school. ""Abusive supervision has been investigated as an antecedent to negative subordinate workplace outcome.""  ""Workplace violence has combination of situational and personal factors"". The study that was conducted looked at the link between abusive supervision and different workplace events.Researchers have previously argued that abusive supervision is a one dimensional construct, however, recently it is found to be a four dimensional construct. The study of Ghayas and Jabeen is a paramount study that suggests abusive supervision to be a four dimensional construct where yelling, belittling behavior, scapegoating and credit stealing are described as the dimensions of abusive supervision. Researchers such as Tepper and Martinko had previously asserted that there was a need to study dimensions of abusive supervision.

",0
